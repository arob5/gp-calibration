@article{MOHAMMADI2019178,
title = {Emulating dynamic non-linear simulators using Gaussian processes},
journal = {Computational Statistics & Data Analysis},
volume = {139},
pages = {178-196},
year = {2019},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2019.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167947319301173},
author = {Hossein Mohammadi and Peter Challenor and Marc Goodfellow},
keywords = {Dynamic simulators, Gaussian processes, Lorenz system, Uncertainty propagation, van der Pol model},
abstract = {The dynamic emulation of non-linear deterministic computer codes where the output is a time series, possibly multivariate, is examined. Such computer models simulate the evolution of some real-world phenomenon over time, for example models of the climate or the functioning of the human brain. The models we are interested in are highly non-linear and exhibit tipping points, bifurcations and chaotic behaviour. However, each simulation run could be too time-consuming to perform analyses that require many runs, including quantifying the variation in model output with respect to changes in the inputs. Therefore, Gaussian process emulators are used to approximate the output of the code. To do this, the flow map of the system under study is emulated over a short time period. Then, it is used in an iterative way to predict the whole time series. A number of ways are proposed to take into account the uncertainty of inputs to the emulators, after fixed initial conditions, and the correlation between them through the time series. The methodology is illustrated with two examples: the highly non-linear dynamical systems described by the Lorenz and van der Pol equations. In both cases, the predictive performance is relatively high and the measure of uncertainty provided by the method reflects the extent of predictability in each system.}
}


@article{doi:10.1137/15M1047659,
author = {Sinsbeck, Michael and Nowak, Wolfgang},
title = {Sequential Design of Computer Experiments for the Solution of Bayesian Inverse Problems},
journal = {SIAM/ASA Journal on Uncertainty Quantification},
volume = {5},
number = {1},
pages = {640-664},
year = {2017},
doi = {10.1137/15M1047659},
URL = { 
    
        https://doi.org/10.1137/15M1047659
},
eprint = {     
        https://doi.org/10.1137/15M1047659
},
abstract = { We present a sequential design strategy for efficient sampling of model functions during the solution of Bayesian inverse problems. The model function is assumed to be computationally expensive and therefore is described by a random field (such as a Gaussian process emulator). The sequential design strategy is a greedy one-step look ahead method, minimizing the Bayes risk with respect to a loss function measuring the quadratic \$L^2\$-error in the likelihood estimate. Four numerical examples demonstrate that the proposed sampling method is more efficient than space-filling, prior-based designs. }
}


@article{10.1093/biomet/asp028,
    author = {Conti, S. and Gosling, J. P. and Oakley, J. E. and O'Hagan, A.},
    title = "{Gaussian process emulation of dynamic computer codes}",
    journal = {Biometrika},
    volume = {96},
    number = {3},
    pages = {663-676},
    year = {2009},
    month = {06},
    abstract = "{Computer codes are used in scientific research to study and predict the behaviour of complex systems. Their run times often make uncertainty and sensitivity analyses impractical because of the thousands of runs that are conventionally required, so efficient techniques have been developed based on a statistical representation of the code. The approach is less straightforward for dynamic codes, which represent time-evolving systems. We develop a novel iterative system to build a statistical model of dynamic computer codes, which is demonstrated on a rainfall-runoff simulator.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asp028},
    url = {https://doi.org/10.1093/biomet/asp028},
    eprint = {https://academic.oup.com/biomet/article-pdf/96/3/663/709193/asp028.pdf},
}

@article{CONTI2010640,
title = {Bayesian emulation of complex multi-output and dynamic computer models},
journal = {Journal of Statistical Planning and Inference},
volume = {140},
number = {3},
pages = {640-651},
year = {2010},
issn = {0378-3758},
doi = {https://doi.org/10.1016/j.jspi.2009.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0378375809002559},
author = {Stefano Conti and Anthony O’Hagan},
keywords = {Bayesian inference, Computer experiments, Dynamic models, Hierarchical models},
abstract = {Computer models are widely used in scientific research to study and predict the behaviour of complex systems. The run times of computer-intensive simulators are often such that it is impractical to make the thousands of model runs that are conventionally required for sensitivity analysis, uncertainty analysis or calibration. In response to this problem, highly efficient techniques have recently been developed based on a statistical meta-model (the emulator) that is built to approximate the computer model. The approach, however, is less straightforward for dynamic simulators, designed to represent time-evolving systems. Generalisations of the established methodology to allow for dynamic emulation are here proposed and contrasted. Advantages and difficulties are discussed and illustrated with an application to the Sheffield Dynamic Global Vegetation Model, developed within the UK Centre for Terrestrial Carbon Dynamics.}
}

@article{10.1214/009053607000000163,
author = {M. J. Bayarri and D. Walsh and J. O. Berger and J. Cafeo and G. Garcia-Donato and F. Liu and J. Palomo and R. J. Parthasarathy and R. Paulo and J. Sacks},
title = {{Computer model validation with functional output}},
volume = {35},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {1874 -- 1906},
keywords = {Bayesian analysis, bias, Computer models, functional data, uncertain inputs, validation},
year = {2007},
doi = {10.1214/009053607000000163},
URL = {https://doi.org/10.1214/009053607000000163}
}


@article{doi:10.1080/01621459.2014.934453,
author = {Marian Farah and Paul Birrell and Stefano Conti and Daniela De Angelis},
title = {Bayesian Emulation and Calibration of a Dynamic Epidemic Model for A/H1N1 Influenza},
journal = {Journal of the American Statistical Association},
volume = {109},
number = {508},
pages = {1398-1411},
year  = {2014},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2014.934453},
URL = { 
    
        https://doi.org/10.1080/01621459.2014.934453
},
eprint = { 
        https://doi.org/10.1080/01621459.2014.934453
}
}


@article{doi:10.1198/016214507000000888,
author = {Dave Higdon and James Gattiker and Brian Williams and Maria Rightley},
title = {Computer Model Calibration Using High-Dimensional Output},
journal = {Journal of the American Statistical Association},
volume = {103},
number = {482},
pages = {570-583},
year  = {2008},
publisher = {Taylor & Francis},
doi = {10.1198/016214507000000888},
URL = {    
        https://doi.org/10.1198/016214507000000888
},
eprint = { 
    
        https://doi.org/10.1198/016214507000000888
}
}


@Article{acp-11-12253-2011,
AUTHOR = {Lee, L. A. and Carslaw, K. S. and Pringle, K. J. and Mann, G. W. and Spracklen, D. V.},
TITLE = {Emulation of a complex global aerosol model to quantify sensitivity to uncertain parameters},
JOURNAL = {Atmospheric Chemistry and Physics},
VOLUME = {11},
YEAR = {2011},
NUMBER = {23},
PAGES = {12253--12273},
URL = {https://acp.copernicus.org/articles/11/12253/2011/},
DOI = {10.5194/acp-11-12253-2011}
}


@article{10.1214/09-BA415,
author = {Fei Liu and Mike West},
title = {{A dynamic modelling strategy for Bayesian computer model emulation}},
volume = {4},
journal = {Bayesian Analysis},
number = {2},
publisher = {International Society for Bayesian Analysis},
pages = {393 -- 411},
keywords = {Backward sampling, computer model emulation, Dynamic linear model, Forwarding filtering, Gaussian process, Markov chain Monte Carlo, time-varying autoregression},
year = {2009},
doi = {10.1214/09-BA415},
URL = {https://doi.org/10.1214/09-BA415}
}


@article{REICHERT20111638,
title = {Mechanism-based emulation of dynamic simulation models: Concept and application in hydrology},
journal = {Computational Statistics & Data Analysis},
volume = {55},
number = {4},
pages = {1638-1655},
year = {2011},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2010.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167947310003993},
author = {P. Reichert and G. White and M.J. Bayarri and E.B. Pitman},
keywords = {Dynamic model, Emulator, Optimization, Sensitivity analysis, Statistical inference},
abstract = {Many model-based investigation techniques, such as sensitivity analysis, optimization, and statistical inference, require a large number of model evaluations to be performed at different input and/or parameter values. This limits the application of these techniques to models that can be implemented in computationally efficient computer codes. Emulators, by providing efficient interpolation between outputs of deterministic simulation models, can considerably extend the field of applicability of such computationally demanding techniques. So far, the dominant techniques for developing emulators have been priors in the form of Gaussian stochastic processes (GASP) that were conditioned with a design data set of inputs and corresponding model outputs. In the context of dynamic models, this approach has two essential disadvantages: (i) these emulators do not consider our knowledge of the structure of the model, and (ii) they run into numerical difficulties if there are a large number of closely spaced input points as is often the case in the time dimension of dynamic models. To address both of these problems, a new concept of developing emulators for dynamic models is proposed. This concept is based on a prior that combines a simplified linear state space model of the temporal evolution of the dynamic model with Gaussian stochastic processes for the innovation terms as functions of model parameters and/or inputs. These innovation terms are intended to correct the error of the linear model at each output step. Conditioning this prior to the design data set is done by Kalman smoothing. This leads to an efficient emulator that, due to the consideration of our knowledge about dominant mechanisms built into the simulation model, can be expected to outperform purely statistical emulators at least in cases in which the design data set is small. The feasibility and potential difficulties of the proposed approach are demonstrated by the application to a simple hydrological model.}
}


@article{doi:10.1198/106186008X384032,
author = {Jonathan Rougier},
title = {Efficient Emulators for Multivariate Deterministic Functions},
journal = {Journal of Computational and Graphical Statistics},
volume = {17},
number = {4},
pages = {827-843},
year  = {2008},
publisher = {Taylor & Francis},
doi = {10.1198/106186008X384032},
URL = { 
        https://doi.org/10.1198/106186008X384032
},
eprint = {     
        https://doi.org/10.1198/106186008X384032
}
}

@article{doi:10.1137/120900915,
author = {Williamson, Daniel and Blaker, Adam T.},
title = {Evolving Bayesian Emulators for Structured Chaotic Time Series, with Application to Large Climate Models},
journal = {SIAM/ASA Journal on Uncertainty Quantification},
volume = {2},
number = {1},
pages = {1-28},
year = {2014},
doi = {10.1137/120900915},
URL = { 
        https://doi.org/10.1137/120900915
},
eprint = {   
        https://doi.org/10.1137/120900915
},
    abstract = { We develop Bayesian dynamic linear model Gaussian processes for emulation of time series output for computer models that may exhibit chaotic behavior, but where this behavior retains some underlying structure. The statistical technology is particularly suited to emulating the time series output of large climate models that exhibit this feature and where we want samples from the posterior of the emulator to evolve in the same way as dynamic processes in the computer model do. The methodology combines key features of good uncertainty quantification (UQ) methods such as using complex mean functions to capture large-scale signals within parameter space, with dynamic linear models in a way that allows UQ to borrow strength from the Bayesian time series literature. We present an MCMC algorithm for sampling from the posterior of the emulator parameters when the roughness lengths of the Gaussian process are unknown. We discuss an interpretation of the results of this algorithm that allows us to use MCMC to fix the correlation lengths, making future online samples from the emulator tractable when used in practical applications where online MCMC is infeasible. We apply this methodology to emulate the Atlantic Meridional Overturning Circulation (AMOC) as a time series output of the fully coupled non--flux-adjusted atmosphere-ocean general circulation model HadCM3. }
}


@Article{psf2021003011,
AUTHOR = {Albert, Christopher G. and Callies, Ulrich and Toussaint, Udo von},
TITLE = {Surrogate-Enhanced Parameter Inference for Function-Valued Models},
JOURNAL = {Physical Sciences Forum},
VOLUME = {3},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {11},
URL = {https://www.mdpi.com/2673-9984/3/1/11},
ISSN = {2673-9984},
ABSTRACT = {We present an approach to enhance the performance and flexibility of the Bayesian inference of model parameters based on observations of the measured data. Going beyond the usual surrogate-enhanced Monte-Carlo or optimization methods that focus on a scalar loss, we place emphasis on a function-valued output of a formally infinite dimension. For this purpose, the surrogate models are built on a combination of linear dimensionality reduction in an adaptive basis of principal components and Gaussian process regression for the map between reduced feature spaces. Since the decoded surrogate provides the full model output rather than only the loss, it is re-usable for multiple calibration measurements as well as different loss metrics and, consequently, allows for flexible marginalization over such quantities and applications to Bayesian hierarchical models. We evaluate the method&rsquo;s performance based on a case study of a toy model and a simple riverine diatom model for the Elbe river. As input data, this model uses six tunable scalar parameters as well as silica concentrations in the upper reach of the river together with the continuous time-series of temperature, radiation, and river discharge over a specific year. The output consists of continuous time-series data that are calibrated against corresponding measurements from the Geesthacht Weir station at the Elbe river. For this study, only two scalar inputs were considered together with a function-valued output and compared to an existing model calibration using direct simulation runs without a surrogate.},
DOI = {10.3390/psf2021003011}
}

@article{LEBEL2019158,
title = {Statistical inverse identification for nonlinear train dynamics using a surrogate model in a Bayesian framework},
journal = {Journal of Sound and Vibration},
volume = {458},
pages = {158-176},
year = {2019},
issn = {0022-460X},
doi = {https://doi.org/10.1016/j.jsv.2019.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S0022460X19303633},
author = {D. Lebel and C. Soize and C. Fünfschilling and G. Perrin},
keywords = {Statistical inverse problem, Bayesian calibration, Surrogate model, High-speed train dynamics, Uncertainty quantification},
abstract = {This paper presents a Bayesian calibration method for a simulation-based model with stochastic functional input and output. The originality of the method lies in an adaptation involving the representation of the likelihood function by a Gaussian process surrogate model, to cope with the high computational cost of the simulation, while avoiding the surrogate modeling of the functional output. The adaptation focuses on taking into account the uncertainty introduced by the use of a surrogate model when estimating the parameters posterior probability distribution by MCMC. To this end, trajectories of the random surrogate model of the likelihood function are drawn and injected in the MCMC algorithm. An application on a train suspension monitoring case is presented.}
}

@misc{ranjan2016inverse,
      title={Inverse problem for time-series valued computer model via scalarization}, 
      author={Pritam Ranjan and Mark Thomas and Holger Teismann and Sujay Mukhoti},
      year={2016},
      eprint={1605.09503},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}


@article{doi:10.1080/00401706.2013.775897,
author = { Matthew T.   Pratola  and  Stephan R.   Sain  and  Derek   Bingham  and  Michael   Wiltberger  and  E.   Joshua   Rigler },
title = {Fast Sequential Computer Model Calibration of Large Nonstationary Spatial-Temporal Processes},
journal = {Technometrics},
volume = {55},
number = {2},
pages = {232-242},
year  = {2013},
publisher = {Taylor & Francis},
doi = {10.1080/00401706.2013.775897},
URL = { 
        https://doi.org/10.1080/00401706.2013.775897
},
eprint = { 
    
        https://doi.org/10.1080/00401706.2013.775897
}
}

@article{PERRIN2020106728,
title = {Adaptive calibration of a computer code with time-series output},
journal = {Reliability Engineering & System Safety},
volume = {196},
pages = {106728},
year = {2020},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2019.106728},
url = {https://www.sciencedirect.com/science/article/pii/S0951832018311232},
author = {G. Perrin},
keywords = {Bayesian framework, Computer experiment, Dynamic simulator, Gaussian process, Multi-output},
abstract = {Simulation plays a major role in the conception, the optimization and the certification of complex systems. Of particular interest here is the calibration of the parameters of computer models from high-dimensional physical observations. When the run times of these computer codes is high, this work focuses on the numerical challenges associated with the statistical inference. In particular, several adaptations of the Gaussian Process Regression (GPR) to the high-dimensional or functional output case are presented for the emulation of computer codes from limited data. Then, an adaptive procedure is detailed to minimize the calibration parameters uncertainty at the minimal computational cost. The proposed method is eventually applied to two applications that are based on dynamic simulators.}
}


