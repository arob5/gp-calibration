\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Local custom commands. 
\include{local-defs}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{Gaussian Process Accelerated MCMC Algorithm}
\author{Andrew Roberts}

\begin{document}

% Setup and Notation
\section{Setup and Notation}
We begin by briefly introducing the statistical calibration model for parameter calibration. Let 
\begin{align*}
\fwd: \R^{\Npar} \to \R^{\Ntime \times \Nobj}
\end{align*}
denote the forward model which maps unknown calibration parameters $\bpar \in \parSpace \subseteq \R^{\Npar}$ to model predictions 
$\fwd(\bpar) \in \R^{\Ntime \times \Nobj}$. The outputs consist of time series for $\Nobj$ different outputs, each of length $\Ntime$. 
Individual outputs, corresponding to columns of the matrix $\fwd(\bpar)$, are denoted by $\indexObj{\fwd}(\bpar)$. 
The task is to infer the value of the parameters $\bpar$ by comparing predictions $\fwd(\bpar)$ to noisy 
observations $\{\indexObj{\bstate}\}_{\objIdx=1}^{\Nobj}$ of the true system being modeled, with observation dimensions 
$\indexObj{\bstate} \in \R^{\indexObj{\Ntime}}$ potentially varying due to missing data. We write 
$\stateMat := \{\indexObj[1]{\bstate}, \dots, \indexObj[\Nobj]{\bstate} \}$ to denote all observed data. 

We connect the observations to the model predictions via the (log) likelihood 
\begin{align}
\llik(\bpar, \CovObs) 
&:= \log p(\stateMat|\bpar, \CovObs) \\
&= \log \prod_{\objIdx=1}^{\Nobj} \Gaussian(\indexObj{\bstate} | \indexObj{\fwd}(\bpar), \sdObs^2_{\objIdx}) \\
&= -\frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \indexObj{\Ntime} \log(2\pi \sdObs^2_{\objIdx}) - \frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \frac{\indexObj{\SSR}(\bpar)}{\sdObs^2_{\objIdx}}
\end{align}
where we denote the \textit{model-data misfit} by 
\begin{align}
\indexObj{\SSR}(\bpar) := \norm{\indexObj{\bstate} - \indexObj{\fwd}(\bpar)}_2^2,
\end{align}
 and write $\CovObs := \{\sdObs^2_1, \dots, \sdObs^2_{\Nobj}\}$ to denote the variance parameters for each output. 
 
 The model-data misfit functions $\indexObj{\SSR}$ are emulated by independent GPs
 \begin{align}
&\SSRVecPredOut{\Ndesign}{\objIdx} \overset{ind}{\sim} \GP(\GPMeanPredOut{\Ndesign}{\objIdx}, \GPKerPredOut{\Ndesign}{\objIdx}), &&\objIdx = 1, \dots, \Nobj,
 \end{align}
 where the subscript $\Ndesign$ indicates a GP predictive distribution, conditional on a design dataset consisting of $\Ndesign$ input-output data pairs. We will write 
 $\indexDesign[\Ndesign]{\SSR} := \left[\SSRVecPredOut{\Ndesign}{1}, \dots, \SSRVecPredOut{\Ndesign}{\Nobj}\right]^\top$ when referencing all of the GPs, which can 
 also be thought of as a single, multi-output GP with independent covariance structure across outputs. 
 
Finally, we consider priors on $\bpar$ and $\CovObs$. The former is left arbitrary, with prior density denoted by $\priorDens(\bpar)$. 
The variance parameters $\sdObs_{\objIdx}^2$ are assigned inverse gamma priors $\sdObs_{\objIdx}^2 \overset{ind}{\sim} \mathcal{IG}(\indexObj{\IGShape}, \indexObj{\IGScale})$ so the
prior density can be written, 
\begin{align}
\priorDens(\CovObs) 
&= \prod_{\objIdx = 1}^{\Nobj} \mathcal{IG}(\sdObs_{\objIdx}^2|\indexObj{\IGShape}, \indexObj{\IGScale}). \label{inv_gamma_prior} \\
&= \prod_{\objIdx = 1}^{\Nobj} \frac{\left[ \indexObj{\IGScale}\right]^{\indexObj{\IGShape}}}{\Gamma(\indexObj{\IGShape})} \left(\frac{1}{\sdObs^2_{\objIdx}}\right)^{\indexObj{\IGShape}+1} 
\exp\left\{-\frac{\indexObj{\IGScale}}{\sdObs^2_{\objIdx}} \right\}. \nonumber
\end{align}

% MCMC Algorithm
\section{MCMC Algorithm}
Replacing the true model-data misfits with the GP approximation $\indexDesign[\Ndesign]{\SSR} $ results in a method to approximately sample from the posterior 
distribution $p(\bpar, \CovObs | \stateMat)$, while significantly accelerating the computation. Given that the emulator induces approximation error, we seek to 
propagate the uncertainty in $\indexDesign[\Ndesign]{\SSR}$ in order to prevent overconfidence in the posterior samples. To this end, we treat $\indexDesign[\Ndesign]{\SSR}$
as another variable to be explored in the parameter space; i.e. the posterior over this extended parameter space becomes 
$p(\bpar, \CovObs, \indexDesign[\Ndesign]{\SSR}(\bpar) | \stateMat)$. The joint distribution over all unknowns is thus 
\begin{align*}
&p(\bpar, \CovObs, \indexDesign[\Ndesign]{\SSR}(\bpar), \stateMat) = 
p(\stateMat | \bpar, \CovObs, \indexDesign[\Ndesign]{\SSR}(\bpar))p(\indexDesign[\Ndesign]{\SSR}(\bpar) | \bpar) \priorDens(\bpar) \priorDens(\CovObs) \\
&= \priorDens(\bpar) \prod_{\objIdx=1}^{\Nobj} \left[(2\pi\sdObs^2_{\objIdx})^{-\indexObj{\Ntime}/2} \exp\left\{-\frac{\SSRVecPredOut{\Ndesign}{\objIdx}(\bpar)}{2\sdObs^2_{\objIdx}} \right\} 
\Gaussian\left(\SSRVecPredOut{\Ndesign}{\Nobj}(\bpar) | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right) \mathcal{IG}(\sdObs^2_{\objIdx}| \indexObj{\IGShape}, \indexObj{\IGScale}) \right] 
\end{align*}

In the algorithms detailed below, we denote $\bphi := \indexDesign[\Ndesign]{\SSR}(\bpar)$, so that the posterior density is then $p(\bpar, \CovObs, \bphi | \stateMat)$. This notation suppresses 
the functional dependence on $\bpar$, but makes it more clear that we are simply considering $\bphi$ to be another parameter in the parameter space, which happens to be strongly 
related to $\bpar$ via the conditionals
\begin{align*}
&p(\indexObj{\phi} | \bpar) = \Gaussian\left(\indexObj{\phi} | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar) \right), &&\objIdx = 1, \dots, \Nobj.
\end{align*}
The joint distribution over all unknowns can thus be written as
\begin{align}
&p(\bpar, \CovObs, \bphi, \stateMat) = 
p(\stateMat | \bpar, \CovObs, \bphi)p(\bphi | \bpar) \priorDens(\bpar) \priorDens(\CovObs) \\
&= \priorDens(\bpar) \prod_{\objIdx=1}^{\Nobj} \left[(2\pi\sdObs^2_{\objIdx})^{-\indexObj{\Ntime}/2} \exp\left\{-\frac{\indexObj{\phi} }{2\sdObs^2_{\objIdx}} \right\} 
\Gaussian\left(\indexObj{\phi}  | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right) \mathcal{IG}(\sdObs^2_{\objIdx}| \indexObj{\IGShape}, \indexObj{\IGScale}) \right] \nonumber
\end{align}

The below sections detail a Metropolis-within-Gibbs (MwG) scheme for sampling from this posterior. 

% Gibbs Step for phi
\subsection{Gibbs Step for $\bphi$}
We consider an alternative update for $\bphi$; namely, a Gibbs update. The conditional posterior for $\bphi$ is given by 
\begin{align*}
p(\bphi | \bpar, \CovObs, \stateMat) 
&\propto \prod_{\objIdx=1}^{\Nobj} \exp\left\{-\frac{\indexObj{\phi}}{2\sdObs^2_{\objIdx}} \right\} 
	\Gaussian\left(\indexObj{\phi} | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right) \\
&\propto \prod_{\objIdx=1}^{\Nobj} \exp\left\{-\frac{1}{2} \frac{(\indexObj{\phi} - \indexObj{a}(\bpar))^2}{\GPKerPredOut{\Ndesign}{\objIdx}(\bpar)} \right\} \\
&\propto \prod_{\objIdx=1}^{\Nobj} \Gaussian\left(\indexObj{\phi} | \indexObj{a}_{\Ndesign}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right)
\end{align*}
where $\indexObj{a}_{\Ndesign}(\bpar) := \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar) - \frac{1}{2}\frac{\GPKerPredOut{\Ndesign}{\objIdx}(\bpar)}{\sdObs^2_{\objIdx}}$. We thus see that 
the conditional distribution for $\bphi$ is given by another GP, with the same variance as before, but with the mean function decreased by an additive factor depending on the 
ratio of the GP uncertainty $\GPKerPredOut{\Ndesign}{\objIdx}(\bpar)$ and the data likelihood noise $\sdObs^2_{\objIdx}$. We note that, 
\begin{align*}
p(\indexObj{\phi} | \bpar, \CovObs, \stateMat) \to \delta(\indexObj{\phi} - \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar)) \text{ as } \GPKerPredOut{\Ndesign}{\objIdx}(\bpar) \to 0.
\end{align*}
This makes intuitive sense: if there is no uncertainty about the model-data misfit value, then the conditional draw will simply be the GP prediction $\GPMeanPredOut{\Ndesign}{\objIdx}(\bpar)$.
Similarly, 
\begin{align*}
p(\indexObj{\phi} | \bpar, \CovObs, \stateMat) \to \Gaussian(\indexObj{\phi}|\GPMeanPredOut{\Ndesign}{\objIdx}(\bpar) , \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)) \text{ as } \sdObs^2_{\objIdx} \to \infty.
\end{align*}
That is, in the case where the likelihood is essentially pure noise, then the conditional draw will be sampled from the GP $\SSRVecPredOut{\Ndesign}{\objIdx}(\bpar)$. In general, the 
conditional for $\bphi$ balances the data fit with the GP predictive uncertainty.

\subsection{Block $(\bpar, \bphi)$ update.}
We consider a block Metropolis step for $\bpar$ and $\bphi$ jointly. Let $\propDens\left([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}] \right)$ be the density for the proposal distribution for 
proposing $[\tilde{\bpar}, \tilde{\bphi}]$ given current state $[\bpar, \bphi]$. This yields a MH acceptance probability
\begin{align*}
\accProbMH([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}]) 
&= \max\left\{1,  \frac{p(\tilde{\bpar}, \tilde{\bphi}|\CovObs, \stateMat)\propDens\left([\tilde{\bpar}, \tilde{\bphi}], [\bpar, \bphi] \right)}{p(\bpar, \bphi|\CovObs, \stateMat) \propDens\left([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}] \right)} \right\},
\end{align*}
where 
\begin{align*}
p(\bpar, \bphi|\CovObs, \stateMat) 
&\propto \priorDens(\bpar) \exp\left\{-\frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \frac{\indexObj{\phi}}{\sdObs^2_{\objIdx}} \right\} 
 \prod_{\objIdx=1}^{\Nobj} \Gaussian\left(\indexObj{\phi} | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right) \\
&\propto \priorDens(\bpar) \exp\left\{-\frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \left[\frac{\indexObj{\phi}}{\sdObs^2_{\objIdx}} + \frac{(\indexObj{\phi} - \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar))^2}{\GPKerPredOut{\Ndesign}{\objIdx}(\bpar)} \right]  \right\}
	\prod_{\objIdx=1}^{\Nobj} \det\left(\GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right)^{-1/2}
\end{align*}
Specific proposal distributions are discussed below. 

\subsubsection{Proposal Option 1}
We first consider the straightforward approach of first sampling a proposal $\tilde{\bpar}$ from a Gaussian proposal, and then proposing $\tilde{\bphi}$ by sampling from the 
GP predictive distribution conditional on $\tilde{\bphi}$: 
\begin{align*}
\tilde{\bpar} &\sim \Gaussian(\bpar, \CovProp) \\
\indexObj{\tilde{\phi}}|\tilde{\bpar} &\overset{ind}{\sim} \Gaussian\left(\GPMeanPredOut{\Ndesign}{\objIdx}(\tilde{\bpar}), \GPKerPredOut{\Ndesign}{\objIdx}(\tilde{\bpar})\right).
\end{align*}
Here, $\CovProp$ is some $\Npar \times \Npar$ proposal covariance. This choice of proposal leads to cancellation of many of the terms in the MH acceptance ratio, yielding
\begin{align*}
\accProbMH([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}]) 
&= \max\left\{1, \exp\left\{\frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \left(\frac{ \indexObj{\phi} - \indexObj{\tilde{\phi}}}{\sdObs^2_{\objIdx}}\right)\right\} \cdot \frac{\priorDens(\tilde{\bpar})}{\priorDens(\bpar)} \right\}
\end{align*}

\subsubsection{Proposal Option 2:}
We next consider adjusting the above proposal so that $\tilde{\bphi}$ is proposed from the conditional posterior $p(\tilde{\bphi}|\tilde{\bpar}, \CovObs, \stateMat)$ rather than the 
conditional prior $p(\tilde{\bphi}|\tilde{\bpar})$:
\begin{align*}
\tilde{\bpar} &\sim \Gaussian(\bpar, \CovProp) \\
\indexObj{\tilde{\phi}}|\tilde{\bpar} &\overset{ind}{\sim} \Gaussian\left(\indexObj{a}_{\Ndesign}(\tilde{\bpar}), \GPKerPredOut{\Ndesign}{\objIdx}(\tilde{\bpar})\right), 
\end{align*}
where $\indexObj{a}_{\Ndesign}(\tilde{\bpar})$ is the same mean function defined above. With this choice the acceptance ratio simplifies to 
\begin{align*}
\accProbMH([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}]) 
&= \max\left\{1, \exp\left(\frac{1}{8}  \sum_{\objIdx=1}^{\Nobj} \frac{\GPKerPredOut{\Ndesign}{\objIdx}(\tilde{\bpar}) - \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)}{\sigma^2_{\objIdx}} \right) \cdot \frac{\priorDens(\tilde{\bpar})}{\priorDens(\bpar)} \right\}.
\end{align*}


% MH Step for u
\subsection{MH Step for $\bpar$}
In the case that a Gibbs step is used for $\bphi$, then a MH step may be used to update $\bpar$. The conditional posterior is 
\begin{align*}
p(\bpar | \bphi, \CovObs, \stateMat) 
&\propto \priorDens(\bpar) \prod_{\objIdx=1}^{\Nobj} \Gaussian\left(\indexObj{\phi} | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar)), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar))\right).
\end{align*}


% Gibbs Step for CovObs
\subsection{Gibbs Step for $\CovObs$}
The inverse gamma priors on $\CovObs$ yield conditional conjugacy. Indeed, the conditional posterior is given by 
\begin{align*}
p(\CovObs | \bpar, \bphi, \stateMat) 
&\propto \prod_{\objIdx=1}^{\Nobj} \left[(2\pi\sdObs^2_{\objIdx})^{-\indexObj{\Ntime}/2} \exp\left\{-\frac{\indexObj{\phi} }{2\sdObs^2_{\objIdx}} \right\} 
\mathcal{IG}(\sdObs^2_{\objIdx}| \indexObj{\IGShape}, \indexObj{\IGScale}) \right] \\
&\propto \prod_{\objIdx=1}^{\Nobj} \left[\left(\frac{1}{\sdObs^2_{\objIdx}}\right)^{\indexObj{\Ntime}/2} \exp\left\{-\frac{\indexObj{\phi} }{2\sdObs^2_{\objIdx}} \right\} 
 \left(\frac{1}{\sdObs^2_{\objIdx}}\right)^{\indexObj{\IGShape}+1} \exp\left\{-\frac{\indexObj{\IGScale}}{\sdObs^2_{\objIdx}} \right\}\right] \\
 &= \prod_{\objIdx=1}^{\Nobj} \left(\frac{1}{\sdObs^2_{\objIdx}}\right)^{\indexObj{\IGShape}+\indexObj{\Ntime}/2+1} \exp\left\{-\frac{\indexObj{\IGScale} + \indexObj{\phi}/2}{\sdObs^2_{\objIdx}} \right\} \\
 &\propto \prod_{\objIdx=1}^{\Nobj} \mathcal{IG}\left(\sdObs^2_{\objIdx} \bigg| \indexObj{\IGShape} + \frac{\indexObj{\Ntime}}{2}, \indexObj{\IGScale} + \frac{\indexObj{\phi}}{2} \right).
\end{align*}


% MCMC Algorithm: Marginal Likelihood Approach
% \section{MCMC Algorithm: Marginal Likelihood Approach}

% Numerical Experiments
\section{Numerical Experiments}
\begin{enumerate}
\item Vary dimension of parameter space
\item Vary number of design points (noisy vs. precise GP emulator)
\end{enumerate}



\end{document}



