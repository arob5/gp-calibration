\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Local custom commands. 
\include{local-defs}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{Gaussian Process Accelerated MCMC Algorithm}
\author{Andrew Roberts}

\begin{document}

% Setup and Notation
\section{Setup and Notation}
We begin by briefly introducing the statistical calibration model for parameter calibration. Let 
\begin{align*}
\fwd: \R^{\Npar} \to \R^{\Ntime \times \Nobj}
\end{align*}
denote the forward model which maps unknown calibration parameters $\bpar \in \parSpace \subseteq \R^{\Npar}$ to model predictions 
$\fwd(\bpar) \in \R^{\Ntime \times \Nobj}$. The outputs consist of time series for $\Nobj$ different outputs, each of length $\Ntime$. 
Individual outputs, corresponding to columns of the matrix $\fwd(\bpar)$, are denoted by $\indexObj{\fwd}(\bpar)$. 
The task is to infer the value of the parameters $\bpar$ by comparing predictions $\fwd(\bpar)$ to noisy 
observations $\{\indexObj{\bstate}\}_{\objIdx=1}^{\Nobj}$ of the true system being modeled, with observation dimensions 
$\indexObj{\bstate} \in \R^{\indexObj{\Ntime}}$ potentially varying due to missing data. We write 
$\stateMat := \{\indexObj[1]{\bstate}, \dots, \indexObj[\Nobj]{\bstate} \}$ to denote all observed data. 

We connect the observations to the model predictions via the (log) likelihood 
\begin{align}
\llik(\bpar, \CovObs) 
&:= \log p(\stateMat|\bpar, \CovObs) \\
&= \log \prod_{\objIdx=1}^{\Nobj} \Gaussian(\indexObj{\bstate} | \indexObj{\fwd}(\bpar), \sdObs^2_{\objIdx}) \\
&= -\frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \indexObj{\Ntime} \log(2\pi \sdObs^2_{\objIdx}) - \frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \frac{\indexObj{\SSR}(\bpar)}{\sdObs^2_{\objIdx}}
\end{align}
where we denote the \textit{model-data misfit} by 
\begin{align}
\indexObj{\SSR}(\bpar) := \norm{\indexObj{\bstate} - \indexObj{\fwd}(\bpar)}_2^2,
\end{align}
 and write $\CovObs := \{\sdObs^2_1, \dots, \sdObs^2_{\Nobj}\}$ to denote the variance parameters for each output. 
 
 The model-data misfit functions $\indexObj{\SSR}$ are emulated by independent GPs
 \begin{align}
&\SSRVecPredOut{\Ndesign}{\objIdx} \overset{ind}{\sim} \GP(\GPMeanPredOut{\Ndesign}{\objIdx}, \GPKerPredOut{\Ndesign}{\objIdx}), &&\objIdx = 1, \dots, \Nobj,
 \end{align}
 where the subscript $\Ndesign$ indicates a GP predictive distribution, conditional on a design dataset consisting of $\Ndesign$ input-output data pairs. We will write 
 $\indexDesign[\Ndesign]{\SSR} := \left[\SSRVecPredOut{\Ndesign}{1}, \dots, \SSRVecPredOut{\Ndesign}{\Nobj}\right]^\top$ when referencing all of the GPs, which can 
 also be thought of as a single, multi-output GP with independent covariance structure across outputs. 
 
Finally, we consider priors on $\bpar$ and $\CovObs$. The former is left arbitrary, with prior density denoted by $\priorDens(\bpar)$. 
The variance parameters $\sdObs_{\objIdx}^2$ are assigned inverse gamma priors $\sdObs_{\objIdx}^2 \overset{ind}{\sim} \mathcal{IG}(\indexObj{\IGShape}, \indexObj{\IGScale})$ so the
prior density can be written, 
\begin{align}
\priorDens(\CovObs) 
&= \prod_{\objIdx = 1}^{\Nobj} \mathcal{IG}(\sdObs_{\objIdx}^2|\indexObj{\IGShape}, \indexObj{\IGScale}). \label{inv_gamma_prior} \\
&= \prod_{\objIdx = 1}^{\Nobj} \frac{\left[ \indexObj{\IGScale}\right]^{\indexObj{\IGShape}}}{\Gamma(\indexObj{\IGShape})} \left(\frac{1}{\sdObs^2_{\objIdx}}\right)^{\indexObj{\IGShape}+1} 
\exp\left\{-\frac{\indexObj{\IGScale}}{\sdObs^2_{\objIdx}} \right\}. \nonumber
\end{align}

% MCMC Algorithm
\section{MCMC Algorithm}
Replacing the true model-data misfits with the GP approximation $\indexDesign[\Ndesign]{\SSR} $ results in a method to approximately sample from the posterior 
distribution $p(\bpar, \CovObs | \stateMat)$, while significantly accelerating the computation. Given that the emulator induces approximation error, we seek to 
propagate the uncertainty in $\indexDesign[\Ndesign]{\SSR}$ in order to prevent overconfidence in the posterior samples. To this end, we treat $\indexDesign[\Ndesign]{\SSR}$
as another variable to be explored in the parameter space; i.e. the posterior over this extended parameter space becomes 
$p(\bpar, \CovObs, \indexDesign[\Ndesign]{\SSR}(\bpar) | \stateMat)$. The joint distribution over all unknowns is thus 
\begin{align*}
&p(\bpar, \CovObs, \indexDesign[\Ndesign]{\SSR}(\bpar), \stateMat) = 
p(\stateMat | \bpar, \CovObs, \indexDesign[\Ndesign]{\SSR}(\bpar))p(\indexDesign[\Ndesign]{\SSR}(\bpar) | \bpar) \priorDens(\bpar) \priorDens(\CovObs) \\
&= \priorDens(\bpar) \prod_{\objIdx=1}^{\Nobj} \left[(2\pi\sdObs^2_{\objIdx})^{-\indexObj{\Ntime}/2} \exp\left\{-\frac{\indexDesign[\Ndesign]{\SSR}(\bpar)}{2\sdObs^2_{\objIdx}} \right\} 
\Gaussian\left(\indexDesign[\Ndesign]{\SSR}(\bpar) | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right) \mathcal{IG}(\sdObs^2_{\objIdx}| \indexObj{\IGShape}, \indexObj{\IGScale}) \right] 
\end{align*}

In the algorithms detailed below, we denote $\bphi := \indexDesign[\Ndesign]{\SSR}(\bpar)$, so that the posterior density is then $p(\bpar, \CovObs, \bphi | \stateMat)$. This notation suppresses 
the functional dependence on $\bpar$, but makes it more clear that we are simply considering $\bphi$ to be another parameter in the parameter space, which happens to be strongly 
related to $\bpar$. The below sections detail a Metropolis-within-Gibbs (MwG) scheme for sampling from this posterior. 

\subsection{Block $(\bpar, \bphi)$ update.}
We consider a block Metropolis step for $\bpar$ and $\bphi$ jointly. Let $\propDens\left([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}] \right)$ be the density for the proposal distribution for 
proposing $[\tilde{\bpar}, \tilde{\bphi}]$ given current state $[\bpar, \bphi]$. This yields a MH acceptance probability
\begin{align*}
\accProbMH([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}]) 
&= \max\left\{1,  \frac{p(\tilde{\bpar}, \tilde{\bphi}|\CovObs, \stateMat)\propDens\left([\tilde{\bpar}, \tilde{\bphi}], [\bpar, \bphi] \right)}{p(\bpar, \bphi|\CovObs, \stateMat) \propDens\left([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}] \right)} \right\},
\end{align*}
where 
\begin{align*}
p(\bpar, \bphi|\CovObs, \stateMat) 
&\propto \priorDens(\bpar) \prod_{\objIdx=1}^{\Nobj} \left[\exp\left\{-\frac{\indexObj{\phi}}{2\sdObs^2_{\objIdx}} \right\} 
\Gaussian\left(\bphi | \GPMeanPredOut{\Ndesign}{\objIdx}(\bpar), \GPKerPredOut{\Ndesign}{\objIdx}(\bpar)\right) \right].
\end{align*}
Specific proposal distributions are discussed below. 

\subsubsection{Proposal Option 1}
We first consider the straightforward approach of first sampling a proposal $\tilde{\bpar}$ from a Gaussian proposal, and then proposing $\tilde{\bphi}$ by sampling from the 
GP predictive distribution conditional on $\tilde{\bphi}$: 
\begin{align*}
\tilde{\bpar} &\sim \Gaussian(\bpar, \CovProp) \\
\indexObj{\tilde{\phi}}|\tilde{\bpar} &\overset{ind}{\sim} \Gaussian\left(\GPMeanPredOut{\Ndesign}{\objIdx}(\tilde{\bpar}), \GPKerPredOut{\Ndesign}{\objIdx}(\tilde{\bpar})\right).
\end{align*}
Here, $\CovProp$ is some $\Npar \times \Npar$ proposal covariance. This choice of proposal yields to cancellation of many of the terms in the MH acceptance ratio, yielding
\begin{align*}
\accProbMH([\bpar, \bphi], [\tilde{\bpar}, \tilde{\bphi}]) 
&= \max\left\{1, \exp\left\{\frac{1}{2} \sum_{\objIdx=1}^{\Nobj} \left(\frac{ \indexObj{\phi} - \indexObj{\tilde{\phi}}}{\sdObs^2_{\objIdx}}\right)\right\} \cdot \frac{\priorDens(\tilde{\bpar})}{\priorDens(\bpar)} \right\}
\end{align*}

\subsubsection{Proposal Option 2: Taking advantage of GP Predictive Correlation}
We now try to obtained a better unformed proposal for $\tilde{\bphi}$ by leveraging the GP predictive correlation. 
\begin{align*}
\tilde{\bpar} &\sim \Gaussian(\bpar, \CovProp) \\
\left[\indexObj{\phi}_1, \indexObj{\tilde{\phi}}\right]|\left[\bpar, \tilde{\bpar}\right] &\overset{ind}{\sim} \Gaussian\left(\GPMeanPredOut{\Ndesign}{\objIdx}(\left[\bpar, \tilde{\bpar}\right]), \GPKerPredOut{\Ndesign}{\objIdx}(\left[\bpar, \tilde{\bpar}\right])\right).
\end{align*}
The sample $\indexObj{\phi}_1$ is simply discarded. 

% Gibbs Step for CovObs
\subsection{Gibbs Step for $\CovObs$}

 % Additional Gibbs Step for phi
\subsection{Additional Gibbs Step for $\bphi$}



% MCMC Algorithm: Marginal Likelihood Approach
\section{MCMC Algorithm: Marginal Likelihood Approach}




\end{document}



