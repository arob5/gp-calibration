\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,commentsnumbered,titlenotnumbered]{algorithm2e}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\def\R{\mathbb{R}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}} % For lines in matrix to represent columns
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}} % For lines in matrix to represent rows

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{notation}{Notation}

\begin{document}

\begin{center}
\Large
Questions on GP Emulation/Calibration Methodology 
\end{center}

\section{Methodological Foundations}
I have been using Robert Gramacy's free online \href{https://bobby.gramacy.com/surrogates/}{textbook} on GPs and surrogate modeling as a primary reference on calibration of 
computer models. It is quite recent and nicely synthesizes many of the important papers on the subject. I do use my own notation here though, as I find that his can contain a somewhat
excessive number of sub and superscripts. I'll just walk through my understanding of the methodology, asking questions along the way. 

\subsection{Defining the Parameters of Interest}
The \textit{computer model} (i.e. \textit{simulator} or \textit{process-based model}, as referred to in the PEcAn papers) is deterministic and hence can be modeled as a function
$f: \mathcal{P} \to \R$, where $\mathcal{P} \subset \R^d$ is the parameter space of the computer model. For now I am assuming scalar output for simplicity, although I know that 
most of the PEcAn models have many outputs. The Kennedy and O'Hagan calibration framework (summarized in Gramacy's book) distinguishes between two types of parameters, so 
that 
\[\mathcal{P} = \mathcal{X} \times \mathcal{U}\]
where $\mathcal{X}$ is the space of \textit{observational parameters} and $\mathcal{U}$ the space of \textit{calibration parameters}. The former refers to those parameters that are 
observed in the real-world data and can also be included in the computer model. The calibration parameters cannot be observed in the real-world; this can mean that they have no 
real-world meaning (e.g. the mesh size in the computer model) or that they do exist in the real-world but cannot be directly observed. To my understanding, the observation parameters
are just like covariates in a typical regression, in the sense that the analysis will be conducted conditional on the values of the observation parameters. The calibration parameters are 
the true objects of interest; we seek to tune these parameters using field data as well as understand the uncertainty in the computer model as a function of the calibration parameters. 

\subsubsection{Questions}
\begin{itemize}
\item Is the distinction between observation and calibration parameters relevant for the PEcAn models? My understanding is that what you refer to as \textit{process-model parameters}
refers to calibration parameters. I would assume there is also some notion of observation parameters. \\
\textbf{Answer: } Yes, the distinction is relevant, but typically don't have well-constrained observable parameters. Looking at the code should help clear up how these are treated. 
\end{itemize}

\subsection{Statistical Model Relating Computer Simulation and Observational Data}
I have already defined the computer model $f$, and I will denote the outputs of this model as $y = f(x, u)$, for parameter values $(x, u) \in \mathcal{X} \times \mathcal{U} = \mathcal{P}$.
The real interest lies with the actual physical process that the computer model seeks to replicate. I will denote the value of this physical process at $x \in \mathcal{X}$ by $z^*(x)$. 
However, the field observations of this process - which I denote by $z(x)$ - are noisy. We thus assume a typical Gaussian noise model for these observations. 
\[z(x) = z^*(x) + \epsilon, \qquad \epsilon \overset{iid}{\sim} N(0, \tau^{-1})\]  
parameterized with respect to the precision parameter $\tau$, the inverse of the variance. Kennedy and O'Hagan then relate the physical process to the computer model via 
\[z^*(x) = f(x, u) + b(x)\]
where $b(\cdot)$ is a discrepancy term or ``bias''. My understanding of the current PEcAn approach is to set $b \equiv 0$, which assumes that the computer model is faithful to the physical
process (when calibrated correctly). The ``$u$'' in the above expression can thus be interpreted as the ``true'' or ``correct''  value of the calibration parameters, though I don't think this 
point is especially necessary in a Bayesian framework. 

To summarize, the Kennedy and O'Hagan model is 
\[z(x) = z^*(x) + \epsilon = f(x, u) + b(x) + \epsilon, \qquad \epsilon \overset{iid}{\sim} N(0, \tau^{-1})\] 
and assume we have observational data $\{(x_i, z_i)\}_{i = 1}^{n}$. Let $z := (z_1, \dots, z_n)^T$. 

For the remainder of this document I will set the discrepancy to $0$, as I believe that's what is done in PEcAn, which gives the working model: 
\[z_i|x_i, u \overset{ind}{\sim} N(y_i^u, \tau^{-1}), \qquad i = 1, \dots, n \]
where $y_i^u := f(x_i, u)$. 

\subsubsection{Questions}
\begin{itemize}
\item Am I correct in assuming that you are using the above model with discrepancy $b \equiv 0$? \\
\textbf{Answer: } Yes, this is correct. The future possibility of including a discrepancy term is mentioned in section 4.2 of Fer et al (2018). 
\end{itemize}

\subsection{``Brute Force'' Calibration}
You mention a brute force calibration strategy in your paper, and I just wanted to write that out below to make sure I'm on the right page. The current parameters of interest are
$u$ and $\tau$. We therefore have posterior (conditional on field observations), 
\[p(u, \tau|z) \propto p(z|u, \tau)p(u, \tau) = N_n(z|y^u, \tau^{-1} I_n)p(u, \tau)\]
for some assumed prior on $(u, \tau)$ and where $y^u := (y_1^u, \dots, y_n^u)$. Everything here is implicitly conditional on $x_1, \dots, x_n$ but I will suppress this to simplify notation. 
We can use MCMC to sample from this posterior. However, the key observation is that evaluating the likelihood $N_n(z|y^u, \tau^{-1} I_n)$ requires the computation of $y^u$, which 
involves running the entire simulation with the current calibration $u$. Therefore, the computer model must be run in full at every single step of MCMC, 
which is infeasible for computationally expensive simulations. 

\subsection{Emulator Methodology: ``Modular Approach''}
To deal with the computational issue in the brute force approach, we replace the computer model with a GP emulator/surrogate $\hat{f}(\cdot) \sim \mathcal{GP}(\mu(\cdot), k(\cdot, \cdot))$. 
Among the various emulator calibration approaches, a simple one is the ``modular'' approach described in Gramacy 8.1.2 and originally in 
\href{https://projecteuclid.org/journals/bayesian-analysis/volume-4/issue-1/Modularization-in-Bayesian-analysis-with-emphasis-on-analysis-of-computer/10.1214/09-BA404.full}{Bayarri et al (2009)}. 
The calibration approach is as follows. 
\begin{enumerate}
\item Run the full model on $N$ design points (i.e. knots): $\{(\tilde{x}_1, \tilde{u}_1), \dots, (\tilde{x}_N, \tilde{u}_N)\}$, where the tilde differentiates these points from the vector of observation parameters $x$
sampled in the field data. Presumably, the design points are chosen such that $\{\tilde{x}_1, \dots, \tilde{x}_N\} \subset \{x_1, \dots, x_n\}$; that is, the model is run at the observation parameter
values observed in the real-world, with the possibility of replicates. Let $\tilde{x}$ and $\tilde{u}$ be N-dimensional vectors containing the 
$\tilde{x}_i$ and $\tilde{u}_i$, respectively. Also let $\tilde{y} := (y_1^{\tilde{u}_1}, \dots, y_N^{\tilde{u}_N})$ be the vector of simulator outputs evaluated at the $N$ design points. 
\item Fit the GP emulator \textit{only using the computer model data} $\tilde{y}$. Denote the fit emulator by $\hat{f}$. 
\item Now essentially conduct the brute force approach described above, but with $\hat{f}$ replacing $f$. That is, we sample from posterior
\[p(u, \tau|z, \hat{f}) \propto p(z|u, \tau, \hat{f})p(u, \tau) = N_n(z|\hat{f}(x, u), \tau^{-1} I_n)p(u, \tau)\]
Now in each step of MCMC we need only evaluate the mean of the GP $\hat{f}(x, u)$ at the current proposed $u$, rather than the whole computer model $f$. 
\end{enumerate}
This approach is not the one proposed by Kennedy and O'Hagan, which is the ``fully Bayesian'' approach: they assume a GP prior for $f$, then consider the posterior over the GP parameters
in addition to the other parameters. Gramacy notes that the modular approach can help to avoid some of the pathologies sometimes present in the fully Bayesian approach. This is of course not
the approach used in PEcAn as I am still considering emulating model outputs directly here (instead of sufficient statistics), but I still find it helpful to review before considering the sufficient 
statistic approach. 

\subsection{Emulator Methodology: Emulating Likelihood}
The above section approached the problem of sampling from the posterior
\[p(u, \tau|z) \propto N_n(z|y^u, \tau^{-1} I_n)p(u, \tau)\]
by replacing the full simulator computations $y^u$ with a surrogate that approximates the full computations. Assuming the surrogate is much faster than the original simulation, then 
this can drastically speed likelihood computation. An alternative method is to essentially skip this intermediate step and directly emulate the likelihood itself. In this case, the function 
we seek to emulate is
\[L(x, z, u) := p(z|y^{u}, \tau) = N_n(z|y^{u}, \tau^{-1} I_n)\]\
To be able to  define this I believe we must consider the extended input space $\mathcal{X}^n \times \mathcal{Z}^n \times \mathcal{U}$, where $\mathcal{X}^n = \mathcal{X} \times \cdots \times \mathcal{X}$
and similarly for $\mathcal{Z}^n$. If we're essentially just treating the $x$ and $z$ values as given, then the domain might be simplified to just $\mathcal{U}$. 
Taking things a step further, we can emulate a sufficient statistic that allows full calculation of the likelihood. That is, we can emulate
\[T(x, z, u) := \sum_{i = 1}^n (z_i - y_i^{u})^2\]\
again defined on the domain $\mathcal{X}^n \times \mathcal{Z}^n \times \mathcal{U}$. Let $\hat{T}(\cdot, \cdot, \cdot)$ denote the fitted GP emulator. 
This approach again allows cheaper (approximate) likelihood computations. Indeed, the likelihood of observed data $z \in \R^n$ (implicitly conditioned on $x \in \R^n$) is given by  
\begin{align*}
p(z|u, \tau) = N_n(z|y^u, \tau^2) &\propto \tau^{n/2} \exp\left\{-\frac{\tau}{2} \norm{z - y^u}^2_2 \right\} \\
					         &= \tau^{n/2} \exp\left\{-\frac{\tau}{2} T(x, z, u) \right\} \\
					         &\approx \tau^{n/2} \exp\left\{-\frac{\tau}{2} \hat{T}(x, z, u) \right\} \\
\end{align*}
Thus, the likelihood can be approximated using evaluations of the GP $\hat{T}$. 
Given this, here is my current understanding of the emulator methodology (for a single site). I'm not considering the experimental design or MCMC methodologies yet at this point, so 
I take them as given. 
\begin{itemize}
\item Choose design points $\{(\tilde{x}_1, \tilde{z}_1, \tilde{u}_1), \dots (\tilde{x}_N, \tilde{z}_N, \tilde{u}_N)\}$, where $\tilde{x}_i \in \mathcal{X}^n$, $\tilde{z}_i \in \mathcal{Z}^n$, and $u_i \in \mathcal{U}$. 
\item Run full simulator at the $(\tilde{x}_i, \tilde{u}_i)$ points, producing the vector of simulator outputs $\tilde{y} \in \R^{N \times n}$. This requires $N \times n$ runs since $\tilde{x}_i$ and $\tilde{z}_i$
each have $n$ components. 
\item Fit GP emulator to the mapping $T(x, z, u) := \sum_{i = 1}^n (z_i - y_i^{u})^2$ using the dataset $\left\{(\tilde{x}_{ij}, \tilde{z}_{ij}, \tilde{u}_i), y_{ij}^{\tilde{u}_i}\right\}_{1 \leq i \leq N, 1 \leq j \leq n}$, producing fit emulator $\hat{T}(\cdot, \cdot, \cdot)$. 
\item Perform MCMC for the approximate posterior
\[p(u, \tau|z) \propto \tau^{n/2} \exp\left\{-\frac{\tau}{2} \hat{T}(x, z, u) \right\}p(u, \tau)\]
\end{itemize}

\subsubsection{Questions}
\begin{itemize}
\item What choices are you making for the GP parameters (mean function $\mu$ and kernel/covariance function $k$)? \\
\textbf{Answer: } Using the defaults of the \textit{mlegp} R package. I believe the default kernel is the inverse squared exponential but I need to check. 
\item Am I correct in defining the sufficient statistic function that you are emulating? 
\textbf{Answer: } Yes. 
\end{itemize}

\subsection{Other methodological components of the analysis}
I haven't thought about this too much in detail, but I'd be interested to hear more about some of the other methodological choices described in the Fer et al (2018) paper. 
\begin{itemize}
\item Calculation of effective sample size (section 2.2).
\item Scaling factors (section 2.3). 
\end{itemize}

\subsection{MCMC Algorithm}
In the below algorithm, I consider a generic symmetric proposal density $q$. I don't know the specific proposal used in the paper, so I can adjust this if needed once this 
is clarified. I also do not explicitly mention any interpolation uncertainty calculations (see questions section below). 

The algorithm is given in more detail below, but my main takeaways are as follows. At each MCMC iteration, the true likelihood calculation is replaced by an approximation calculated 
using the GP. Therefore, the algorithm samples from an approximation to the true posterior. To quantify the uncertainty created by this GP approximation, the sufficient statistic values
used to calculate the likelihoods are sampled from the GP at the current and proposed parameter values. The alternative to this would be to simply use the GP mean at the parameter value. 
However, the sampling approach bakes the GP uncertainty directly into the samples, which allows for the calculation of confidence intervals, etc. that better reflect the true uncertainty. 
This GP kernel also allows for the calculation of the variance at each point, which is what I'm assuming you mean by ``interpolation uncertainty''. 
\bigskip

 \begin{algorithm}[H]
	\SetAlgoLined
	
	\textbf{Input}: 
	\begin{itemize}
	\item Initial parameter values $u^{(0)}, \tau^{(0)}$
	\item Fit emulator $\hat{T}(\cdot, \cdot, \cdot) \sim \mathcal{GP}(\mu(\cdot), k(\cdot, \cdot))$
	\item Proposal density $q(\cdot, \cdot)$ for process-model parameters $u$ 
	\item Number iterations $N_{\text{MCMC}}$
	\end{itemize}
		
	\bigskip
	
	\For{$t = 1, \dots, N_{\text{MCMC}}$} {
	\textit{MH step with GP approximation}: \\[.2cm]
	Sample $u^{(t)} \sim q(u^{(t - 1)}, \cdot)$ \\
	Sample $T^{(t - 1)} \sim \hat{T}(x, z, u^{(t - 1)})$, $T^{(t)} \sim \hat{T}(x, z, u^{(t)})$ \\
	Calculate approximate likelihood $\hat{\mathcal{L}}^{(t - 1)} := \left(\tau^{(t - 1)}\right)^{n/2} \exp\left\{-\frac{\tau^{(t - 1)}}{2} \hat{T}(x, z, u^{(t - 1)}) \right\}$, and similarly for $\hat{\mathcal{L}}^{(t)} $  \\
	Accept $u^{(t)}$ with probability $\min\left\{1, \frac{\hat{\mathcal{L}}^{(t)}p_0(u^{(t)}, \tau^{(t - 1)})}{\hat{\mathcal{L}}^{(t - 1)} p_0(u^{(t - 1)}, \tau^{(t - 1)})}\right\}$
	
	\bigskip
	
	\textit{Gibbs step for statistical parameters}: \\[.2cm]
	Sample $\tau^{(t)} \sim p(\tau|u^{(t)})$
	
	}

	
\caption{MCMC for Parameter Calibration}
\end{algorithm}


\subsubsection{Questions}
\begin{itemize}
\item What proposal distribution $q(\cdot, \cdot)$ are you using? Are you mimicking the Haario et al paper, which is basically random walk MH, but with an adaptively chosen proposal variance?
\end{itemize}


\section{Future Directions}
\subsection{GP Modeling Improvements} (Istem's work with her student this summer)
\begin{itemize}
\item Investigating radial/isotropic covariance assumption (i.e. using separable/antisotropic kernels) (see Gramacy 5.2.5).
\item Investigating stationarity assumption. 
	\begin{itemize}
	\item Heteroskedastic modeling (see Gramacy ch 10). 
	\end{itemize}
\end{itemize}

\subsection{Experimental Design Improvements}
\begin{itemize}
\item Lots of literature in sequential design/active learning/Bayesian optimization
\end{itemize}

\subsection{Speeding up GP calculations}
There is a lot of literature in this area as well, with all of the techniques essentially trying to cope with the expensive matrix decompositions required 
to calculate the inverse and determinant in the equations used for GP prediction and inference. The introduction to chapter 9 in Gramacy's book has a 
very nice list of some of these methods (pseudo-inputs, compactly supported kernels, local neighborhoods, etc.) 

\subsection{MCMC}
Here, we focus in on specific improvements on MCMC side of things, noting that there could certainly be interplay between the previous areas of possible improvement 
and improvements to the MCMC algorithm itself. 

As a first step, Jonathan has already mentioned the potential for adopting a gradient-based approach by trying out Hamiltonian Monte Carlo. 


\subsubsection{Literature Review}
There is certainly a wide body of literature on MCMC algorithms in settings with expensive likelihood calculations. I looked around a bit for literature in this vein but 
tailored specifically to parameter calibration for computer experiments and didn't find as much as I expected. Here are some papers I did find: 
\begin{itemize}
\item \href{https://bg.copernicus.org/articles/14/4295/2017/}{Bayesian calibration of terrestrial ecosystem models: a study of advanced Markov chain Monte Carlo methods}
	\begin{itemize}
	\item Advocates Differential Evolution Adaptive Metropolis (DREAM) over Adaptive Metropolis (AM)
	\item Finds that DREAM improves model fit and predictive performance, and identifies multimodal distributions of parameters where AM fails. 
	\item Also finds that heteroskedastic Gaussian noise model is appropriate, whereas uncorrelated error model would underestimate parameter uncertainty. 
	\end{itemize}
\item \href{https://www.tandfonline.com/doi/abs/10.1198/TECH.2010.09195}{Efficient MCMC Schemes for Computationally Expensive Posterior Distributions}
	\begin{itemize}
	\item Builds on Rasmussen's work \href{http://mlg.eng.cam.ac.uk/pub/pdf/Ras03.pdf}{Gaussian Processes to Speed Up Hybrid Monte Carlo for Expensive Bayesian Integrals}
	\item HMC approach with GP approximation to log posterior.
	\item Parallel tempering for multimodal distributions.
	\item True target (i.e. using full simulation) is maintained at the lowest temperature, so stationary distribution of lowest temperature chain is exactly the posterior of interest. 
	\item ``Exploratory phase'' uses GP approximation to propose parameter values (via leapfrog discretization), and evaluates the full posterior on the final proposed values to refine the GP approximation.
	\item ``Sampling phase'' uses the GP approximation returned from the exploratory phase, then proposes param values using leapfrog discretization and GP, and accepts via MH rejection criterion.
	\end{itemize}
\item \href{https://www.sciencedirect.com/science/article/pii/S0304380021001708}{Sequential Monte-Carlo algorithms for Bayesian model calibration – A review and method comparison} 
(SMC, but interesting comparison to MCMC in the calibration setting)
	\begin{itemize}
	\item SMC generally thought to be less efficient than MCMC for parameter calibration, but SMC is parallelizable; with sufficient number of cores and for runtime-intensive models, authors show that SMC can sometimes be faster
	\item Downside: SMC can be very sensitive to tuning parameters.
	\item Benchmarked SMC against Differential Evolution MCMC with snooker update
	\item They achieved best results with a mix of MCMC and SMC steps. Authors indicate that such ``mixed'' algorithms may be an interesting direction for future research.  
	\item Other future research needs: better adaptive SMC algorithms, more reliable convergence checks that can identify issues during SMC runs. 
	\end{itemize}
\end{itemize}

\subsubsection{Integrating over GP Uncertainty}
Recall that we are interested in sampling from the posterior
\[p(u, \tau|z) \propto N_n(z|y^u, \tau^{-1} I_n)p(u, \tau)\]
and we have opted for the GP approximation 
\[p(u, \tau|z) \propto \tau^{n/2} \exp\left\{-\frac{\tau}{2} \hat{T}(x, z, u) \right\}p(u, \tau)\]
To account for the uncertainty introduced by approximating $T$ with $\hat{T}$, the current algorithm samples from $\hat{T}(x, z, u) \sim N(\mu(u), k(u, u))$ in the MH 
accept-reject step. An alternative approach to incorporating uncertainty that is more conducive to HMC implementation in Stan is to average the likelihood over the GP 
interpolation uncertainty. Noting that the below expectation is with respect to the Gaussian distribution of $\hat{T}(x, z, u)$, we obtain 
\[\E \left[\tau^{n/2} \exp\left\{-\frac{\tau}{2} \hat{T}(x, z, u)\right\} \right] = \tau^{n/2} \E \left[ \exp\left\{-\frac{\tau}{2} \hat{T}(x, z, u)\right\} \right] = \tau^{n/2} \exp\left\{-\frac{\tau}{2}\mu(u) + \frac{\tau^2}{8} k(u, u)\right\}\]
where the final equality follows from the form of the Gaussian moment generating function (MGF). Therefore, an alternative to the re-sampling MCMC approach described above is to use the posterior approximation
\[p(u, \tau|z) \propto \tau^{n/2} \exp\left\{-\frac{\tau}{2}\mu(u) + \frac{\tau^2}{8} k(u, u)\right\}p(u, \tau)\]
where the righthand side may now be evaluated directly to calculate the MH ratio, as the interpolation uncertainty is now baked in to this closed-form expression. Note that based on my definition of the GP in earlier sections I should really be writing $\mu(x, z, u)$ and $k((x, z, u), (x, z, u))$, but I am essentially treating $x$ and $z$ as given above and focusing attention on $u$. 

\subsection{Targeting Specific Needs in Terrestrial Carbon Monitoring}
I included this section as a longer-term goal of better understanding the current state of the terrestrial carbon monitoring field, and how a combination 
of improvements in statistical modeling and computational techniques might help address current limitations. To this end, here are some papers I have bookmarked 
for future reading. 
\begin{itemize}
\item \href{https://www.globalcarbonproject.org/global/pdf/trudinger.07_opti_jgr.pdf}{OptIC project: An intercomparison of optimization techniques for parameter estimation in terrestrial biogeochemical models}
\item \href{https://centaur.reading.ac.uk/28464/1/Fox_etal.REFLEX.AFM.2009.pdf}{The REFLEX project: Comparing different algorithms and implementations for the inversion of a terrestrial ecosystem model against eddy covariance data}
\end{itemize}



\section{PEcAn Code}
\subsection{Suggestions/Updates}
\begin{enumerate}
\item Add a config file to specify file paths that will be read by makefile, rather than having file paths embedded in makefile itself. 
\end{enumerate}

\end{document} 





