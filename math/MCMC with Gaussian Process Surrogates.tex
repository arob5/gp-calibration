\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Local custom commands. 
\include{local-defs}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{MCMC with Gaussian Process Log-Likelihood Surrogates}
\author{Andrew Roberts}

\begin{document}

\maketitle

% Problem Setting
\section{Problem Setting}
We study methods of approximate inference in Bayesian settings which combine a Gaussian process (GP) approximation of the log-likelihood 
with Markov Chain Monte Carlo (MCMC) algorithms. Generically, the goal is to characterize a posterior distribution with (Lebesgue) density 
given by 
\begin{align}
\postDens(\bpar) &= \frac{p(\dataOut|\bpar)\priorDens(\bpar)}{\int p(\dataOut|\bpar)\priorDens(\bpar) d\bpar}, \label{generic_posterior}
\end{align}
where $\bpar \in \parSpace \subseteq \R^{\Npar}$. We consider the setting where evaluation of the likelihood $p(\dataOut|\bpar)$ is very 
computationally demanding, rendering standard MCMC algorithms intractable. This setting commonly occurs when \ref{generic_posterior} is the 
posterior distribution for a Bayesian inverse problem with an expensive forward model; e.g. where the likelihood arises via the data-generating 
process 
\begin{align*}
\dataOut &= \fwd(\bpar) + \boldsymbol{\epsilon},
\end{align*}
and evaluation of the forward model $\fwd(\bpar)$ requires a significant amount of time. A well-established solution to circumvent the intractability of standard MCMC is 
to leverage a cheaper surrogate model (also called an \textit{emulator} or \textit{meta-model}), which is trained from a small number of forward model 
runs, and then proceed to use the surrogate in place of the expensive model in subsequent inference algorithms. In the fields of computer modeling and 
Bayesian inverse problems, the typical approach is to replace the forward model $\fwd$ with an emulator. We instead focus on the alternative 
method of directly emulating the log-likelihood $\llik(\bpar) := \log p(\bpar|\dataOut)$. In particular, we assume uncertainty in the log-likelihood is represented by a Gaussian 
process (GP), 
\begin{align}
\llik_{\Ndesign} \sim \GP(\GPMeanPred[\Ndesign], \GPKerPred[\Ndesign]),
\end{align}
corresponding to a GP prior $\llik \sim \GP(\GPMean, \GPKer)$ which has been conditioned on a dataset 
$\designData := \{\designMat[], \designOutLik\}$ consisting of $\Ndesign$ \textit{design points} 
$\bpar_1, \dots, \bpar_{\Ndesign}$ stacked in the rows of $\designMat[]$, and their corresponding outputs $\designOutLik_{\designIdx} = \llik(\bpar_{\designIdx})$. The 
mean function $\GPMeanPred[\Ndesign]$ and kernel $\GPKerPred[\Ndesign]$ thus pertain to the GP predictive distribution and are given by 
\begin{align}
\GPMeanPred[\Ndesign](\newInputMat) &= \GPMean(\newInputMat) + \GPKer(\newInputMat, \designMat[]) \KerMat[]^{-1} \left(\designOutLik - \GPMean(\designMat[]) \right) \label{kriging_eqns} \\
\GPKerPred[\Ndesign](\newInputMat) &= \GPKer(\newInputMat) - \GPKer(\newInputMat, \designMat[]) \KerMat[]^{-1} \GPKer(\designMat[], \newInputMat),
\end{align}
where $\KerMat[] \in \R^{\Ndesign \times \Ndesign}$ is the \textit{kernel matrix} with entries $\KerMat[n,m] = \GPKer(\bpar_n, \bpar_m)$. 

We investigate two questions: 
\begin{enumerate}
\item How should the GP emulator $\llik_{\Ndesign}$ be used to define a target posterior that approximates the true posterior, and which MCMC 
strategies are effective for sampling from this target?
\item What is an effective batch sequential design strategy for refining the emulator $\llik_{\Ndesign}$? 
\end{enumerate}

% Literature Review.
\section{Literature Review}

\subsection{Log-Likelihood Emulation}

\subsection{Propagating GP Uncertainty}
Stuart and Teckentrup posterior consistency paper, Aki Vehtari paper, train paper that approximates sampling GP trajectories, Emulate/Calibrate/Sample paper, 
GP MCMC paper for MALA approximation; mention exact methods: Youssef work and delayed acceptance schemes 

\subsection{Experimental Design}
Original integrated variance paper (see Gramacy book for references), Youssef paper on integrated variance criteria, Vehtari paper, Stuart and Teckentrup experimental 
design paper, sequential design GP paper that considers KL divergence, Stefan Wild paper, Sinsbeck and Nowak 

% Gaussian Process Posterior Approximations.
\section{Gaussian Process Posterior Approximations}
We now investigate different approaches for utilizing the emulator $\llik_{\Ndesign}$ to define an approximate inference scheme. Replacing the true log-likelihood 
with the emulator results in a random posterior approximation 
\begin{align}
\postDens_{\Ndesign}(\bpar)
&:= \frac{\priorDens(\bpar) \exp\left\{\llik_{\Ndesign}(\bpar) \right\}}{\int \priorDens(\bpar) \exp\left\{\llik_{\Ndesign}(\bpar) \right\} d\bpar}.
\end{align}
The randomness in $\postDens_{\Ndesign}(\bpar)$ results from the fact that the expression depends on the GP $\llik_{\Ndesign}(\bpar)$. We consider 
two general classes of methods for turning this random quantity into a well-defined sampling algorithm: (i.) methods which select a single deterministic 
posterior density from the distribution over all possible densities, and (ii.) methods which retain the randomness and result in noisy MCMC algorithms. 

% Deriving a Deterministic Posterior Approximation.
\subsection{Deriving a Deterministic Posterior Approximation}
We now consider producing a point estimate of $\postDens_{\Ndesign}(\bpar)$ which ideally propagates the emulator uncertainty. An argument could 
be made for the point estimator 
\begin{align}
\hat{\postDens}^*(\bpar) 
&:= \E_{\llik_{\Ndesign} \sim \GP(\GPMeanPred[\Ndesign], \GPKerPred[\Ndesign])} \left[ \postDens_{\Ndesign} \right] \nonumber \\
&= \E_{\llik_{\Ndesign} \sim \GP(\GPMeanPred[\Ndesign], \GPKerPred[\Ndesign])} \left[ \frac{\priorDens(\bpar) \exp\left\{\llik_{\Ndesign}(\bpar) \right\}}{\int \priorDens(\bpar) \exp\left\{\llik_{\Ndesign}(\bpar) \right\} d\bpar} \right] \label{ideal_point_estimate},
\end{align}
but the integral in the normalizing constant in \ref{ideal_point_estimate} renders this expectation intractable. Note that \ref{ideal_point_estimate} considers taking the 
expectation with respect to the entire GP distribution. An alternative, computationally tractable, approach instead considers taking the expectation of the 
likelihood $\exp\left\{\llik_{\Ndesign}(\bpar)\right\}$ separately for each $\bpar$, and then normalizing the result afterwards
\begin{align}
\hat{\postDens}(\bpar) 
&:= \frac{\priorDens(\bpar) \E\left[\exp\left\{\llik_{\Ndesign}(\bpar)\right\} \right]}{\int \priorDens(\bpar) \E\left[\exp\left\{\llik_{\Ndesign}(\bpar)\right\} \right] d\bpar} \\
&= \frac{\priorDens(\bpar) \exp\left\{\GPMeanPred[\Ndesign](\bpar) + \frac{1}{2}\GPKerPred[\Ndesign](\bpar) \right\}}{\int \priorDens(\bpar) \exp\left\{\GPMeanPred[\Ndesign](\bpar) + \frac{1}{2}\GPKerPred[\Ndesign](\bpar) \right\} d\bpar}, \label{point_estimate}
\end{align}
where the second line follows from the expectation formula for a log-normal random variable. The use of the posterior $\hat{\postDens}$ may be partially justified in at least two different ways. 
First consider extending the joint distribution over $(\bpar, \dataOut)$ to $(\bpar, \dataOut, \ell) := (\bpar, \dataOut, \llik_{\Ndesign}(\bpar))$, defined by 
\begin{align*}
p(\bpar, \dataOut, \ell) 
&:= p(\dataOut|\bpar, \ell) p(\ell|\bpar) \priorDens(\bpar) \\
&= \exp(\ell) \Gaussian(\ell | \GPMeanPred(\bpar), \GPKerPred(\bpar)) \priorDens(\bpar).
\end{align*}
It is then natural to consider the marginal distribution $p(\bpar, \dataOut)$, which is given by 
\begin{align}
p(\bpar, \dataOut) &= \priorDens(\bpar) \E\left[\exp\left(\llik_{\Ndesign}(\bpar)\right) \right].
\end{align}
We observe that the marginal posterior $p(\bpar|\dataOut)$ in this setting is thus equal to $\hat{\postDens}$. 

Bayesian decision theory provides a second perspective. We might consider deriving a target density by solving 
\begin{align}
\text{argmin}_{\rho \in \mathcal{F}} \E_{\llik_{\Ndesign}} \norm{\postDens_{\Ndesign} - \rho}^2
\end{align}  
for some suitable normed space of densities $(\mathcal{F}, \norm{\cdot})$. The normalizing constant in \ref{ideal_point_estimate} again renders 
this intractable. However, we might instead consider minimizing the averaged error in the \textit{unnormalized} density 
\begin{align}
\tilde{\postDens}_{\Ndesign}(\bpar) := \priorDens(\bpar) \exp\left(\llik_{\Ndesign}(\bpar)\right). 
\end{align}
Taking $(\mathcal{F}, \norm{\cdot}) = L^2(\parSpace)$ then gives the optimization problem 
\begin{align}
\hat{\tilde{\postDens}}(\bpar) &= \text{argmin}_{\rho \in L^2(\parSpace)} \E_{\llik_{\Ndesign}} \norm{\tilde{\postDens}_{\Ndesign} - \rho}_2^2,
\end{align} 
which is solved by 
\begin{align}
\hat{\tilde{\postDens}}(\bpar) &= \priorDens(\bpar) \E\left[\exp\left\{\llik_{\Ndesign}(\bpar)\right\} \right]. \label{unnormalized_optimum}
\end{align}
Normalizing \ref{unnormalized_optimum} again recovers $\hat{\postDens}$, as given in \ref{point_estimate}. We emphasize that the density 
$\hat{\postDens}$ does not inherit the $L^2$ optimality from $\hat{\tilde{\postDens}}(\bpar)$. 


% Noisy MCMC Approaches
\subsection{Noisy MCMC Approaches}
The previous approaches are attractive in that they target well-defined posterior distributions, but from an uncertainty quantification viewpoint it may
be unsatisfying to reduce to a point estimate. Intuitively, one approach to propagate the GP uncertainty might be to draw a sample from the 
distribution of $\postDens_{\Ndesign}$ for each iteration of an MCMC algorithm. Formally, we might consider the extended state space 
$(\bpar, \llik_{\Ndesign})$, in which case the random posterior density sample would manifest as a Gibbs sampling step for $\llik_{\Ndesign}$. 
Note that $\llik_{\Ndesign}$ is infinite-dimensional so that this notion is purely formal at this point. We now detail a family of algorithms that each 
provide a different noisy approximation to the MCMC acceptance probability in a random walk Metropolis-Hastings (RWMH) algorithm. For 
a current sample $\bpar$ and proposal $\bpar^\prime \sim \propDens(\bpar, \cdot)$ the exact acceptance probability is given by 
\begin{align*}
\accProbMH(\bpar, \bpar^\prime) 
&:= \min\left\{1, r(\bpar, \bpar^\prime) \right\}, && r(\bpar, \bpar^\prime) := 
\frac{\priorDens(\bpar^\prime) \exp\left\{\llik(\bpar^\prime)\right\} \propDens(\bpar^\prime,\bpar)}{\priorDens(\bpar) \exp\left\{\llik(\bpar)\right\} \propDens(\bpar, \bpar^\prime)}.
\end{align*}
We consider noisy MCMC algorithms which replace the exact acceptance probability with the noisy approximation 
\begin{align*}
\hat{\accProbMH}(\bpar, \bpar^\prime; \ell, \ell^\prime) 
&:= \min\left\{1, \hat{r}(\bpar, \bpar^\prime|\ell, \ell^\prime) \right\}, && \hat{r}(\bpar, \bpar^\prime|\ell, \ell^\prime)  := 
\frac{\priorDens(\bpar^\prime) \exp\left(\ell^\prime\right) \propDens(\bpar^\prime,\bpar)}{\priorDens(\bpar) \exp\left(\ell\right) \propDens(\bpar, \bpar^\prime)}
\end{align*}
with the variations stemming from how $\ell$ and $\ell^\prime$ are sampled. We consider the three following options: 
\begin{enumerate}
\item\label{gp-mcmc-pseudo-marginal} $\ell \sim \Gaussian(\GPMeanPred[\Ndesign](\bpar), \GPKerPred[\Ndesign](\bpar))$, with $\ell^\prime$ recycled from the previous iteration. 
\item\label{gp-mcmc-noisy} $\ell \sim \Gaussian(\GPMeanPred[\Ndesign](\bpar), \GPKerPred[\Ndesign](\bpar))$, $\ell^\prime \sim 
\Gaussian(\GPMeanPred[\Ndesign](\bpar^\prime), \GPKerPred[\Ndesign](\bpar^\prime))$ sampled independently each iteration. 
\item\label{gp-mcmc-noisy-cov} $(\ell, \ell^\prime) \sim \Gaussian(\GPMeanPred[\Ndesign](\bpar, \bpar^\prime), \GPKerPred[\Ndesign](\bpar, \bpar^\prime))$ sampled independently from the joint distribution each iteration. 
\end{enumerate}
The first option can be viewed as a pseudo-marginal method targeting the posterior $\hat{\postDens}(\bpar) = \priorDens(\bpar) \E\left[\exp\left\{\llik_{\Ndesign}(\bpar)\right\}\right]$, which is the same 
posterior discussed in the previous section. The other two methods can be viewed generally as Monte Carlo within Metropolis (MCWM) algorithms. Seeing as $\ell, \ell^\prime$ 
are sampled independently across iterations, the algorithms do produce valid Markov chains. However, it is not immediately clear whether these chains are ergodic and, if so, which 
distribution they actually sample from. 

% The Effect of Incorporating the GP Predictive Covariance
\subsection{The Effect of Incorporating the GP Predictive Covariance}
Out of the algorithms considered above, only the third noisy method considers the GP covariance structure. The remaining algorithms essentially view the emulator as providing 
pointwise predictions independently for different $\bpar$. In this section we consider the impact of incorporating the GP covariance structure. The distribution of 
$\hat{r}(\bpar, \bpar^\prime; \ell, \ell^\prime)$ when predictive covariance is included is given by 
\begin{align*}
\hat{r}(\bpar, \bpar^\prime; \ell, \ell^\prime) \sim \text{LN}\left(\log \frac{\priorDens(\bpar^\prime)\propDens(\bpar^\prime, \bpar)}{\priorDens(\bpar)\propDens(\bpar, \bpar^\prime)} 
+ \GPMeanPred[\Ndesign](\bpar^\prime) - \GPMeanPred[\Ndesign](\bpar), \GPKerPred[\Ndesign](\bpar) + \GPKerPred[\Ndesign](\bpar^\prime) - 2\GPKerPred[\Ndesign](\bpar, \bpar^\prime) \right).
\end{align*}
In particular, the expectation is 
\begin{align*}
\E_{\ell, \ell^\prime}\left[\hat{r}(\bpar, \bpar^\prime; \ell, \ell^\prime)\right]
&= \frac{\priorDens(\bpar^\prime)\exp\left\{\GPMeanPred[\Ndesign](\bpar^\prime)\right\} \propDens(\bpar^\prime, \bpar)}{\priorDens(\bpar) \exp\left\{\GPMeanPred[\Ndesign](\bpar)\right\} \propDens(\bpar, \bpar^\prime)}
\exp\left\{\frac{\GPKerPred[\Ndesign](\bpar) + \GPKerPred[\Ndesign](\bpar^\prime) - 2\GPKerPred[\Ndesign](\bpar, \bpar^\prime) }{2} \right\}.
\end{align*}
We observe that the first term is the acceptance ratio computed using the plug-in mean estimator of the GP, while the second term accounts for GP uncertainty. 
In the case of the second algorithm, the covariance term $\GPKerPred[\Ndesign](\bpar, \bpar^\prime)$ is set to $0$. It is perhaps clearer to write this expectation as 
\begin{align*}
\E_{\ell, \ell^\prime}\left[\hat{r}(\bpar, \bpar^\prime; \ell, \ell^\prime)\right]
&= \frac{\priorDens(\bpar^\prime)\exp\left\{\E\left[\llik_{\Ndesign}(\bpar^\prime)\right] \right\} \propDens(\bpar^\prime, \bpar)}{\priorDens(\bpar) \exp\left\{\E\left[\llik_{\Ndesign}(\bpar)\right]\right\} \propDens(\bpar, \bpar^\prime)}
\exp\left\{\frac{1}{2}\Var\left[\llik_{\Ndesign}(\bpar^\prime) -  \llik_{\Ndesign}(\bpar) \right] \right\}.
\end{align*}
For the second algorithm, the variance in the exponential term is replaced by $\Var\left[\llik_{\Ndesign}(\bpar^\prime)\right] + \Var\left[\llik_{\Ndesign}(\bpar)\right]$. We observe 
that the expected acceptance ratio for algorithm 3 is strictly less than that of algorithm 2 when $\GPKerPred[\Ndesign](\bpar, \bpar^\prime) > 0$ and vice versa. Including the covariance 
accounts for the fact that even though $\llik_{\Ndesign}(\bpar^\prime)$ and $\llik_{\Ndesign}(\bpar)$ may be quite uncertain, their difference may have little uncertainty 
if the correlation between the two is high. Given that the acceptance ratio only depends on their difference, intuitively we would expect accounting for the covariance to result 
in a better estimator. Moreover, between the two algorithms, including the covariance results in larger acceptance probabilities when the predictive covariance is smaller, which tends 
to be when $\bpar$ and $\bpar^\prime$ are farther apart, a property that appears desirable for good MCMC mixing.  

% Sequential Design
\section{Sequential Design}
\textbf{TODO: add intro}

We now investigate the uncertainty in the predictive equations \ref{kriging_eqns} for the process $\llik_{\Ndesign + \Nbatch} := \llik_{\Ndesign}|(\inputMatBatch, \outputVecBatch)$
when $\outputVecBatch$ is unknown and assumed to follow the current GP predictive distribution. 
\begin{lemma}  \label{lemma_pred_uncertainty}
Let $(\inputMatBatch, \outputVecBatch)$ be a new batch of $\Nbatch$ design points, with 
$\outputVecBatch \sim \Gaussian(\GPMeanPred[\Ndesign](\inputMatBatch), \GPKerPred[\Ndesign](\inputMatBatch))$. Then for an arbitrary set of inputs 
$\newInputMat$, the predictive mean $\GPMeanPred[\Ndesign+\Nbatch](\newInputMat)$ and $\GPKerPred[\Ndesign+\Nbatch](\newInputMat)$
 (viewed as functions of the random quantity $\outputVecBatch$) satisfy 
\begin{align}
\GPMeanPred[\Ndesign+\Nbatch](\newInputMat) 
&\sim \Gaussian\left(\E\left[\llik_{\Ndesign}(\newInputMat)| \inputMatBatch, \GPMeanPred[\Ndesign](\inputMatBatch) \right], 
\GPKerPred[\Ndesign](\newInputMat, \inputMatBatch) \GPKerPred[\Ndesign](\inputMatBatch)^{-1} \GPKerPred(\inputMatBatch, \newInputMat) \right)  \label{mean_batch_uncertainty} \\
\GPKerPred[\Ndesign+\Nbatch](\newInputMat) 
& \sim \delta_{\GPKer(\newInputMat) - \GPKer(\newInputMat, \inputMat[\Ndesign+\Nbatch]) \KerMat[\Ndesign+\Nbatch]^{-1} \GPKer(\inputMat[\Ndesign+\Nbatch], \newInputMat)}  \label{ker_batch_uncertainty}
\end{align}
\end{lemma}
The predictive kernel \ref{ker_batch_uncertainty} has no uncertainty given that the GP predictive variance does not depend on the response. The predictive mean does depend 
on the response and thus exhibits uncertainty; it's mean $\E\left[\llik_{\Ndesign}(\newInputMat)| \inputMatBatch, \GPMeanPred[\Ndesign](\inputMatBatch) \right]$ is 
equal to the mean of the GP resulting from conditioning on the data $(\inputMatBatch, \GPMeanPred[\Ndesign](\inputMatBatch))$ (i.e. the current GP mean is treated as if it 
were the observed data). It's variance can be re-written as 
\begin{align*}
\Var_{\outputVecBatch}\left[\GPMeanPred[\Ndesign+\Nbatch](\newInputMat) \right] 
&= \Var\left[\llik_{\Ndesign}(\newInputMat)\right]  - \Var\left[\llik_{\Ndesign}(\newInputMat) | \inputMatBatch  \right],
\end{align*}
which is the change in GP variance due to the addition of the new input batch $\inputMatBatch$. A larger change in variance implies that 
the batch $\inputMatBatch$ is more influential and hence the resulting GP mean $\GPMeanPred[\Ndesign+\Nbatch]$ will be more uncertain. 

The above lemma is useful in deriving an integrated variance criterion targeting $\tilde{\postDens}_{\Ndesign}$, which we recall is a log-Gaussian process emulating the unnormalized 
posterior density. The following lemma shows that the expected variance of $\tilde{\postDens}_{\Ndesign+\Nbatch}(\newInput)$, with respect to 
$\outputVecBatch \sim \Gaussian(\GPMeanPred[\Ndesign](\inputMatBatch), \GPKerPred[\Ndesign](\inputMatBatch))$, is available in closed-form. 
\begin{lemma}
Under the same assumptions as lemma \ref{lemma_pred_uncertainty}, it follows that 
\begin{align*}
\E_{\outputVecBatch} \Var\left[\tilde{\postDens}_{\Ndesign+\Nbatch}(\newInput) \right]
&= \Var\left[\tilde{\postDens}_{\Ndesign}(\newInput)| \inputMatBatch, \GPMeanPred[\Ndesign](\inputMatBatch) \right] v(\newInput; \inputMatBatch),
\end{align*}
where 
\begin{align*}
v(\newInput; \inputMatBatch) &= \exp\left\{2\left(\Var[\llik_{\Ndesign}(\newInput)] - \Var[\llik_{\Ndesign}(\newInput)| \inputMatBatch] \right) \right\}
\end{align*}
\end{lemma}
We observe that the first term is simply the variance of the LNP $\tilde{\postDens}_{\Ndesign}(\newInput)$ conditioned on the additional data 
$(\inputMatBatch, \GPMeanPred[\Ndesign](\inputMatBatch))$ (treating the current GP mean as observed data). The second term 
$v(\newInput; \inputMatBatch)$, which we refer to as the \textit{variance inflation factor}, accounts for the GP uncertainty. We note that 
$v(\newInput; \inputMatBatch) \geq 1$ and that this term is larger when the input batch $\inputMatBatch$ is more influential. If 
$\inputMatBatch$ is a subset of the current design, then $v(\newInput; \inputMatBatch) = 1$ (no variance inflation). The expected integrated 
variance criterion is defined by integrating the expected variance over the input space, weighted by some density $\rho$. 
\begin{definition} 
The integrated expected variance (IEVAR) design criterion (i.e. acquisition function) $\acq[\Ndesign]: \parSpace^{\Nbatch} \to [0, \infty]$
for batches of size $\Nbatch$ is defined by 
\begin{align*}
\acq[\Ndesign](\inputMatBatch)
&:= \E_{\newInput \sim \rho} \E_{\outputVecBatch} \Var\left[\tilde{\postDens}_{\Ndesign+\Nbatch}(\newInput) \right] \\
&= \int_{\parSpace} \Var\left[\tilde{\postDens}_{\Ndesign}(\newInput)| \inputMatBatch, \GPMeanPred[\Ndesign](\inputMatBatch) \right]
v(\newInput; \inputMatBatch) \rho(\newInput) d\newInput.
\end{align*}
\end{definition} 


\end{document}






