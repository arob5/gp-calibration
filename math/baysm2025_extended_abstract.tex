\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode} % Note that this also loads algorithmicx
\usepackage{cleveref}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{caption, subcaption} % Captions and sub-figures. 
\usepackage{fancyvrb} % For writing using verbatim font inline. 
% \usepackage[demo]{graphicx}

% Bibliography
\bibliographystyle{plainnat}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Tables. 
\usepackage{multirow}

% Local custom commands. 
\include{latex_macros_general}
\include{latex_macros_gp_inv_prob}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{{../output/gp_post_approx_paper/}}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{Gaussian Process Surrogates for Bayesian Inverse Problems: Posterior Approximation and Sequential Design}
\author{Andrew Roberts}

\begin{document}

\maketitle

\subsubsection*{Introduction}
The use of surrogates (i.e., emulators) has become routine in accelerating inference for inverse problems featuring expensive forward models. Gaussian processes (GPs) 
are a popular choice of surrogate model, owing in part to their ability to yield tractable uncertainty estimates. However, it is not always clear how to leverage the GP
predictive uncertainty in downstream tasks. In this work, we focus on the task of constructing an approximate posterior distribution of a Bayesian inverse problem, where
the log-likelihood is replaced by a random approximation induced by a GP emulator. This problem has attracted recent attention, and a variety of different recommendations 
have been given in the literature. \textbf{TODO: cite} We provide a unified framework in which to compare these methods, in addition to presenting a novel inference scheme
 based on a noisy approximation to Metropolis-Hastings algorithms. We also emphasize methods for (batch) sequential design, whereby the GP surrogate is iteratively refined 
 in stages. We conduct extensive numerical comparisons, with a focus on applications to parameter estimation for differential equations. 

\end{document}









