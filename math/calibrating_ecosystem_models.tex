\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithm}
\usepackage{algpseudocode} % Note that this also loads algorithmicx
\usepackage{cleveref}
\usepackage{bbm}
\usepackage{caption, subcaption} % Captions and sub-figures. 
% \usepackage[demo]{graphicx}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Local custom commands. 
\include{latex_macros_general}
\include{latex_macros_calibrating_LSMs}
\newcommand{\bphi}{\boldsymbol{\phi}}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{{../output/gp_post_approx_paper/}}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{example}{Example}

% Title and author
\title{Parameter Calibration for Land Surface Models}
\author{Andrew Roberts}

\begin{document}
\maketitle

% The Structure of Land Surface Models
\section{The Structure of Land Surface Models}
Unlike the typical PDE models used in atmospheric and oceanic modeling, the standard toolkit in land surface modeling 
consists primarily of ODEs describing time evolution at a single location. In this introductory section, we omit discussion 
of the application of these models across space, but return to this important topic in a later section. The notation 
used throughout this section can thus be thought of as suppressing a fixed spatial index on most of the quantities considered. 

While LSMs can incorporate a wide 
variety of terrestrial processes, we will focus on models of the carbon cycle when providing concrete examples. 
LSMs model the carbon cycle as consisting of a set of states (i.e., \textit{pools}; soil, roots, above-ground vegetation, atmosphere, etc.),
along with processes that transfer carbon between these states (i.e., \textit{fluxes}; photosynthesis, respiration, etc.). 
We denote the state vector at time $\Time$ by 
\begin{align}
\state(\Time) \Def [\indexState[1]{\state}(\Time), \dots, \indexState[\dimState]{\state}(\Time)]^\top \in \R^{\dimState}.
\end{align}
Carbon fluxes between these states are then described by an ODE model of the form
\begin{align}
&\frac{d}{d\Time} \state_{\Par}(\Time) = \funcODE_{\Par}(\state_{\Par}(\Time), \forcing(\Time)), &&\state_{\Par}(\timeInitState) = \stateInit, 
\end{align}
where $\funcODE_{\Par}(\cdot, \forcing): \R^{\dimState} \to \R^{\dimState}$ is typically a nonlinear function, and $\stateInit$ is the \textit{initial condition}, 
the value of the state at some initial time $\timeInitState$. Models of this form are referred to as \textit{pool-based models}, or more generically 
\textit{box models}, as they conceptualize the carbon cycle are consisting of a set of carbon pools that are exchanging carbon. 
The forward dynamics encoded by $\funcODE_{\Par}$ are dependent both on a set of 
\textit{parameters} $\Par \in \parSpace \subset \R^{\dimPar}$, as well as a \textit{forcing} (i.e., \textit{driving}) function $\forcing(\Time)$.
In general, the parameters $\Par$ are not physical constants; rather, they provide a means to empirically parameterize ecosystem 
processes, which may vary in space and time.   
We emphasize that the solution $\state_{\Par}(\Time)$ of the ODE is a function of the parameters $\Par$, driver $\forcing(\Time)$, and 
initial condition $\stateInit$, though only the first is made explicit in the notation as the parameters are the main quantity of interest in this document.

% The Forward Problem 
\subsection{The Forward Problem}
The \textit{forward problem} consists of recovering the solution $\state_{\Par}(\Time)$ over some time interval $[\timeInitState, \timeEnd]$ for given 
values of $\Par$, $\stateInit$, and $\forcing(\cdot)$. Given the nonlinearity of $\funcODE_{\Par}$, this solution is typically approximated 
numerically at a finite set of times $\{\indexTime{\Time}\}_{\timeIdx=\firstTimeIdxState}^{\lastTimeIdx} \subset [\timeInitState, \timeEnd]$. We 
let $\stateApprox_{\Par}(\indexTime{\Time})$ denote the approximation of $\state_{\Par}(\indexTime{\Time})$ for each 
$\timeIdx = \firstTimeIdxState, \dots, \lastTimeIdx$. Also, let $\indexTime{\timeStep} \Def \indexTime[\timeIdx+1]{\Time} - \indexTime{\Time}$ denote the 
time step used by the numerical solver at the $\timeIdx^{\text{th}}$ iteration. Standard ODE solvers are time-stepping algorithms of the 
form 
\footnote{The simplest example here is a forward Euler scheme, in which the update assumes the form 
$\stateApprox_{\Par}(\indexTime[\timeIdx+1]{\Time})
= \stateApprox_{\Par}(\indexTime{\Time}) + \indexTime{\timeStep} \funcODE(\stateApprox_{\Par}(\indexTime{\Time}), \forcing(\indexTime{\Time}))$.}
\begin{align}
&\stateApprox_{\Par}(\indexTime[\timeIdx+1]{\Time}) \Def \fwdOne_{\Par}(\stateApprox_{\Par}(\indexTime{\Time}), \forcing(\indexTime{\Time}); \indexTime{\timeStep}), 
&&\stateApprox_{\Par}(\indexTime[\firstTimeIdxState]{\Time}) = \stateInit, \label{ode_discrete}
\end{align}
for $\timeIdx = \firstTimeIdxState, \dots, \lastTimeIdx$. Setting a constant step size $\timeStep \equiv \indexTime{\timeStep}$ is a common choice, though 
algorithms that adapt the step size are also quite standard. In practice, the model drivers $\forcing(\indexTime{\Time})$
are typically given by a sequence of (noisy) observations of meteorological variables (e.g., photosynthetically-active radiation).
Going forward, we will treat the discrete dynamical system \ref{ode_discrete} as 
the true model and starting point for subsequent analysis, thus neglecting discretization error with respect to the true continuous-time solution.


% The Inverse Problem
\subsection{The Inverse Problem}
Naturally, one must recognize that the predictions of the model \ref{ode_discrete} are subject to many sources of uncertainty. 
The simulated trajectory $\{\stateApprox_{\Par}(\indexTime{\Time})\}_{\timeIdx=\firstTimeIdxState}^{\lastTimeIdx}$ is a function of  
the chosen value of the parameters $\Par$, the model drivers  $\{\indexTime{\obs}\}_{\timeIdx=\firstTimeIdxState}^{\lastTimeIdx}$, the initial condition $\stateInit$, 
and the model processes encoded by $\fwdOne_{\Par}$ (irrespective of the parameter value). In the LSM context, 
all of these quantities contribute non-negligible uncertainty. 
In this document, we restrict ourselves to the consideration of parameter uncertainty. 

The values of LSM parameters are not known exactly, and moreover, cannot always be observed directly. In other words, offline estimation of $\Par$
using a separate data source is typically not possible for all of the parameters of interest. Historically, the choice of parameter settings 
was commonly performed on an ad hoc basis using expert judgement. 
Given that $\Par$ consists of empirical parameters 
(not physical constants) the concept of ``true'' parameter values is largely ill-defined. It is perhaps most conceptually useful to draw an 
analogy with empirically-determined parameters of a statistical model, in which ``true values'' is interpreted as best-fit in a regression sense.
Therefore, a natural solution is to learn the parameter values from data. For example, suppose we have access to noisy observations 
$\{\indexTime{\obs}\}_{\timeIdx=\firstTimeIdxObs}^{\lastTimeIdx}$ of the true states 
$\{\state_{\Par}(\indexTime{\Time})\}_{\timeIdx=\firstTimeIdxObs}^{\lastTimeIdx}$. 
We can then consider tuning (i.e., \textit{calibrating}), the value of $\Par$ such that $\{\state_{\Par}(\indexTime{\Time})\}_{\timeIdx=\firstTimeIdxObs}^{\lastTimeIdx}$
is ``close'' to $\{\indexTime{\obs}\}_{\timeIdx=\firstTimeIdxObs}^{\lastTimeIdx}$  in some well-defined sense. We will refer to the 
general problem of learning parameters from data as \textit{parameter calibration} or \textit{parameter estimation}. We make this 
problem precise in the following section, which casts parameter calibration within the generic framework of \textit{inverse problems}. Before 
doing so, we provide a concrete example of a basic vegetation model. 

% Toy Example: Very Simple Ecosystem Model 
\subsection{Toy Example: Very Simple Ecosystem Model}
\todo: Discuss that GPP is a nonlinear function of both states and parameters; depends explicitly on some parameters, and implicitly on others through the 
state variable (which itself depends on all parameters). 

% Inverse problems 
\section{Inverse Problems}
In this section, we provide a brief introduction to inverse problems from a generic perspective. The following section 
interprets these ideas in the context of parameter calibration for LSMs. 

\subsection{Basic Setup}
We start by considering a \textit{forward model} 
\footnote{An alternative name for $\fwd$ is the \textit{parameter-to-observable map}. We favor the shorter term 
\textit{forward model}, but note that terminology can vary.}
$\fwd: \parSpace \subseteq \R^{\dimPar} \to \R^{\dimObs}$ describing some 
process of interest, parameterized by input parameters $\Par \in \parSpace$. In addition, suppose we have noisy 
observations $\obs \in \obsSpace \subset \R^{\dimObs}$ of the output signal that $\fwd(\Par)$ approximates. 
We seek to invert the process to infer the parameter values that produced the data; loosely speaking, the 
\textit{inverse problem} consists of identifying $\Par$ such that $\fwd(\Par) \approx \obs$. 

\begin{example} \label{ex:lsm-state-obs}
There are many ways we might define the forward model in the dynamical setting \ref{ode_discrete}, which we recall 
conceptualizes an LSM at a single spatial location. Suppose we have noisy observations 
$\obs \Def \{\indexTime{\obs}\}_{\timeIdx=\firstTimeIdxObs}^{\lastTimeIdx}$ 
of the true states $\{\indexState[1]{\state}_{\Par}(\indexTime{\Time})\}_{\timeIdx=\firstTimeIdxObs}^{\lastTimeIdx}$; that is, we have observations of 
the first state variable (e.g., above-ground biomass). It is then natural to define the forward model as 
\begin{align}
&\fwd: \parSpace \to \R^{\Ntime}, && \fwd(\Par) 
\Def [\indexState[1]{\stateApprox}_{\Par}(\indexTime[\firstTimeIdxObs]{\Time}), \dots, \indexState[1]{\stateApprox}_{\Par}(\indexTime[\lastTimeIdx]{\Time})]^\top. \label{fwd_model}
\end{align}
In words, $\fwd(\Par)$ is the simulated trajectory of the first state variable given the parameter value $\Par$. In this context, achieving 
the approximation $\fwd(\Par) \approx \obs$ implies that this simulated trajectory agrees with the noisy state observations. We also 
see that $\dimObs = \Ntime$; i.e., the output dimension of the forward model equals the number of time steps.
\footnote{Note that we have defined $\fwd$ here in such a way that the initial condition $\stateInit$ is excluded from the forward model 
output, given that we are assuming the initial condition has been fixed. Alternatively, the initial condition can be regarded as an additional 
parameter to learn from data, in which case we would include the initial condition in the forward model output.} 
\end{example}

We emphasize that this setup is quite general; in particular, $\fwd$ can conceptualize a wide array 
of different problems. The forward model is an abstraction that represents the map from parameters to a quantity that
can be directly compared to the observations $\obs$. We focus on the setting where $\fwd$ is a deterministic, known 
function. It is often the case that the forward model has no analytical form; rather, $\fwd$ may be given by a complex 
computer simulation (e.g., an ODE solver). 
In the setting of interest, $\fwd$ typically has a variety of characteristics that make 
the inverse problem especially challenging. We will emphasize forward models that (1) are expensive to evaluate 
at inputs $\Par$; (2) have high-dimensional, structured output spaces (e.g., time series); and (3) are highly nonlinear. 
In addition, computing gradients of $\fwd$ may be difficult or impossible in many cases. Given these characteristics, 
it is desirable to consider algorithms that treat $\fwd$ as a ``black-box''; that is, algorithms that only require the 
ability to compute evaluations $\fwd(\Par)$, without assuming any additional structure. However, there are certainly 
cases where additional structure (e.g., derivative information, smoothness, periodicity) can be exploited. 

\subsection{Loss Minimization}
It is typically impossible (or undesirable) to seek an exact solution $\fwd(\Par) = \obs$. An alternative is to cast 
model inversion as an optimization problem of the form 
\begin{align}
\parEst \Def \text{argmin}_{\Par \in \parSpace} \loss(\Par), \label{opt}
\end{align}
where $\loss(\Par)$ is a loss function, providing some notion of discrepancy between $\fwd(\Par)$ and $\obs$.
A common choice is the Euclidean distance (i.e., mean squared error),
\begin{align}
\loss(\Par) = \norm{\obs - \fwd(\Par)}^2_2 \Def \sum_{\obsIdx=1}^{\dimObs} (\obs_{\obsIdx} - \fwd_{\obsIdx}(\Par))^2. \label{l2_loss}
\end{align}
This quadratic loss can be extended to weighted generalizations via 
\begin{align}
\loss(\Par) = \norm{\obs - \fwd(\Par)}^2_{\obsCov} \Def (\obs - \fwd(\Par))^\top \obsCov^{-1} (\obs - \fwd(\Par)), \label{l2_loss_weighted}
\end{align}
for some positive-definite matrix $\obsCov \in \R^{\dimObs \times \dimObs}$. Note that \ref{l2_loss_weighted} reduces to 
\ref{l2_loss} by setting $\obsCov$ to the identity matrix. 

In theory, any standard optimization algorithms may be employed to solve this optimization problem. However, 
the typical black-box structure of $\fwd$ poses a challenge. If gradients are available, then gradient descent or 
(quasi)-Newton methods are a possibility. However, evaluations of $\fwd(\Par)$ may be prohibitively expensive, 
requiring specialized optimization routines designed to minimize the required number of model evaluations. 
So-called \textit{black box}, or \textit{derivative free}, optimization algorithms are designed for the setting 
in which gradient evaluations are not available. 

Another issue to contend with is the potential for $\loss(\Par)$ to have many local minima. The phenomenon in which 
multiple values of $\Par$ explain the observed data equally well is generally referred to as \textit{non-identifiability}, 
or \textit{equifinality}. One approach to mitigate non-identifiability issues is to incorporate prior information regarding 
the value of $\Par$. This can be accomplished via the addition of a \textit{regularization} term $\regularizer(\Par)$ in 
the objective function, yielding 
\begin{align}
\parEst \Def \text{argmin}_{\Par \in \parSpace} \left\{\loss(\Par) + \regularizer(\Par) \right\}. \label{opt_reg}
\end{align}
A common choice of regularizer is $\regularizer(\Par) = \frac{1}{c^2} \norm{\Par - \priorMean}_2^2$, with $c > 0$ tuning 
the strength of the regularization. As before, this can be generalized to 
$\regularizer(\Par) = \norm{\Par - \priorMean}_{\priorCov}^2 = (\Par - \priorMean)^\top \priorCov^{-1} (\Par - \priorMean)$, 
with $\priorCov$ another positive definite matrix. 
Choosing both a quadratic loss and quadratic regularization yields the common formulation
\begin{align}
\parEst \Def \text{argmin}_{\Par \in \parSpace} \left\{\norm{\obs - \fwd(\Par)}^2_{\obsCov} + \norm{\Par - \priorMean}_{\priorCov}^2\right\}. \label{quadratic_opt}
\end{align}
The first term quantifies the model fit, while the second encourages agreement between $\Par$ and $\priorMean$.

\subsection{Maximum Likelihood}
We now consider a frequentist statistical approach to the solution of inverse problems. Instead of defining a loss function, the 
starting point is now to consider a \textit{likelihood function} $p(\obs | \Par)$ (viewed as a function of $\Par$, with $\obs$ fixed). 
For example, we might assume that the observations $\obs$ are given by Gaussian perturbations of the underlying signal 
$\fwd(\Par)$, for some ``true'' value of $\theta$: 
\begin{align}
\obs | \Par &\sim \Gaussian(\fwd(\Par), \obsCov). \label{gaussian-lik}
\end{align}
In this case, the likelihood function is then given by $p(\obs | \Par) = \Gaussian(\obs | \fwd(\Par), \obsCov)$, with 
$\Gaussian(\obs | \fwd(\Par), \obsCov)$ denoting the density of $\Gaussian(\fwd(\Par), \obsCov)$ evaluated 
at $\obs$. Note that \ref{gaussian-lik} can equivalently be written as the additive error model 
\begin{align}
\obs &= \fwd(\Par) + \noise, && \noise \sim \Gaussian(0, \obsCov). 
\end{align}
As was the case with the loss function, evaluating the likelihood at $\fwd$ requires the forward 
model evaluation $\fwd(\Par)$. We can then define the solution to the inverse problem as the value 
of $\Par$ that maximizes the likelihood of the data; that is, 
\begin{align}
\parEst \Def \text{argmax}_{\Par \in \parSpace} \ p(\obs | \Par). \label{mle}
\end{align}
Maximizing $p(\obs | \Par)$ is equivalent to minimizing $\loss(\Par) \Def -\log p(\obs | \Par)$, so we can view the 
negative log-likelihood as defining a loss function, thus drawing a connection with the non-statistical optimization 
framework discussed above. Indeed, if we consider the Gaussian observation model \ref{gaussian-lik}, the log-likelihood
assumes the form 
\begin{align}
\loss(\Par) = -\log p(\obs | \Par) = \cst + \frac{1}{2} \norm{\obs - \fwd(\Par)}_{\obsCov}^2, 
\end{align}
where $\cst$ is a constant that depends only on $\obsCov$, not $\Par$. 
This implies that the MLE solution in the Gaussian noise setting is equal to the minimizer of the loss function 
\ref{l2_loss_weighted}. The observation covariance $\obsCov$ is often not known in practice, and hence can 
also be jointly optimized along with $\Par$. A regularization term can also be included in the same way as in the 
loss minimization framework. 

\subsection{Bayesian Methods}
The frequentist MLE approach views the unknown parameter $\Par$ as a fixed quantity, which we seek to estimate.
The Bayesian approach instead views $\Par$ as a random variable, and proceeds by defining a joint probability 
distribution on $(\Par, \obs)$. This is typically defined by noting that the joint distribution can be 
factored as $p(\Par, \obs) = p(\obs | \Par)p(\Par)$. The first term is the likelihood, which we already considered in 
the previous section. The new requirement is thus to define the \textit{prior distribution} $p(\Par)$, which encodes
domain knowledge about $\Par$ prior to observing the data $\obs$. We can now define the solution to the Bayesian 
inverse problem to be the conditional distribution $p(\Par | \obs)$, known as the \textit{posterior distribution}. 
Applying Bayes' rule shows that the posterior can be computed via 
\begin{align}
p(\Par | \obs) &= \frac{p(\obs | \Par) p(\Par)}{p(\obs)} \propto p(\obs | \Par) p(\Par). 
\end{align}
The denominator (known as the \textit{model evidence} or more generically the \textit{normalizing constant}) is 
not a function of $\Par$. Thus, so long as the data $\obs$ is viewed as fixed throughout the analysis, this constant 
is not a required input to most statistical inference algorithms. It is worth emphasizing that the solution to the Bayesian inverse problem 
is an entire distribution $p(\Par | \obs)$, whereas the loss minimization and MLE approaches instead resulted in point 
estimates of $\Par$. One can view the posterior $p(\Par | \obs)$ as assigning a weight to each possible value of 
$\Par$ that encodes both its fit to the data as well as its agreement with the prior.  
Therefore, the Bayesian approach is viewed as the gold standard for uncertainty quantification. In the Bayesian framework, 
the prior $p(\Par)$ acts as the regularizer, providing a probabilistic perspective on the regularization terms discussed previously. 

Within the loss minimization and MLE frameworks, the act of solving an inverse problem reduced to optimizing some 
objective function. In the Bayesian case, the key challenge is to extract useful information from the posterior distribution 
$p(\Par | \obs)$. In rare cases, the posterior assumes a well-understood analytical form (e.g., Gaussian). However, in 
general we must resort to computational methods. Extracting information from the posterior commonly implies
computing useful statistics (mean, median, mode, variance, quantiles, etc.) or drawing samples. 

We first consider computing the mode of the posterior distribution, which is known as the 
\textit{maximum a posteriori (MAP)} estimator. The MAP estimator solves the optimization problem 
\begin{align}
\parEst &\Def \text{argmax}_{\Par \in \parSpace} \ p(\Par | \obs), \nonumber \\
&= \text{argmin}_{\Par \in \parSpace} \left\{-\log p(\obs | \Par) - \log p(\Par) \right\} \label{map}
\end{align}
where we have taken the log, and have again re-written the maximization as a minimization by negating the objective function. 
We immediately see that \ref{map} is equivalent to the regularized MLE approach with $\regularizer(\Par) \Def -\log p(\Par)$ acting as the regularization term.
Choosing a uniform prior reduces to the classical (un-regularized) MLE setting. If we assume a Gaussian likelihood and prior, 
\begin{align*}
\obs | \Par &\sim \Gaussian(\fwd(\Par), \obsCov) \\
\Par &\sim \Gaussian(\priorMean, \priorCov), 
\end{align*} 
then the MAP optimization \ref{map} reduces to 
\begin{align}
\parEst \Def \text{argmin}_{\Par \in \parSpace} \left\{\norm{\obs - \fwd(\Par)}^2_{\obsCov} + \norm{\Par - \priorMean}_{\priorCov}^2\right\}, 
\end{align}
which is precisely equal to \ref{quadratic_opt}. We have thus established a connection between regularized loss minimization, regularized 
MLE, and MAP estimation. 

While the MAP estimate provides a nice interpretation of regularization, it again reduces to a single point estimate of $\Par$. The true 
power of Bayesian methods lies in the information provided by the entire posterior distribution. It is beyond the scope of these notes to 
summarize the wide array of techniques for interrogating the posterior, but we note that the most common method involves drawing 
samples from $p(\Par | \obs)$. These samples can then be used to estimate moments (mean, variance, etc.), generate histograms, 
and produce other posterior summaries. Markov chain Monte Carlo (MCMC) methods is a powerful class of algorithms for producing 
samples from arbitrary probability distributions. These algorithms are iterative, and simply require the ability to evaluate the 
unnormalized posterior density $p(\obs | \Par) p(\Par)$ given any value of $\Par$. Similar to standard iterative optimization algorithms, 
MCMC therefore requires one evaluation of the forward model $\fwd(\Par)$ for each iteration of the algorithm. It is not uncommon for 
MCMC to require $\BigO(10^5)$ or more iterations, which can render these algorithms infeasible for expensive forward models. 

% Parameter calibration 
\section{Parameter Calibration for LSMs}
We now return to the discussion of LSMs, mapping the generic inverse problem concepts introduced above to the problem 
of calibrating LSM parameters. Typically, the data $\obs$ in this setting consists of noisy observations of either carbon states 
or fluxes (or some function of these quantities). A key point is that the observations typically have a time series structure 
$\obs = \{\obs_{\indexTime[\firstTimeIdxObs]{\Time}}, \dots, \obs_{\indexTime[\lastTimeIdx]{\Time}}\}$ and may contain widely varying degrees of missing 
data. This often stems from the fact that the temporal resolution of the data differs from the time step used by the ODE solver.
This difference can be quite extreme depending on the dataset. For example, the ODE may be solved numerically using a sub-daily 
time step, while the time resolution of the calibration data products can vary from sub-daily (e.g., eddy covariance flux observations) 
to annual (e.g., field measurements of soil and leaf litter). It is common to calibrate LSM parameters using multiple data sources of 
varying temporal resolution, though we defer such discussions of multi-objective calibration to \Cref{multi-objective}. 
We start by considering the case of a single data source $\obs = \{\obs_{\indexTime[\firstTimeIdxObs]{\Time}}, \dots, \obs_{\indexTime[\lastTimeIdx]{\Time}}\}$, 
in which some or many of the $\obs_{\indexTime{\Time}}$ may be missing. We then define the forward model 
$\fwd: \parSpace \to \R^{\Ntime}$ as the map from $\Par$ to the trajectory of model outputs that are directly comparable to 
$\obs$. \Cref{ex:lsm-state-obs} provides a concrete example where $\obs$ contains noisy observations of the first state variable, 
in which case $\fwd(\Par)$ returns the predicted model trajectory of the first state. 


\subsection{Parameter Structure}
PFTs, identifiability/equifinality, non-linear dependence 

\subsection{Parameter Dimension Reduction}
Parameter fixing, potential for more sophisticated methods, scaling factors for PFTs

\subsection{Learning Initial Conditions}

\subsection{Spatial Considerations}
\subsubsection{Change-of-Support}
\subsubsection{Impure Pixels}
\subsubsection{Parameter Variability}

\subsection{Multi-Objective Calibration} \label{multi-objective}

\subsection{Connections with State Estimation}

% Surrogate Modeling 
\section{Surrogate Modeling}

\end{document} 




