\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage{algorithmic}
\usepackage[ruled,vlined,commentsnumbered,titlenotnumbered]{algorithm2e}
\usepackage{bbm}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bx}{\mathbf{x}}

\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}


\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% For embedding images
\graphicspath{ {./images/} }

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}

% Title and author
\title{Loss Emulation for Scalable Ecosystem Model Calibration}
\author{Andrew Roberts}

\begin{document}

\maketitle
\tableofcontents
\newpage

% Notation 
\section{Notation}

\subsection{Statistical Setting}
We denote the vector of calibration parameters by $\btheta \in \Theta \subset \R^D$. The forward model (e.g. SIPNET or ED2) $G(\btheta)$ maps calibration parameters to the model outputs. Note that the forward 
model also depends on initial conditions and model drivers, but these are fixed throughout the analysis so are suppressed in the notation. Model outputs consist 
of $T$ time steps for each of $P$ output variables, so $G(\btheta) \in \mathbb{R}^{T \times P}$. We have observed data $Y \in \mathbb{R}^{T \times P}$, potentially with missing values. Let $T_p$ denote the number 
of non-missing observations of output variable $p$. We index the observations of output $p$ as $\{y_{tp}\}_{t = 1}^{T_p}$, meaning that $Y$ is then technically a ragged matrix. 
This is suitable for the model detailed below, as the ordering of the observations is inconsequential. 

To measure error between model 
predictions $G(\btheta)$ and observed data $Y$, we assume the following Gaussian noise model. 
\begin{align*}
\mathcal{L}(\btheta) := p(Y|\mathbf{\btheta}) = \prod_{p = 1}^{P} \prod_{t = 1}^{T_p} \mathcal{N}\left(y_{tp}| G_{tp}(\btheta), \sigma_p^2 \right)
\end{align*}
This likelihood assumes the errors are independent across time and output variable. Note that $\mathcal{L}(\btheta)$ depends on $Y$, but $Y$ is constant throughout the analysis so we drop it from the notation. Missing 
observations are simply ignored, hence the product from $t = 1, \dots, T_p$ for each output $p$.

For notational convenience, we collect the variance parameters in the matrix $\Sigma := \text{diag}\left(\sigma_1^2, \dots, \sigma_P^2 \right)$. 
We denote the priors on the calibration and variance parameters as  $\pi_0(\btheta, \Sigma) = \pi_0(\btheta)\pi_0(\Sigma)$, assuming prior independence.  
The variances $\sigma_p^2$ are assigned inverse gamma priors $\sigma_p^2 \overset{ind}{\sim} \mathcal{IG}(\alpha_p, \beta_p)$ so that 
\[\pi_0(\Sigma) = \prod_{p = 1}^{P} \mathcal{IG}(\sigma_p^2|\alpha_p, \beta_p)\]
Combining these priors with the likelihood yields the posterior 
\[\pi(\btheta, \Sigma) := p(\btheta, \sigma_1^2, \dots, \sigma_P^2|Y) \propto \mathcal{L}(\btheta)\pi_0(\btheta, \Sigma)\]

\subsection{Surrogate Model}
In this section we describe the emulator used to approximate the true likelihood $\mathcal{L}(\btheta)$. The likelihood can be written as 
\begin{align*}
\mathcal{L}(\btheta) &= \prod_{p = 1}^{P} \prod_{t = 1}^{T_p} \mathcal{N}\left(y_{tp}| G_{tp}(\btheta), \sigma_p^2 \right) \\
			       &= \prod_{p = 1}^{P}  \prod_{t = 1}^{T_p} (2\pi \sigma_p^2)^{-1/2} \exp\left(-\frac{1}{2\sigma_p^2} (y_{tp} - G_{tp}(\btheta))^2 \right) \\
			       &= (2\pi)^{-\frac{1}{2} \sum_{p = 1}^{P} T_p}  \prod_{p = 1}^{P}  (\sigma_p^2)^{-T_p/2} \exp\left(-\frac{1}{2\sigma_p^2} \sum_{t = 1}^{T_p} (y_{tp} - G_{tp}(\btheta))^2  \right) \\
			       &= (2\pi)^{-\frac{1}{2} \sum_{p = 1}^{P} T_p}  \prod_{p = 1}^{P}  (\sigma_p^2)^{-T_p/2} \exp\left(-\frac{1}{2} \frac{\Phi_p(\btheta)}{\sigma_p^2} \right)
\end{align*}
where 
\[\Phi_p(\btheta) := \sum_{t = 1}^{T_p} (y_{tp} - G_{tp}(\btheta))^2\]
is the sum of squared errors between the observed data and the model output for the $p^{\text{th}}$ output variable. Note that $\Phi_p(\btheta)$ also depends on $Y$, but again we suppress this in the notation. The key observation 
is that the model evaluations $G(\btheta)$ only appear in the likelihood through the $\Phi_p(\btheta)$, which means that approximating $\Phi_p(\btheta)$ will induce an approximation of the likelihood. The independence assumptions 
that yield the product form of the likelihood make it so that $\Phi(\btheta)$ is a sufficient statistic which is not a function of the variance parameters. This means that $\Phi(\btheta)$ can be emulated without regard for the variance parameters, 
and then inference can be performed over the variance parameters as usual. The choice to emulate the mappings $\Phi_p: \Theta \to \R$ also reduces the problem to 
approximating $P$ univariate functions, instead of approximating $G(\btheta)$, which has output dimension $T \times P$. 

Our emulator of choice uses Gaussian processes (GP). In particular, we treat the $\Phi_p$ as unknown and assign them independent GP priors
\[\Phi_p(\cdot) \overset{ind}{\sim} \mathcal{GP}(\mu_p, k_p(\cdot, \cdot))\] 
where $\mu_p$ is a constant mean and $k_p(\cdot, \cdot)$ a covariance function (i.e. kernel). The constant mean and kernel hyperparameters are fixed to their MLE estimates. We then run the forward model at carefully selected 
\textit{design points} $\btheta_1, \dots, \btheta_N \in \Theta$ and compute $\{\Phi_p(\btheta_n)\}_{1 \leq p \leq P, 1 \leq n \leq N}$. 

We denote the resulting observed data for output $p$ as 
$\mathcal{D}_p := \left\{(\btheta_1, \Phi_1(\btheta_1)), \dots, (\btheta_P, \Phi_p(\btheta_P))  \right\}$ and collect the observed outputs in a vector 
$\boldsymbol{\phi}_p = \left[\Phi_1(\btheta_1), \dots, \Phi_P(\btheta_1) \right]^T$. Conditioning the GPs on the observed data yields the GP predictive distributions 
\[\Phi_p(\cdot)|\mathcal{D}_p := \Phi_p^*(\cdot) \sim \mathcal{GP}(\mu^*_p(\cdot), k_p^*(\cdot, \cdot)), \text{ for } p = 1, \dots, P\]
where 
\begin{align*}
\mu_p^*(\btheta) &= \mu_p  - \mathbf{k}^T \mathbf{K}^{-1} \left(\boldsymbol{\phi}_p - \mu_p \right) \\
\end{align*}

\subsection{The big picture: dynamic emulators}
I believe this work nicely complements a series of papers on so-called \textit{dynamic} or \textit{time-series valued} emulation. The necessity of such emulators typically arise from forward models 
defined as a the solution of an autonomous system of ODEs. I will denote the state vector of such a system by 
\[\bx(t) = \left(x_1(t), \dots, x_K(t) \right)^T \]
If we consider discretizing at constant time steps $\Delta t$ then since the system is autonomous then the \textit{one-step map} or \textit{flow map} $g: \R^K \to \R^K$ is time-independent: 
 \[\bx(t + \Delta t) = g(\bx(t))\]
 Note that this could also be generalized to variable step sizes $\Delta t$ by considering the flow map to also be a function of the step size; i.e., $g = g(\bx(t), \Delta t)$. We can also view the 
 vector-valued $g$ as a collection of $K$ univariate flow maps
 \[g(\bx(t)) = \left(g_1(\bx(t)), \dots, g_K(\bx(t)) \right)^T\]
 so that $g_k: \R^K \to \R$ maps $\bx(t)$ to $\bx_k(t + \Delta t)$, the value of the $k^{\text{th}}$ state at the subsequent time step. Of course, $g$ and hence the states $\bx(t)$ depend on 
 the parameters $\btheta$. I will reflect this dependence by writing $g_\theta$ and $\bx_\theta(t)$. The forward model $G: \R^D \to \R^{T \times P}$ defined previously can thus be characterized 
 as 
 \[
 G(\btheta; \bx_0) = \begin{pmatrix} \bx_0^T \\ \bx_\theta(\Delta t)^T \\  \bx_\theta(2\Delta t)^T \\ \vdots \\ \bx_\theta\left([T-1]\Delta t\right)^T \end{pmatrix} = 
 \begin{pmatrix} \bx_0^T \\ g_\theta(\bx_0)^T \\  g_\theta\left(g_\theta(\bx_0)\right)^T \\ \vdots \\ g_\theta^{(T-1)}(\bx_0)^T \end{pmatrix}
 \]
 where I now explicitly write $G$ as a function of an initial condition $\bx_0 = \bx(0)$, which is independent of $\btheta$, and I use the shorthand $g_\theta^{(k)}$ to denote 
 the composition consisting of $k$ applications of the map $g_\theta$. I have also assumed that the initial time is $0$, but 
 some other time $t_0$ could of course be considered. 

% Abstract 
\section{Abstract}
The primary scientific goal is to improve prediction and understanding of ecosystem dynamics. By combining the strengths of mechanistic models and data-driven analysis, model-data fusion 
has proven to be a valuable approach in working towards this goal. Effective model-data fusion requires careful and robust uncertainty quantification. In particular, uncertainty must be acknowledged 
in empirically-determined estimates of process model parameters. A Bayesian statistical framework...

% Background/Literature Review
\section{Background/Literature Review}
From a methodological point of view, I see this paper as existing at the intersection of the computer experiments and Bayesian inverse problem fields. 
 
 \subsection{Likelihood Emulators/Loss Emulators/Scalarization}
 The idea of reducing dimensionality by emulating some sort of scalar-valued function summarizing the model-data discrepancy (e.g. loss function, log-likelihood) is certainly well-known, but 
 it is difficult to find any sort of systematic study of this approach or comparison to alternative approaches. 
 
 The paper \cite{LEBEL2019158} utilizes a GP approximation of the log-likelihood 
 $\ell(\btheta) := \log \mathcal{L}(\btheta)$. This requires fixing the likelihood parameters in advance. Their GP-assisted MCMC algorithm consists of posterior evaluations of the form 
 \[\hat{\pi}(\btheta) = \frac{1}{L} \sum_{l = 1}^{L} \pi(\btheta|\ell_l) \text{, where } \ell_l \overset{iid}{\sim} \ell^*(\btheta)\]
 where $\pi(\btheta|\ell_l)$ indicates the deterministic posterior density approximation constructed by plugging in $\ell_l$ in place of the true log-likelihood $\ell(\btheta)$. 
 The current PEcAn approach generally utilizes the same approximation with $L = 1$ (and emulating $\Phi(\cdot)$ instead of $\ell(\cdot)$). For simplicity above, I wrote 
 $\ell_l \overset{iid}{\sim} \ell^*(\btheta)$, indicating pointwise GP predictive draws. Surprisingly, this is not actually what the authors do. They are 
 instead concerned with sampling GP trajectories (functions) $\ell_l(\cdot) \overset{iid}{\sim} \ell^*(\cdot)$; that is, they seek to draw GP realizations across the entire input space 
 which respect the correlation structure, and then evaluate those realizations at $\btheta$ to obtain the final values $\{\ell_l\}_{l = 1}^{L} = \{\ell_l(\btheta)\}_{l = 1}^{L}$. Since doing this 
 would require sampling the GP over a dense grid of points, they instead propose an approximation that only uses a sparse set of ``conditioning points''. The conditioning 
 set $\Theta_c \subset \Theta$ is defined to target regions where the GP is confident that the likelihood is larger. In particular, it is defined as 
 \begin{align*}
\Theta_c &:= \left\{\btheta \in \Theta : \Prob\left(\ell^*(\btheta) > \ell^*(\btheta_{\text{max}}) \right) > \rho \right\} \\
\btheta_{\text{max}} &:= \text{argmax}_{\btheta \in \Theta} \E\left[\ell^*(\btheta)\right]
 \end{align*}
 where $\rho \in [0, 1]$ is some specified threshold. i.e., the conditioning set is the subset of the input space where the GP assigns high probability of improvement. The authors' description is 
 not entirely clear to me, but I believe this is what they do to construct each $\ell_l$: 
 \begin{enumerate}
 \item Draw samples at the conditioning points: $\ell(\Theta_c) \sim \ell^*(\Theta_c)$. 
 \item Treat $\left(\Theta_c, \ell(\Theta_c)\right)$ as pseudo-data and condition the GP $\ell^*$ on this pseudo-data as if they were true observations. Denote the conditioned GP as $\ell^*_c$. 
 \item Return $\ell_i := \E\left[\ell_c^*(\btheta) \right]$
 \end{enumerate}
 I believe the idea is to condition so that the uncertainty in the distribution collapses and the mean function of the conditioned GP is hopefully a good approximation of the trajectory. Note that 
 $\left(\Theta_c, \ell(\Theta_c)\right)$ are observations of the true trajectory. All of this seems a bit odd to me given that ultimately a prediction is only required at $\btheta$, so why not just 
 use the GP marginal?  
 
 
 \subsection{Dynamic Emulators}
 There have been many proposals to emulate such dynamical systems. Many such approaches consider emulation of the trajectory $\{\bx_\theta(k\Delta t)\}_{k = 1}^{T-1}$ as a function of 
 the initial condition $\bx_0$, but assuming fixed $\btheta$. This is not very useful when parameter calibration is the goal, as the dynamics change when $\btheta$ changes. I briefly summarize some 
 of the relevant literature below. 
 
 \subsubsection{Early work of Conti and O'Hagan}
 Here I summarize the papers \cite{10.1093/biomet/asp028} and \cite{CONTI2010640}. 
 
\subsubsection{Emulating the Flow Map}
Although they assume $\btheta$ to be fixed, Mohammadi et al (2018) \cite{MOHAMMADI2019178} propose some interesting ideas. They focus on emulating the flow map $g(\cdot)$ 
(I omit the $\btheta$ subscript as it is constant here). The idea is to fix a small step $\Delta t$, and learn a map from the initial condition $\bx_0$ to $\bx(\Delta t)$. This produces an emulator 
that can produce one-step-ahead predictions. Their emulator consists of $K$ univariate emulators, one for each $g_k(\cdot)$. Prediction requires iteratively composing GP predictions, which 
propagates the uncertainty forward. This can actually be viewed as a deep GP, though it avoids the main difficulty of having to fit kernel hyperparameters in a deep GP. Inference is conducted 
via a Monte Carlo approach, propagating GP samples iteratively through each time step. 

\bigskip
\textbf{Questions:} 
\begin{enumerate}
\item What are the weaknesses of current approaches to solving this problem? How does our method overcome these weaknesses? 
\item \textbf{What are the strengths and weaknesses of loss emulation?} \\ 
In this high-dimensional output setting, some sort of dimensionality reduction is required. The alternatives to loss emulation are dynamic emulation (i.e. emulating the flow map) or 
emulating the parameters in a basis representation of the output. 
\item \textbf{What is the effect of range-constraint in loss emulation?} 
\item \textbf{What are effective strategies for running emulator-assisted MCMC?}
\end{enumerate}

\begin{enumerate}
\item \textbf{Problem}: Improve prediction and understanding of ecosystem dynamics. \\
	\textbf{Solution}: Model-data fusion; combining strengths of mechanistic models and data-driven approaches. 
\item \textbf{Problem}: Effective model-data fusion requires careful and robust UQ. In particular, uncertainty must be acknowledged in empirically-determined estimates of process model parameters. \\
\textbf{Solution}: Bayesian approach. 
\item \textbf{Problem}: Bayesian inference with MCMC is infeasible when the forward model runtime is very costly. \\
\textbf{Solution}: Approximate the forward model. 
\end{enumerate}

\section{Introduction}

\section{Methods}

\subsection{Statistical Model}
\subsubsection{Likelihood: Multi-objective calibration}

\subsubsection{Priors}

\bigskip
\noindent
\textbf{Question}: Does PEcAn currently always assume prior independence across the $\theta_d$? 

\subsubsection{Exact MCMC-based inference}

\subsection{Loss Emulation}
Every iteration of MCMC requires evaluation of the forward model $G(\btheta)$. If this evaluation is costly, then this will render MCMC computationally intractable. To address this, we employ a surrogate modeling approach. 
The forward model $G(\btheta)$ is replaced by an an approximation $\hat{G}(\btheta)$ known as an \textit{emulator}. Assuming $\hat{G}(\btheta)$ is much faster to evaluate then we substitute it for the exact model and thus 
sample from the approximate posterior
 \[\hat{\pi}(\btheta, \Sigma) \propto \hat{\mathcal{L}}(\btheta)\pi(\btheta)p(\Sigma)\]
 where 
 \begin{align*}
\hat{\mathcal{L}}(\theta) = \prod_{p = 1}^{P} \prod_{t = 1}^{T_p} \mathcal{N}\left(y_{tp}| \hat{G}_{tp}(\btheta), \sigma_p^2 \right)
\end{align*}
 
\subsubsection{Emulator Details}
\begin{enumerate}
\item \textbf{Problem}: The model output $G(\btheta)$ has dimension $T \times P$. For any reasonable number of time steps $T$, the high-dimensionality of the output renders the problem of directly emulating $G$ intractable.  \\
	\textbf{Solution}: One approach is to reduce the dimensionality of the output by representing it with respect to a basis, and then instead emulate the mapping from $\btheta$ to the basis coefficients. We consider an alternative 
	of instead directly emulating the loss between the forward model and observed data. 
	
\item \textbf{Problem}: Issues with emulating the $\Phi_p$: non-linear, need to account for uncertainty in approximation. \\
\textbf{Solution}: GP emulators. \\
I need to write out this section, but to establish notation I briefly note that I will write $\Phi_p^*$ to denote the posterior/predictive distribution; i.e. the random field approximation of $\Phi_p$. I intentionally refrain from calling 
this the predictive \textit{GP} since technically this could be a rectified or truncated Gaussian, or sometimes a Student-t process. This induces a random field approximation of the likelihood, which I similarly write as 
$\mathcal{L}^*$, noting that the randomness in $\mathcal{L}^*$ comes from $\Phi^*_1, \dots, \Phi^*_P$. 
	
\end{enumerate}

\subsubsection{Emulator-based MCMC inference}


\subsection{Sequential Design}
\begin{enumerate}
\item \textbf{Problem}: While space-filling designs (e.g. via LHS or maximin) are common, they can be very inefficient in the Bayesian inverse problem setting. If the posterior distribution is concentrated in a small 
subset of the parameter space, then space-filling designs will yield many design points in regions that are not of interest, while simultaneously under-sampling the region of significance.  \\
	\textbf{Solution}: Sequential design approach that takes into account knowledge of the posterior as it proceeds. 
	
\subsection{Other things?}
\begin{itemize}
\item Scaling factors for PFTs. 
\item Imbalanced data constraints. 
\end{itemize}
	
\end{enumerate}

% Details on Specific Methods
\section{Details on Specific Methods}

\subsection{Evaluation Metrics}

\begin{enumerate}
\item Challenges: 
	\begin{enumerate} 
	\item Assessing GP performance in a way that takes into account the GP distribution, i.e. challenge of validating probabilistic forecasts. 
	\item The fact that we would like metrics to take into account the true posterior over $\btheta$ when possible. 
	\end{enumerate}
\item \textit{Diagnostics for Gaussian Process Emulators} (Bastos and O'Hagan, 2009) \\
Discusses various criteria for evaluating GP emulators. A lot of focus is on defining suitably standardized residuals, the tricky part being that GP residuals are correlated. For example, interpreting 
a QQ plot with typical standardized residuals is a bit difficult given the fact that the residuals are correlated. 
\item \textit{Diagnostics and Simulation-Based Methods for Validating Gaussian Process Emulators} (Al-Taweel, PhD thesis from 2018). 
\item \textit{Quantifying Model Error in Bayesian Parameter Estimation} (White, PhD thesis from 2015)
\item Strictly proper scoring rules/CRPS
\item Would like to read up on some more applied papers (e.g. Simon Mak's work on emulating spatiotemporal flows) to see what sort of metrics they report. 
\end{enumerate}

\subsection{Range-Constrained GP}
\subsubsection{Do nothing to constrain GP prior}
\begin{itemize}
\item Current approach; instead transform GP posterior to truncated or rectified Gaussian. 
\item Concern is that the prior is wrong, so may compromise GP fit and uncertainty calibration. 
\end{itemize}

\subsubsection{Warped GP}
\begin{itemize}
\item For example, a log-normal or square root GP. 
\item We have seen that blindly applying the log-normal process (LNP) leads to very bad results due to the funneling effect of the log-transformation; i.e. the sum of squared residuals (SSR) often exhibits a very high dynamic range, 
with some very large values and others that are almost zero. In the VSEM examples at least, this effect was especially bad as the funneling occurs at some values of SSR, which means the emulator fared worse in the 
most important region of the parameter space. 
\item In simple one-dimensional examples, I showed a while back that instead transforming the data as $\log\left(\Phi_p(\theta) + C \right)$ for a well-chosen constant $C$ could yield nice LNP results. One approach to explore 
would be to optimize the value of $C$. 
\end{itemize}

\subsubsection{Other range-constrained GP methods that have been proposed:}
\begin{enumerate}
\item ``fit all available model data and impute a set of ``artificial data"" throughout the input space points that maintain the constraint.'' (Spiller et al, 2023)
\item Another approach: modify the MLE for hyperparameter fitting. In particular, Pensoneault et al., 2020 propose a method whereby the lengthscale parameters are constrained so that the predictive GP obeys the 
range constraint at untested inputs with high probability. This has the benefit that the predictive GP distribution is still Gaussian, as opposed to some other methods. 
\item \textit{The Zero Problem: Gaussian Process Emulators for Range-Constrained Computer Models} (Spiller et al, 2023) \\
They are dealing with zero-censored computer models, and they consider a prior on the computer model $f(\btheta)$: $f(\btheta) \sim \max \left\{0, g(\btheta) \right\}$ where $g \sim \mathcal{GP}$. Not that relevant to our 
case but some interesting ideas here.  
\end{enumerate}


\subsection{Sequential Design}

\subsubsection{Sinsbeck and Nowak (2017)}
Sinsbeck and Nowak \cite{doi:10.1137/15M1047659} propose a sequential design method which constructs and refines a deterministic approximation to the true likelihood $\mathcal{L}(\btheta)$ at each iteration of the sequential design procedure. 
This likelihood approximation is then used to construct an acquisition function that targets regions of high posterior density. I summarize their method here, with adjustments to tailor the method to our loss-emulation setting. 

\bigskip
\noindent
\textbf{Deterministic likelihood approximation.}
The first step is to construct the deterministic likelihood approximation $\hat{\mathcal{L}}_n(\btheta)$ from 
$\mathcal{L}^*_n(\btheta)$, where the subscript $n$ indicates that both the random field approximation $\mathcal{L}^*_n(\btheta)$ and deterministic approximation $\hat{\mathcal{L}}_n(\btheta)$ have been constructed from the data 
$\mathcal{D}_n = \left\{(\btheta_1, \mathcal{L}(\btheta_1)), \dots, (\btheta_n, \mathcal{L}(\btheta_n)) \right\}$. One option is to define $\hat{\mathcal{L}}_n(\btheta)$ as the approximation resulting from plugging in the GP predictive 
means. However, this fails to account for the uncertainty encoded by the GP predictive distribution. Sinsbeck and Nowak take a more principled approach, defining $\hat{\mathcal{L}}_n(\btheta)$ as the approximation that minimizes 
a certain loss criterion. The loss criterion of choice is the prior-weighted $L^2$ error:
\[\ell(\mathcal{L}, \mathcal{L}^\prime) := \E_{\btheta}\left[\left(\mathcal{L}(\btheta) - \mathcal{L}^\prime(\btheta) \right)^2 \right]\]
where the notation $\E_{\btheta}(\cdot)$ indicates integration with respect to the prior $\pi_0$. 
However, in this setting the goal is to choose the $\hat{\mathcal{L}}_n$ that minimizes error with respect to a \textit{random} approximation $\mathcal{L}_n^*$. Thus, the error measure is defined as the 
expectation of $\ell(\mathcal{L}^*_n, \hat{\mathcal{L}}_n)$ with respect to the GP $\Phi^*$. This yields the \textit{Bayes' risk}
\[\mathcal{R}(\mathcal{L}_n^*, \mathcal{L}_n) := \E_{\Phi^*} \E_{\btheta} \left[\left(\mathcal{L}^*(\btheta) - \mathcal{L}(\btheta) \right)^2 \right] \]
The deterministic approximation is taken as the minimizer  
\[\hat{\mathcal{L}}_n := \text{argmin}_{\mathcal{L}_n} \mathcal{R}(\mathcal{L}_n^*, \mathcal{L}_n) \]
which can be shown to be given by 
\[\hat{\mathcal{L}}_n(\btheta) = \E_{\Phi^*}\left[\mathcal{L}_n^*(\btheta) \right]\]
i.e. the approximation resulting from integrating the GP out of the random field $\mathcal{L}_n^*(\btheta)$. Evaluated at the optimizer, the Bayes' risk reduces to the prior-weighted predictive variance 
of $\mathcal{L}_n^*(\btheta)$: 
\begin{align}
\hat{\mathcal{R}}(\mathcal{L}_n^*) := \mathcal{R}(\mathcal{L}_n^*, \hat{\mathcal{L}}_n) = \E_{\btheta} \Var_{\Phi^*}\left[\mathcal{L}_n^*(\btheta)\right] \label{Bayes_Risk}
\end{align}
The authors also consider a ``fully Bayesian'' likelihood estimation approach, which turns out to result in the same exact estimator. 

\bigskip
\noindent
\textbf{Acquisition Function.}
The authors propose a greedy one-step look ahead strategy. Intuitively, we assess the quality of a new design point $\tilde{\btheta}$ by considering the GP predictive distribution 
at this proposed point $\tilde{\Phi} := \Phi(\tilde{\btheta})$. We use this predictive distribution to predict what Bayes' risk \ref{Bayes_Risk} would be were we to observe 
$(\tilde{\btheta}, \tilde{\Phi})$ and condition on this additional observation. Recall that $\hat{\mathcal{R}}(\mathcal{L}_n^*)$ denotes the Bayes' risk between the 
random field approximation and optimal deterministic approximation. I introduce the notation $\tilde{\mathcal{L}}^*_n := \mathcal{L}^*_n|\tilde{\btheta}, \tilde{\Phi}$ to denote the 
random field likelihood approximation conditioned on $(\tilde{\btheta}, \tilde{\Phi})$. Note that the forward model has not yet been run at input parameter $\tilde{\btheta}$ so 
$\tilde{\Phi}$ is itself a random variable. I utilize the same notation for the GP itself, so that $\tilde{\Phi}^*_n := \Phi^*_n|\tilde{\btheta}, \tilde{\Phi}$

With this notation established, $\hat{\mathcal{R}}(\tilde{\mathcal{L}}^*_n)$ is an estimator for the future Bayes' risk, were we 
to run the forward model at $\tilde{\btheta}$. In order to define a deterministic acquisition function, we must now integrate over the distribution of $\tilde{\Phi}$, in addition to the two other 
integrals in the original definition of the Bayes' risk. This yields the acquisition function, 
\begin{align}
J_n(\tilde{\btheta}) &:=  \E_{\tilde{\Phi}} \hat{\mathcal{R}}(\tilde{\mathcal{L}}^*_n) \\ 
			     &= \E_{\tilde{\Phi}} \E_{\btheta} \Var_{\tilde{\Phi}_n^*}\left[\tilde{\mathcal{L}}_n^*(\btheta) \right]
\end{align}
Note that the acquisition function is a function of $\tilde{\btheta}$, a new design point; not to be confused with the $\btheta$ in the second line above, which is averaged over by 
$\E_{\pi_0}(\cdot)$. 

This is the final acquisition function considered in the paper. However, in our case the likelihood parameters $\Sigma$ are not known. We could consider augmenting to include these 
parameters and integrate over the prior on the likelihood parameters as well: 
\begin{align}
J_n(\tilde{\btheta}) &:= \E_{\tilde{\Phi}} \E_{\Sigma} \E_{\btheta} \Var_{\tilde{\Phi}_n^*}\left[\tilde{\mathcal{L}}_n^*(\btheta, \Sigma) \right]
\end{align}

\bigskip
\noindent
\textbf{Approximating the Acquisition Function.}

\bigskip
\noindent
\textbf{Questions.}
\begin{enumerate}
\item How could this be modified to take advantage of parallel computing resources? 
\item Are the authors assuming the likelihood parameters are known/fixed? How would we account for unknown likelihood parameters? 
\end{enumerate}

\subsubsection{Ensemble Kalman Inversion}
TODO


\bibliography{first_paper} 
\bibliographystyle{ieeetr}


\section{References}
\begin{itemize}
\item Emulating dynamic non-linear simulators using Gaussian processes (Mohammadi et al, 2019)
\item Mechanism-based emulation of dynamic simulation models: Concept and application in hydrology (Reichert et al, 2016)
\item Gaussian process emulation of dynamic computer codes (Conti et al, 2009) (Resource for one-step-ahead emulator)
\item Evolving Bayesian emulators for structured chaotic time series, with application to large climate models. (Williamson and Blaker, 2014)
\item A dynamic modelling strategy for Bayesian computer model emulation (Liu and West, 2009)
\item Emulating complex dynamical simulators with random Fourier features (Mohammadi et al, 2023)
\item Sequential adaptive design for emulating costly computer codes (Mohammadi et al, 2022)
\item Emulation-accelerated Hamiltonian Monte Carlo algorithms for parameter estimation and uncertainty quantification in differential equation models (Paun and Husmeier, 2021)
\item Sequential design of computer exper- iments for the estimation of a probability of failure (Bect et al, 2012)
\item Kriging Is Well-Suited to Parallelize Optimization (Ginsbourger et al, 2010)
\end{itemize}



\end{document}




