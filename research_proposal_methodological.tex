\documentclass[12pt]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[main=english]{babel}
\usepackage[rm={lining,tabular},sf={lining,tabular},tt={lining,tabular,monowidth}]{cfr-lm}
\usepackage{amsthm,amssymb,latexsym,gensymb,mathtools,mathrsfs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{epstopdf,enumitem,microtype,dcolumn,booktabs,hyperref,url,fancyhdr}
\usepackage[margin=0.5in]{geometry}

% Plotting
\usepackage{pgfplots}
\usepackage{xinttools} % for the \xintFor***
\usepgfplotslibrary{fillbetween}
\pgfplotsset{compat=1.8}
\usepackage{tikz}

% Custom Commands
\newcommand*{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand*{\suchthat}{\,\mathrel{\big|}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\R}{\mathcal{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Cor}{\mathrm{Corr}}
\newcommand{\Prob}{\mathbb{P}}
\DeclarePairedDelimiterX\innerp[2]{(}{)}{#1\delimsize\vert\mathopen{}#2}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\def\R{\mathbb{R}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\setlist{topsep=1ex,parsep=1ex,itemsep=0ex}
\setlist[1]{leftmargin=\parindent}
\setlist[enumerate,1]{label=\arabic*.,ref=\arabic*}
\setlist[enumerate,2]{label=(\alph*),ref=(\alph*)}

% Specifically for paper formatting 
\renewcommand{\baselinestretch}{1.2} % Spaces manuscript for easy reading

% Formatting definitions, propositions, etc. 
\newtheorem{definition}{Definition}
\newtheorem{condition}{Condition}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{notation}{Notation}

\begin{document}

\begin{center}
Scalable Bayesian Methods for Scientific Machine Learning
\end{center}

\begin{flushright}
Andrew Roberts
\end{flushright} 

The effectiveness of combining physics and simulation-based models with statistical and machine learning methods is increasingly being recognized \cite{Willcox}. Physical models
encapsulate prior scientific knowledge, while a Bayesian statistical framework allows for principled inference, prediction, and uncertainty quantification. This interplay between domain 
knowledge and statistical inference is essential for advancing scientific theory and informing high-consequence decision-making. My research goal is to develop novel methodological 
and computational approaches for model calibration, prediction, and uncertainty quantification for scientifically-informed modeling of complex systems. 

I will focus on the setting of a deterministic computer model $f: \R^d \to \R$ as a function of some unknown parameters $\theta \in \R^d$. [insert example here] In general, I will allow
for these models to depend on additional covariates and produce multiple outputs (i.e. $f: (x, \theta) \to \R^k$), but I omit these complexities here for notational convenience. Suppose 
we obtain observational data $y$ corresponding to the quantity that $f$ tries to predict; that is, we want $f(\theta) \approx y$. This is a standard \textit{inverse problem}, in which
the un-observed quantity $\theta$ must be inferred from the observed data $y$. Typically, $f$ is highly non-linear, non-invertible, and direct numerical solution to this equation may be extremely sensitive
to small perturbations of $y$ (i.e. this problem is ill-posed). It is therefore typically preferable to re-frame the inverse problem in a Bayesian statistical setting, as in the simple Gaussian error model below. 
\begin{align*}
y_i &= f(\theta) + \epsilon_i \\
\epsilon_i &\overset{iid}{\sim} N(0, \sigma^2) \\
(\theta, \sigma^2) &\sim \pi_0 \\
\end{align*}
Here, the prior distribution $\pi_0$ encodes domain knowledge about the unknown calibration parameters $\theta$ and statistical parameter $\sigma^2$, and we suppose the observed data is given by 
$y = (y_1, \dots, y_n)^T$. ``Solving'' this inverse problem is now interpreted as finding the joint posterior distribution
\[\pi(\theta, \tau|y) \propto N(y|f(\theta), \sigma^2 I_n)\pi_0(\theta, \sigma^2)\]
or the marginal posterior $\pi(\theta|y)$, which can be obtained by marginalizing over $\sigma^2$. My research will focus on characteristics of this setup commonly found in scientific applications: 1.) $f(\theta)$ is
costly to compute, 2.) uncertainty quantification is essential, and 3.) the underlying process of interest exhibits significant spatial and/or temporal variation. The first constraint typically precludes iterative inference 
procedures like Markov Chain Monte Carlo (MCMC), instead demanding approximation techniques such as statistical emulation. A common approach is to fit a Gaussian process emulator 
$\hat{f}(\cdot) \sim \mathcal{GP}(m(\cdot), k(\cdot, \cdot))$ to approximate the true model $f$, and then using $\hat{f}$ in place of $f$ in the inference algorithm. The second point implies that optimizing $\theta$ is not enough; informed  decision-making based on the model requires summarizing the distribution of possible parameter values, which should incorporate all possible sources of uncertainty. Finally, while the above statistical model is static, the physical phenomenon of interest often exhibits spatiotemporal variation, which should be included in the model if one hopes to draw general scientific conclusions and make predictions 
across unobserved space and time. \\

\noindent
\textbf{Research Plan.} To address these problems, I will begin by developing baseline methods for incorporating emulator uncertainty into the statistical inference algorithm in order to achieve more ``honest''
uncertainty quantification. I will then generalize the statistical model to explicitly incorporate spatial information, seeking to improve predictive power and allowing for uncertainty to be analyzed across
the spatial dimension. Finally, I generalize to a full spatiotemporal model. These modeling steps will pose increasingly difficult computational challenges, which I intend to address by developing 
approximation and dimensionality reduction techniques. Throughout this process, I will test these methods on terrestrial carbon models used in ecology. 
 
 \textbf{1. Propagating Emulator Uncertainty.}
 



\begin{thebibliography}{20}
\bibitem{Willcox} Willcox, K.E., Ghattas, O. \& Heimbach, P. The imperative of physics-based modeling and inverse theory in computational science. Nat Comput Sci 1, 166â€“168 (2021). https://doi.org/10.1038/s43588-021-00040-z
\end{thebibliography}



\end{document}



