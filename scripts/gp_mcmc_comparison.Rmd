---
title: "GP-Accelerated MCMC Comparison"
author: "Andrew Roberts"
date: '2023-10-30'
output: html_document
---

```{r, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(lhs)
library(hetGP)
library(mlegp)
library(ggplot2)
library(viridis)
library(parallel)
library(gridExtra)
library(data.table)
library(BayesianTools)

source("numerical_experiment_functions.r")
source("mcmc_calibration_functions.r")
source("gp_emulator_functions.r")
source("gp_mcmc_functions.r")
source("sequential_design_optimization.r")
source("sequential_design_sim_study.r")
```

# 1D Linear Gaussian Model 

We begin we the simplest possible example, the one-dimensional linear Gaussian model 
$$
\begin{align*}
\mathbf{y} &= \mathbf{g}u + \epsilon \\
\epsilon &\sim \mathcal{N}(0, \sigma_\epsilon^2) \\
u &\sim \mathcal{N}(\mu_0, \sigma^2_0),
\end{align*}
$$
where $\mathbf{g}, \mathbf{y} \in \mathbb{R}^T$ and the noise variance $\sigma_\epsilon^2$ is assumed to be known. This results in an unnormalized log posterior density 
$$
\ell^\pi(u) \propto -\frac{1}{2} \log(2\pi\sigma_{\epsilon}^2) - \frac{\Phi(u)}{2\sigma^2_\epsilon} - \frac{1}{2\sigma^2_0}(u - \mu_0)^2,
$$
where 
$$
\Phi(u) := ||\mathbf{y} - \mathbf{g}u||_2^2
$$
is the data-misfit.


```{r}
# Linear Gaussian Model Setup. 
N_obs <- 100
freq <- 1
g <- matrix(sin(2*pi*freq*seq(1, N_obs)/N_obs), ncol=1)
sig2_eps <- 1
sig2_0 <- matrix(1)
mu0 <- 0

# linear_Gaussian_info <- generate_linear_Gaussian_test_data(linear_Gaussian_seed, N_obs=N_obs, 
#                                                            D=1, Sig_theta=sig2_0, G=g, sig2_eps=sig2_eps)
# computer_model_data <- linear_Gaussian_info$computer_model_data
# theta_prior_params <- linear_Gaussian_info$theta_prior_params
# linear_Gaussian_info$true_posterior$SSR <- get_computer_model_SSR(computer_model_data, 
#                                                                   theta_vals=linear_Gaussian_info$true_posterior$mean, 
#                                                                   na.rm=TRUE)
# 
# plot(1:N_obs, computer_model_data$data_obs, main = "Ground Truth and Observed Data", xlab = "t")
# lines(1:N_obs, computer_model_data$data_ref, col = "red")
```


```{r}

#
# Observational Data, Forward Model, and Emulator Setup. 
#

# Random number generator seeds.
data_seed <- 5
design_seed <- 10

# Defining forward model.
freq <- 1
g <- matrix(sin(2*pi*freq*seq(1, N_obs)/N_obs), ncol=1)

# Likelihood parameters and priors. 
sig2_eps <- 1
sig2_0 <- matrix(1)
N_obs <- 100

# Emulator settings. 
N_design <- 4
emulator_settings <- data.frame(gp_lib = c("hetGP"), 
                                kernel = "Gaussian", 
                                transformation_method = c("truncated"),
                                emulator_target = "SSR",
                                scale_X = TRUE, 
                                normalize_y = TRUE)

# Generate data and fit emulator. 
linear_Gaussian_list <- get_1d_linear_Gaussian_approx_post_density(data_seed, design_seed, g, sig2_eps, sig2_0, N_design,
                                                                   emulator_settings, N_obs, design_method="grid")
computer_model_data <- linear_Gaussian_list$obj$computer_model_data
lpost_emulator <- linear_Gaussian_list$obj$lpost_emulator
linear_Gaussian_info <- linear_Gaussian_list$obj$linear_Gaussian_info

for(plt in linear_Gaussian_list$plots) plot(plt)
```

```{r}
# TODO: TEMP - test

inputs_temp <- matrix(c(-1.5, 0.75, 1.5), ncol=1)
inputs_scaled_temp <- scale_input_data(inputs_temp, input_bounds=lpost_emulator$design_info_list$input_bounds)

test_post <- matrix(nrow=3, ncol=1000)
test_prior <- matrix(nrow=3, ncol=1000)

for(i in 1:1000) {
  test_post[,i] <- sample_emulator_cond(inputs_scaled_temp, lpost_emulator$emulator_info_list, "post", sig2_eps=sig2_eps, 
                                        trunc_method="truncated", include_nugget=TRUE)
  test_prior[,i] <- sample_emulator_cond(inputs_scaled_temp, lpost_emulator$emulator_info_list, "prior", sig2_eps=sig2_eps, 
                                         trunc_method="truncated", include_nugget=TRUE)
}

j <- 2
hist(test_post[j,], 30)
hist(test_prior[j,], 30)


```
```{r}
# TODO: TEMP - test

# Gibbs test.
theta_init <- 0.75
mcmc_test <- mcmc_calibrate_ind_gp_gibbs(computer_model_data, lpost_emulator$theta_prior_params, 
                                         lpost_emulator$emulator_info_list, sig2_eps_init=lpost_emulator$sig2_eps,
                                         theta_init=theta_init, learn_sig_eps=FALSE, adapt_cov=FALSE, adapt_scale=FALSE,
                                         N_mcmc=N_mcmc, Cov_prop_init_diag=1.0, adapt_frequency=1000)
mcmc_test_dt <- format_mcmc_output(samp_list=mcmc_test[c("theta")], test_label="gibbs_test")

# Exact samples.
N_samp_exact <- 50000
samp_exact <- rnorm(n=N_samp_exact, mean=drop(linear_Gaussian_info$true_posterior$mean), 
                    sd=sqrt(drop(linear_Gaussian_info$true_posterior$Cov)))
samp_exact_dt <- data.table(param_type="theta", 
                            itr=seq_len(N_samp_exact), 
                            param_name=computer_model_data$pars_cal_names, 
                            sample=samp_exact,
                            test_label="exact")
mcmc_test_dt <- rbindlist(list(mcmc_test_dt, samp_exact_dt), use.names=TRUE)

# Plots
trace_plots <- get_trace_plots(mcmc_test_dt[itr<=100])
for(plt in trace_plots) plot(plt)

hist_plots <- get_hist_plot_comparisons(mcmc_test_dt, param_types="theta", test_label_baseline="exact", 
                                        xlab="samples", ylab="density", bins=30)
for(plt in hist_plots) plot(plt)


# Conclusions: 
#    - An adaptive scheme with more frequent tuning early on might be helpful. 
#    - The algorithm seems to get stuck near the design point near 0.75. 
#    - Example: With fixed step size 1.0 (no adaptation), the first 100 iterations 
#               are rejections.
#    - Might be helpful to plot p(theta|phi, Y) for values of phi around 114-115. 

plot(1:100, mcmc_test$SSR[1:100,1], type="l")

```

```{r}
# TEST: looking at p(u|Sigma, phi, Y)

u_grid <- matrix(seq(-2, 2, length.out=101), ncol=1)
SSR_test <- 114

# No emulator. 
u_cond_lpost_exact <- calc_lpost_theta_product_lik(computer_model_data, theta_vals=u_grid, 
                                                   vars_obs=sig2_eps, na.rm=TRUE, 
                                                   theta_prior_params=lpost_emulator$theta_prior_params, 
                                                   return_list=FALSE)

# p(u|Sigma, phi, Y)
lprior_theta_test <- calc_lprior_theta(u_grid, lpost_emulator$theta_prior_params)
u_grid_scaled <- scale_input_data(u_grid, lpost_emulator$design_info_list$input_bounds)
gp_pred_list_test <- predict_independent_GPs(X_pred=u_grid_scaled, gp_obj_list=lpost_emulator$emulator_info_list$gp_fits, 
                                             gp_lib=lpost_emulator$emulator_info_list$settings$gp_lib, include_cov_mat=FALSE, 
                                             denormalize_predictions=TRUE, 
                                             output_stats=lpost_emulator$emulator_info_list$output_stats)
gp_pred_means_test <- sapply(gp_pred_list_test, function(x) x$mean)
gp_pred_vars_test <- sapply(gp_pred_list_test, function(x) x$var_comb)
u_cond_lpost_test <- lprior_theta_test + dnorm(SSR_test, drop(gp_pred_means_test), sqrt(drop(gp_pred_vars_test)), log=TRUE)
u_cond_lpost_test_truc <- lprior_theta_test + log(dtruncnorm(SSR_test, 0, 
                                                        mean=drop(gp_pred_means_test), 
                                                        sd=sqrt(drop(gp_pred_vars_test))))
CI_upper <- qnorm(0.99, gp_pred_means_test, sqrt(gp_pred_vars_test))
CI_lower <- qnorm(0.01, gp_pred_means_test, sqrt(gp_pred_vars_test))
CI_upper_trunc <- qtruncnorm(0.99, 0, mean=gp_pred_means_test, sd=sqrt(gp_pred_vars_test))
CI_lower_trunc <- qtruncnorm(0.01, 0, mean=gp_pred_means_test, sd=sqrt(gp_pred_vars_test))
trunc_moments <- transform_GP_predictions(gp_pred_means_test, gp_pred_vars_test, transformation_method="truncated")
gp_pred_means_test_trunc <- trunc_moments$mean
gp_pred_vars_test_trunc <- trunc_moments$var

sel <- (drop(u_grid) >= -2) & (drop(u_grid) <= 2)
plot(u_grid[sel,], exp(u_cond_lpost_exact[sel]), type="l")
plot(u_grid[sel,], exp(u_cond_lpost_test[sel]), type="l")
plot(u_grid[sel,], exp(u_cond_lpost_test_truc[sel]), type="l")

plot(u_grid[sel,], gp_pred_means_test[sel,], type="l")
lines(u_grid[sel,], CI_upper[sel], col="gray")
lines(u_grid[sel,], CI_lower[sel], col="gray")
points(0.7754493, 0, col="red")

plot(u_grid[sel,], gp_pred_means_test_trunc[sel], type="l")
lines(u_grid[sel,], CI_upper_trunc[sel], col="gray")
lines(u_grid[sel,], CI_lower_trunc[sel], col="gray")
points(0.7754493, 0, col="red")

```

```{r}
# Set up list of MCMC algorithm settings and runs. 

# General settings to apply to all runs. 
N_mcmc <- 50000
learn_sig_eps <- FALSE
sig2_eps_init <- sig2_eps

# Fix pre-MCMC estimates of calibration and likelihood parameters based on design data. All MCMC
# algs will use this initialization. 
design_info_list <- lpost_emulator$design_info_list
best_idx <- which.max(design_info_list$lpost)
theta_init <- design_info_list$inputs[best_idx,]

# Algorithm-specific settings list. 
run_settings_list <- list()
run_settings_list[["gibbs_adapt_cov"]] <- list(test_label="gibbs_adapt_cov", 
                                               alg="ind_gp_gibbs",
                                               adapt_cov=FALSE, 
                                               adapt_scale=FALSE, 
                                               Cov_prop_init_diag=1.0)
# run_settings_list[["gibbs_adapt_scale"]] <- list(test_label="gibbs_adapt_scale", 
#                                                  alg="ind_gp_gibbs",
#                                                  adapt_cov=FALSE, 
#                                                  adapt_scale=TRUE)
# run_settings_list[["gibbs_adapt"]] <- list(test_label="gibbs_adapt", 
#                                                  alg="ind_gp_gibbs",
#                                                  adapt_cov=FALSE, 
#                                                  adapt_scale=TRUE)
# run_settings_list[["traj_gp_cov"]] <- list(test_label="traj_gp_cov", 
#                                            alg="ind_gp_trajectory",
#                                            use_gp_cov=TRUE, 
#                                            second_gibbs_step=FALSE)
# run_settings_list[["traj_gp_cov_gibbs"]] <- list(test_label="traj_gp_cov_gibbs", 
#                                                  alg="ind_gp_trajectory",
#                                                  use_gp_cov=TRUE, 
#                                                  second_gibbs_step=TRUE)
# run_settings_list[["traj_gp_pecan"]] <- list(test_label="traj_gp_pecan", 
#                                              alg="ind_gp_trajectory",
#                                              use_gp_cov=FALSE, 
#                                              second_gibbs_step=TRUE)
```

```{r}
# Run GP-MCMC algorithms. 
mcmc_test_info <- run_gp_mcmc_tests(run_settings_list, computer_model_data=computer_model_data, lpost_emulator=lpost_emulator,   
                                    theta_init=theta_init, N_chain=4, N_itr=N_mcmc, burn_ins=NULL, learn_sig_eps=FALSE,
                                    return_cov_prop_scale=TRUE, return_SSR_samp=TRUE, sig2_eps_init=sig2_eps)
mcmc_samp_dt <- mcmc_test_info$mcmc_samp_dt
burn_ins <- mcmc_test_info$burn_ins

# Append exact posterior samples. 
N_samp_exact <- N_mcmc
samp_exact <- rnorm(n=N_samp_exact, mean=drop(linear_Gaussian_info$true_posterior$mean), 
                    sd=sqrt(drop(linear_Gaussian_info$true_posterior$Cov)))
samp_exact_dt <- data.table(param_type="theta", 
                            itr=seq_len(N_samp_exact), 
                            param_name=computer_model_data$pars_cal_names, 
                            sample=samp_exact,
                            test_label="exact")
mcmc_samp_dt <- rbindlist(list(mcmc_samp_dt, samp_exact_dt), use.names=TRUE)

```

```{r}
#
# MCMC Setup. 
#

# MCMC settings
N_mcmc <- 50000

# Fix pre-MCMC estimates of calibration and likelihood parameters based on design data. All MCMC
# algs will use this initialization. 
design_info_list <- lpost_emulator$design_info_list
best_idx <- which.max(design_info_list$lpost)
theta_init <- design_info_list$inputs[best_idx,]

# Emulator-Accelerated MCMC algorithms. 
mcmc_algs <- c("ind_gp_gibbs", "ind_gp_trajectory")

mcmc_info_list <- run_gp_mcmc_tests(computer_model_data, lpost_emulator, mcmc_algs, theta_init, N_chain=4,  
                                    N_itr=N_mcmc, learn_sig_eps=FALSE, return_cov_prop_scale=TRUE,  
                                    return_SSR_samp=TRUE, burn_ins=1)
mcmc_samp_dt <- mcmc_info_list$mcmc_samp_dt
burn_ins <- mcmc_info_list$burn_ins

# Add GP trajectory using PEcAn settings. 
# TODO: should modify `run_gp_mcmc_tests()` to allow control over MCMC function arguments. 
mcmc_pecan <- mcmc_calibrate_ind_gp_trajectory(computer_model_data, lpost_emulator$theta_prior_params, 
                                               lpost_emulator$emulator_info_list, sig2_eps_init=lpost_emulator$sig2_eps,
                                               theta_init=theta_init, learn_sig_eps=FALSE, 
                                               N_mcmc=N_mcmc, use_gp_cov=FALSE, second_gibbs_step=TRUE)
mcmc_pecan_dt <- format_mcmc_output(samp_list=mcmc_pecan[c("theta", "cov_prop_scale")], test_label="pecan")
mcmc_samp_dt <- rbindlist(list(mcmc_samp_dt, mcmc_pecan_dt), use.names=TRUE)
                                               
# Add GP trajectory with both GP cov and second Gibbs step.  
mcmc_pecan_cov <- mcmc_calibrate_ind_gp_trajectory(computer_model_data, lpost_emulator$theta_prior_params, 
                                                   lpost_emulator$emulator_info_list, sig2_eps_init=lpost_emulator$sig2_eps,
                                                   theta_init=theta_init, learn_sig_eps=FALSE, 
                                                   N_mcmc=N_mcmc, use_gp_cov=TRUE, second_gibbs_step=TRUE)
mcmc_pecan_cov_dt <- format_mcmc_output(samp_list=mcmc_pecan[c("theta", "cov_prop_scale")], test_label="pecan_cov")
mcmc_samp_dt <- rbindlist(list(mcmc_samp_dt, mcmc_pecan_cov_dt), use.names=TRUE)

# Append samples from exact posterior. 
N_samp_exact <- 50000
samp_exact <- rnorm(n=N_samp_exact, mean=drop(linear_Gaussian_info$true_posterior$mean), 
                    sd=sqrt(drop(linear_Gaussian_info$true_posterior$Cov)))
samp_exact_dt <- data.table(param_type="theta", 
                            itr=seq_len(N_samp_exact), 
                            param_name=computer_model_data$pars_cal_names, 
                            sample=samp_exact,
                            test_label="exact")
mcmc_samp_dt <- rbindlist(list(mcmc_samp_dt, samp_exact_dt), use.names=TRUE)

```

```{r}
trace_plots <- get_trace_plots(mcmc_samp_dt)
for(plt in trace_plots) plot(plt)
```

```{r}
# TODO: 
#    1.) look into why the trajectory alg posterior is multimodal, while the current PEcAn alg is not. 
#    2.) look into adding second Phi sampling step in the trajectory algorithm. 
#    3.) return effective proposal variances (scale parameter times diag of proposal covariance) in mcmc_samp_dt. 
#    4.) add option to exclude a param_type when selecting columns. 
#    5.) Re-check math for the Gibbs alg.
#    6.) Try out alternative proposal for Gibbs alg. 
#    7.) Implement the marg algorithm to compare. 
#    8.) Add KDE estimate for plots. 

hist_plots <- get_hist_plot_comparisons(mcmc_samp_dt, param_types="theta", test_label_baseline="exact", 
                                        xlab="samples", ylab="density", bins=30)
for(plt in hist_plots) plot(plt)
```

