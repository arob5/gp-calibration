---
title: "Basis Function Emulation"
author: "Andrew Roberts"
date: "2024-10-22"
output: html_document
---

This file provides an introduction to the functions defined in 
`basis_function_emulation.r`. The functions contained therein are designed 
to approximate the output space of functions with high-dimensional outputs
using a basis representation. It also introduces the `gpWrapperSum` class, 
which encodes a model that is a weighted sum of basis functions, with the 
weights given by independent Gaussian processes (GPs). See 
[this](https://arob5.github.io/blog/2024/06/25/basis-func-emulator/) 
writeup for background on models of this form. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)

library(lhs)
library(ggplot2)
library(data.table)
library(assertthat)

base_dir <- file.path("/projectnb", "dietzelab", "arober", "gp-calibration")
src_dir <- file.path(base_dir, "src")

# Various helper functions.
source(file.path(src_dir, "seq_design.r"))
source(file.path(src_dir, "gpWrapper.r"))
source(file.path(src_dir, "llikEmulator.r"))
source(file.path(src_dir, "inv_prob_test_functions.r"))
source(file.path(src_dir, "general_helper_functions.r"))
source(file.path(src_dir, "plotting_helper_functions.r"))

# Main functions being illustrated.
source(file.path(src_dir, "basis_function_emulation.r"))
```

# Evaluate function at design points.
```{r}
# The function g() will be the test function used throughout this document.
inv_prob <- get_vsem_test_1()
g <- inv_prob$par_to_obs_op
```

```{r}
# Create an initial input design.
n_design <- 200L
U <- get_batch_design("LHS", N_batch=n_design, prior_params=inv_prob$par_prior)

# Run forward model g() at the design points.
G <- g(U)
```

```{r}
# Plot a subset of the function evaluations.
idx <- sample(1:nrow(G), size=20L)
plt_design <- plot_curves_1d_helper(inv_prob$time_points, t(G[idx,,drop=FALSE]), 
                                    plot_title="Model runs at design points",
                                    xlab="days", ylab="LAI")
              
plot(plt_design + theme(legend.position="none"))
```

# Run PCA on model outputs
```{r}
pca_list <- pca(G) 
sdev <- pca_list$sqrt_val # square root of eigenvalues of empirical covariance.
V <- pca_list$vec # eigenvectors.
m <- pca_list$mean
```

```{r}
# Eigenvalue (scree) plot. Different scalings emphasize different features.
scree_plt <- get_scree_plot(pca_list, sdev=TRUE, log_scale=FALSE)
scree_plt_log <- get_scree_plot(pca_list, sdev=FALSE, log_scale=TRUE)

plot(scree_plt)
plot(scree_plt_log)
```


We define a cutoff and only include the dominant principal components. We 
visually compare true evaluations of $g(u)$ versus evaluations of $g(u)$ that 
have been approximated by projecting the functions outputs on the subspace 
spanned by the dominant eigenvalues. The plot considers a set of new 
"out-of-sample" $u$ values. 
```{r}
variance_threshold <- 0.975
pca_list_trunc <- truncate_pca_basis(pca_list, variance_threshold)

# Basis vectors and eigenvalues.
B <- pca_list_trunc$vec
sdev <- pca_list_trunc$sqrt_val

r <- length(sdev)
print(paste0("Number of eigenvectors retained: ", r))
```

```{r}
# Plot the dominant eigenvectors.
for(j in 1:r) {
  plt_eig <- plot_curves_1d_helper(inv_prob$time_points, B[,j, drop=FALSE], 
                                   plot_title=paste0("Eigenvector ", j),
                                   xlab="days", ylab="LAI")
  plot(plt_eig)
}
```

```{r}
# Define the approximate map g(), which evaluates g() and then projects 
# the output onto the subspace spanned by the dominant principal components.

g_hat <- function(U) {
  # Vectorized to work over `m` inputs in the rows of `U`. Returns 
  # matrix that approximates g(U).
  W <- eval_basis_weights(U, g, B, m)
  proj <- tcrossprod(B, W)
  t(add_vec_to_mat_cols(m, proj))
}

```


```{r}
# Test approximation at a set of test points.
n_test <- 5
U_test <- get_batch_design("LHS", N_batch=n_test, prior_params=inv_prob$par_prior)

# Evaluate true vs. approximate function.
G_test <- g(U_test)
G_test_hat <- g_hat(U_test)

# Plot comparison.
df_test <- rbindlist(list(data.table(G_test), data.table(G_test_hat)))
colnames(df_test) <- as.character(1:ncol(df_test))
df_test[, id := as.factor(c(1:n_test, 1:n_test))]
df_test[, type := c(rep("true",n_test), rep("approx",n_test))]
df_test <- melt.data.table(df_test, id.vars=c("id", "type"), 
                           variable.name="time", value.name="value")
df_test[, time := as.integer(time)]

plt_approx <- ggplot(df_test) + 
              geom_line(aes(x=time, y=value, color=id, linetype=type)) + 
              labs(xlab="days", ylab="LAI", title="True vs. Approximated g()")
plot(plt_approx)

```

Below we plot the basis weight functions $w_j(u)$ over a grid of $u$ values. 
Since these functions map from $\mathbb{R}^r$ to $\mathbb{R}$ we cannot easily 
plot them when $r > 1$. We therefore plot 1d projections by varying only one 
input variable at a time. 
```{r}
# First, get the grids of input points to plot. Note that the below code for 
# defining `par_bounds` only works for uniform priors.
par_bounds <- t(inv_prob$par_prior[,c("param1","param2")])
U_proj_list <- get_input_grid_1d_projection(inv_prob$par_names, X_bounds=par_bounds)

# Plot 1d projections of w_j(u), for j=1,...,r.
for(par in names(U_proj_list)) {
  U_proj <- U_proj_list[[par]][[1]]
  w_U <- eval_basis_weights(U_proj, g, B, m=pca_list$mean)
  plt <- plot_curves_1d_helper(U_proj[,par], w_U, df_by=NULL, 
                               plot_title=paste0("w(u), projection on ", par),
                               xlab="u", ylab=par)
  plot(plt)
}

```

# Gaussian Process (GP) Emulators
We now consider approximating the maps $u \mapsto w_j(u)$, $j = 1, \dots, r$
by independent GP emulators. This induces a multi-output GP emulator for 
$g(\cdot)$. Again, see [this](https://arob5.github.io/blog/2024/06/25/basis-func-emulator/)
writeup for more background.

## Fitting the Independent GPs
We consider fitting independent GPs to each weight function $w_j(u)$. We 
use zero mean GP priors with squared exponential (i.e., Gaussian) kernels.

```{r}
# Assemble design (training) data for independent GPs.
design_info <- list(input=U, W=project_orthog_scalar(G, B, m))

# Fit GPs. Note that the empirical mean of each weight vector `w_j(U)` is 
# already 0, but we still set `normalize_output=TRUE` to scale these to have 
# standard deviation 1. 
gp_w <- gpWrapperHet(design_info$input, design_info$W, scale_input=TRUE,
                     normalize_output=TRUE)
gp_w$set_gp_prior("Gaussian", "constant", include_noise=FALSE)
gp_w$fit()
gp_w$summarize()
```

```{r}
# Validation points to test GP fit.
n_test <- 500
test_info <- list(input=get_batch_design("LHS", N_batch=n_test, 
                                         prior_params=inv_prob$par_prior))
test_info$W <- eval_basis_weights(test_info$input, g, B, m) 
```

```{r}
# Summarize predictions at validation points.
gp_w$plot_pred(test_info$input, test_info$W, include_CI=TRUE)
```

```{r}
gp_w$plot_1d_projection(include_design=FALSE)
```










