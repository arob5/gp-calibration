# test_gp_r_stan_conversion.R
# Tests the Gaussian Process (GP) Stan functions by comparing their output to 
# that of supported GP packages in R. The Stan functions assume a fixed form 
# of the Gaussian covariance function, which may differ from the exact 
# parameterization used by various R packages. This file tests that the 
# parameterizations are correctly mapped. 
#
# Andrew Roberts

# TODO:
#   1.) Compare Stan function gp_approx() to function defined in R (as in likelihood comparison script).
#   2.) 3-way comparison: predictive means/variances using Stan code, R implementation, and mlegp functions. 
#       Can help diagonose why mlegp results are choppy. 

library(rstan)
library(mlegp)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

source("stan.helper.functions.R")

# -----------------------------------------------------------------------------
# Generate Test Data: Toy example
# -----------------------------------------------------------------------------

# # Dimension of input space
# k <- 2
# 
# # Design points
# nx <- 20
# x <- seq(0, 2*pi, length = nx)
# X.df <- expand.grid(x, x)
# X <- as.matrix(X.df)
# y <- sin(X[,1] + 4*X[,2])
# N <- length(y)
# 
# # Test points
# N.pred.x <- 30
# x.pred <- seq(-0.5, 2*pi + 0.5, length = N.pred.x)
# X.pred.df <- expand.grid(x.pred, x.pred)
# X.pred <- as.matrix(X.pred.df)
# N.pred <- nrow(X.pred)


k <- 1
f <- function(u) {u}

# True calibration parameter value
u <- .5

# Support of calibration parameter
u.min <- 0
u.max <- 1
u.extrapolation.width <- .01

n.u <- 1000
u.vals <- seq(u.min - u.extrapolation.width, u.max + u.extrapolation.width, length = n.u)
X.pred <- matrix(u.vals, ncol=1)
N.pred <- n.u

# Precision parameter values.
sigma <- .3
tau <- 1/sigma^2

# Simulate observed data
n <- 1000
y.obs <- matrix(NA, nrow = n, ncol = 1)
y.obs[,1] <- rnorm(n, f(u), sigma)

# Design matrix, evaluate model at design points
N <- 10
design.points <- c(0, .05, .07, .08, .1, .2, .25, .3, 1)
N <- length(design.points)
X <- matrix(design.points, ncol = 1)
y_model <- f(X)

SS <- matrix(NA, nrow = N, ncol = 1)
for(i in seq(1, N)) {
  SS[i, 1] <- sum((y_model[i] - y.obs[,1])^2)
}
y <- SS


# Plot test data (will only work if k = 1)
matplot(X, y, pch = 20, cex = 2, xlab = 'Design Points', ylab = 'Model Value')


# -----------------------------------------------------------------------------
# R package: mlegp
# -----------------------------------------------------------------------------

# Fit GP model
gp.mlegp <- mlegp(X, y, nugget.known = 0, constantMean = 1)

# Map kernel parameters to Stan parameterization
gp.stan.params <- create.gp.params.list(gp.mlegp, "mlegp")

# Compile and run Stan code
stan.model.path <- "test_gp_r_stan_conversion.stan"
model <- stan_model(stan.model.path)

stan.list <- as.list(c(gp.stan.params, 
                       list(N = N, 
                            N_pred = N.pred, 
                            k = k,
                            X = X, 
                            y = as.vector(y), 
                            X_pred = X.pred)))

stan.fit <- sampling(model, data = stan.list, warmup = 0, iter = 1, chains = 1, 
                     seed = 494838, refresh = 4000, algorithm = "Fixed_param")
stan.output <- extract(stan.fit)
                     
# Test the covariance matrix generated by the design points
K.mlegp <- calcVarMatrix(X, gp.mlegp$beta, gp.mlegp$a, gp.mlegp$nugget, gp.mlegp$sig2, 0, gp.mlegp$numObs)
K.stan <- stan.output$K_out[1,,]
print(paste0("Cov matrices K(X) equal: ", all.equal(K.mlegp, K.stan)))

# Test the covariance matrix generated by the test/prediction points
K.pred.mlegp <- calcVarMatrix(X.pred, gp.mlegp$beta, gp.mlegp$a, gp.mlegp$nugget, gp.mlegp$sig2, 0, N.pred)
K.pred.stan <- stan.output$K_pred[1,,]
print(paste0("Cov matrices K(X_pred) equal: ", all.equal(K.pred.mlegp, K.pred.stan)))

# Test the expression inv(K(X)) %*% (y - gp_mean). mlegp directly inverts the covariance matrix, while my Stan code
# instead opts for a Cholesky decomposition. If the above tests pass but the results are significantly 
# different here, then this points to an ill-conditioned matrix, which will mean the predictive means
# and variances will differ in the below tests. 
K.inv.y.mlegp <- as.vector(solve(K.mlegp) %*% (y - gp.mlegp$Bhat))
K.inv.y.stan <- as.vector(stan.output$K_inv_y_out)
print(paste0("Vector K_inv_y equal: ", all.equal(K.inv.y.mlegp, K.inv.y.stan)))

# Investigating possible ill-conditioning of the covariance matrix
K.mlegp.svd <- svd(K.mlegp)
K.mlegp.cond.num <- max(K.mlegp.svd$d) / min(K.mlegp.svd$d)
K.inv.K.mlegp <- solve(K.mlegp) %*% K.mlegp

print(paste0("Condition number for inverse of K(X): ", K.mlegp.cond.num))
print(paste0("K.inv.K equal to identity matrix: ", all.equal(K.inv.K.mlegp, diag(rep(1.0, N)))))

# Test the covariances between the design and prediction points
K.cross.mlegp <- matrix(NA, nrow = N, ncol = N.pred)
for(j in seq(1, N.pred)) {
  K.cross.mlegp[,j] <- gp.mlegp$sig2 * calcCorOneObs(X, gp.mlegp$beta, gp.mlegp$a, X.pred[j,])
}

K.cross.stan <- stan.output$K_cross[1,,]
print(paste0("Cov matrices K(X, X_pred) equal: ", all.equal(K.cross.mlegp, K.cross.stan)))

# Test that mean prediction gives same results
gp.pred.mlegp <- predict(gp.mlegp, newData = X.pred)
gp.pred.stan <- t(stan.output$mean_pred)
print(paste0("Max absolute error in mean predictions: ", max(abs(gp.pred.mlegp - gp.pred.stan))))

# Test variance predictions
gp.var.mlegp <- predict(gp.mlegp, X.pred, se.fit = TRUE)$se.fit^2 + gp.mlegp$nugget
gp.var.stan <- t(stan.output$var_pred)
print(paste0("Max absolute error in variance predictions: ", max(abs(gp.var.mlegp - gp.var.stan))))


# -----------------------------------------------------------------------------
# General Stan tests
# -----------------------------------------------------------------------------

# Compare user defined covariance function to Stan's internal cov_exp_quad()
K.stan.test <- stan.output$K_stan_test[1,,]
K.test <- stan.output$K_out_test[1,,]
print(paste0("Cov matrix agrees with Stan's cov_exp_quad(): ", all.equal(K.test, K.stan.test)))

# Test that predictive mean interpolates observed data (when nugget is 0). If nugget is not 0, then 
# the predictive mean will not exactly equal the observed value. 
mean.design.stan <- as.vector(stan.output$mean_design)
print(paste0("Max absolute error of mean at design points: ", max(abs(mean.design.stan - y))))

# Test that predictive variance is equal to the nugget at observed data points
var.design.stan <- as.vector(stan.output$var_design)
print(paste0("Max absolute error of variance at design points: ", max(abs(var.design.stan - gp.mlegp$nugget))))








