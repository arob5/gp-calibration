---
title: "Plots for Environmental Bayes Poster Presentation"
author: "Andrew Roberts"
date: '2023-08-28'
output: html_document
---

```{r, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lhs)
library(hetGP)
library(mlegp)
library(ggplot2)
library(viridis)
library(parallel)
library(gridExtra)
library(data.table)
library(BayesianTools)

source("numerical_experiment_functions.r")
source("mcmc_calibration_functions.r")
source("gp_emulator_functions.r")
source("sequential_design_optimization.r")
```

# Computer Model and Data 

```{r}
# Synthetic data generation
computer_model_data <- generate_vsem_test_case(4)
```

```{r}
print(computer_model_data$ref_pars[computer_model_data$pars_cal_sel,])
```

```{r echo = FALSE}
for(output_var in computer_model_data$output_vars) {
 plotTimeSeries(observed = computer_model_data$data_obs[, output_var],
                predicted = computer_model_data$data_ref[, output_var], main = output_var) 
}
```

# Priors 

## Calibration Parameters 
```{r, echo = FALSE} 
# Priors 
theta_prior_params <- computer_model_data$ref_pars[computer_model_data$pars_cal_sel,]
theta_prior_params[, "dist"] <- c("Uniform", "Uniform")
theta_prior_params[,"param1"] <- c(1.4, 0.45) # theta_prior_params[,"lower"]
theta_prior_params[,"param2"] <- c(1.6, 0.55)  # theta_prior_params[,"upper"]
theta_prior_params <- theta_prior_params[, c("dist", "param1", "param2")]

print(theta_prior_params)
```


## Likelihood Parameters 
```{r}
sig2_prior_info <- get_IG_priors_numerical_test(sig2_true = diag(computer_model_data$Sig_eps), 
                                                bias_frac = c(0.1, -0.15), bins = 50,
                                                coef_var = c(0.3, 0.5), return_prior_plots = TRUE, 
                                                output_variables = computer_model_data$output_vars)
sig_eps_prior_params <- sig2_prior_info$prior
plts <- sig2_prior_info$plots

grid.arrange(arrangeGrob(grobs = plts, nrow = 1))
```

# Exact MCMC Samples.

## Exact MCMC. 
```{r}
N_mcmc_exact <- 50000

time_start <- proc.time()
mcmc_exact_list <- mcmc_calibrate_product_lik(computer_model_data = computer_model_data, 
                                              theta_prior_params = theta_prior_params, 
                                              learn_sig_eps = TRUE,
                                              sig_eps_prior_params = sig_eps_prior_params,
                                              N_mcmc = N_mcmc_exact)
mcmc_exact_runtime <- (proc.time() - time_start)[["elapsed"]]
print(paste0("Exact MCMC runtime: ", mcmc_exact_runtime, " seconds."))

# Format MCMC samples. 
mcmc_samp_dt <- format_mcmc_output(samp_list = mcmc_exact_list[c("theta", "sig_eps")], test_label = "exact")

```

```{r}
burn_ins <- c(exact = 10000)

mcmc_exact_trace_plts <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "exact", param_types = "theta")
grid.arrange(arrangeGrob(grobs = mcmc_exact_trace_plts, nrow = 1))
```

```{r}
mcmc_exact_trace_plts_sig_eps <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "exact", param_types = "sig_eps")
grid.arrange(arrangeGrob(grobs = mcmc_exact_trace_plts_sig_eps, nrow = 1))
```

```{r}
# Store matrix of calibration parameter samples from exact MCMC for plotting purposes. 
samp_exact_theta <- select_mcmc_samp(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "exact", param_types = "theta")[, .(param_name, sample)]
samp_exact_theta <- as.matrix(unstack(samp_exact_theta, sample ~ param_name))[, computer_model_data$pars_cal_names]
```


```{r}
# Store exact samples that will be used to compute error metrics. 

# Samples for sample-based metrics that require approximately independent samples. 
# TODO: should monitor estimated auto-correlation here. 
samp_exact_theta_thinned <- samp_exact_theta[seq(1, nrow(samp_exact_theta), 5),]

# Samples for computing emulator-based metrics. This requires computing GP predictions at every sample, so must reduce 
# the number of samples for computational feasibility. 
samp_exact_theta_emulator_metrics <- samp_exact_theta[seq(1, nrow(samp_exact_theta), 10),]

```


# Round 0: Fit GP on initial space-filling design. 

```{r, echo = FALSE}
# Emulator settings
emulator_settings <- data.frame(gp_lib = c("hetGP"), 
                                kernel = "Gaussian", 
                                transformation_method = c("truncated"),
                                emulator_target = "SSR",
                                scale_X = TRUE, 
                                normalize_y = TRUE)
print(emulator_settings)
```

```{r}
# Initial design (round 0). 
design_settings <- data.frame(N_design = 15, design_method = "LHS", design_seed = 5)
init_design_info <- get_input_output_design(N_points = design_settings$N_design,
                                            design_method = design_settings$design_method, 
                                            scale_inputs = TRUE,
                                            computer_model_data = computer_model_data, 
                                            theta_prior_params = theta_prior_params)

# Grid of points spread across prior (for plotting).  
prior_grid_info <- get_input_output_design(N_points = 51^2,
                                           design_method = "grid", 
                                           scale_inputs = TRUE,
                                           param_ranges = init_design_info$input_bounds,
                                           computer_model_data = computer_model_data, 
                                           theta_prior_params = theta_prior_params, 
                                           design_seed = design_settings$design_seed)
prior_grid_info$lpost <- calc_lpost_theta_product_lik(computer_model_data = computer_model_data, 
                                                      theta_vals = prior_grid_info$inputs, 
                                                      vars_obs = diag(computer_model_data$Sig_eps), 
                                                      SSR = prior_grid_info$outputs,
                                                      na.rm = TRUE, theta_prior_params = theta_prior_params, 
                                                      return_list = FALSE)
```

```{r}
# Plot initial design. 
# TODO: change axis labels to theta1 and theta2 or something generic like that. 

plt_init_design <- get_2d_heatmap_plot(X = prior_grid_info$inputs, y = prior_grid_info$lpost, param_names = computer_model_data$pars_cal_names, 
                                       samples_kde = samp_exact_theta, samples_points = init_design_info$inputs, raster = TRUE, 
                                       bigger_is_better = TRUE, main_title = "Initial Design and Heatmap of True Posterior")
                                       
plot(plt_init_design)


```

```{r}
# Fix pre-MCMC estimates of calibration and likelihood parameters based on design data. 
init_estimates <- get_init_param_estimates(init_design_info, computer_model_data, sig_eps_prior_params)
init_design_info$init_estimates <- init_estimates
print("Initial Estimates:")
print(init_estimates)
```


```{r}
# Fit emulators on initial design. 
gp_fits <- fit_independent_GPs(X_train = init_design_info$inputs_scaled, Y_train = init_design_info$outputs_normalized, 
                               gp_lib = emulator_settings$gp_lib, gp_kernel = emulator_settings$kernel)$fits
emulator_info_list <- list(gp_fits = gp_fits, input_bounds = init_design_info$input_bounds, 
                           output_stats = init_design_info$output_stats, settings = emulator_settings)

# Induced log joint density (i.e. log unnormalized posterior density) emulator. 
lpost_emulator <- get_lpost_emulator_obj(emulator_info_list = emulator_info_list, design_info_list = init_design_info, 
                                         computer_model_data = computer_model_data, sig2_eps = init_design_info$init_estimates$best_sig2_eps, 
                                         theta_prior_params = theta_prior_params)
```


```{r}
#
# Compute round 0 emulator-based metrics.  
#

# # Validation data for evaluating emulator-based metrics. 
# lpost_emulator_metrics <- calc_lpost_theta_product_lik(computer_model_data = computer_model_data, 
#                                                        theta_vals = samp_exact_theta_emulator_metrics, 
#                                                        vars_obs = diag(computer_model_data$Sig_eps), 
#                                                        na.rm = TRUE, theta_prior_params = theta_prior_params, 
#                                                        return_list = FALSE)
# 
# val_data_emulator_metrics <- list(inputs = samp_exact_theta_emulator_metrics, 
#                                   inputs_scaled = scale_input_data(samp_exact_theta_emulator_metrics, init_design$input_bounds), 
#                                   outputs = lpost_emulator_metrics)
# 
# # Compute metrics. 
# metrics_results <- get_lpost_emulator_metrics(lpost_emulator = lpost_emulator, 
#                                               lpost_validation_inputs = val_data_emulator_metrics$inputs, 
#                                               lpost_validation_inputs_scaled = val_data_emulator_metrics$inputs_scaled,
#                                               lpost_validation_outputs = val_data_emulator_metrics$outputs,
#                                               metrics = c("crps", "rmse"),  
#                                               include_nugget = TRUE)
# emulator_metrics_results <- data.frame(as.list(metrics_results))
# emulator_metrics_results$round <- 0
```


## Sample approximate posterior. 
```{r}
#
# Round 0 approximate posterior sampling. 
#

N_mcmc_approx <- 50000

mcmc_approx_round0 <- mcmc_calibrate_ind_GP(computer_model_data = computer_model_data, 
                                            theta_prior_params = theta_prior_params, 
                                            emulator_info = lpost_emulator$emulator_info_list,
                                            theta_init = init_design_info$init_estimates$best_input[1,], 
                                            sig_eps_init = init_design_info$init_estimates$best_sig2_eps, 
                                            learn_sig_eps = TRUE, 
                                            sig_eps_prior_params = sig_eps_prior_params, 
                                            N_mcmc = N_mcmc_approx)
```

```{r}
# Combine with existing data.table of MCMC output. 
mcmc_samp_dt <- rbindlist(list(mcmc_samp_dt, format_mcmc_output(samp_list = mcmc_approx_round0[c("theta", "sig_eps")], test_label = "round0")), 
                          use.names = TRUE)
```

### Round 0 MCMC sampling diagnostics. 
```{r}

burn_ins <- c(burn_ins, round0 = 10000)

mcmc_round0_trace_plts <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "round0", param_types = "theta")
grid.arrange(arrangeGrob(grobs = mcmc_round0_trace_plts, nrow = 1))
```

```{r}
mcmc_round0_trace_plts_sig_eps <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "round0", param_types = "sig_eps")
grid.arrange(arrangeGrob(grobs = mcmc_round0_trace_plts_sig_eps, nrow = 1))
```

```{r}
#
# Store round 0 MCMC approximate posterior samples. These are used as candidate/integration points for sequential design, 
# as well as for plotting purposes. 
#

samp_round0_theta <- select_mcmc_samp(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "round0", param_types = "theta")[, .(param_name, sample)]
samp_round0_theta <- as.matrix(unstack(samp_round0_theta, sample ~ param_name))[, computer_model_data$pars_cal_names]

SSR_round0 <- get_computer_model_SSR(computer_model_data = computer_model_data, theta_vals = samp_round0_theta, na.rm = TRUE)
lpost_round0_outputs <- calc_lpost_theta_product_lik(computer_model_data = computer_model_data, 
                                                     theta_vals = samp_round0_theta, 
                                                     SSR = SSR_round0, 
                                                     vars_obs = lpost_emulator$sig2_eps, 
                                                     theta_prior_params = theta_prior_params)
samp_round0_info <- list(inputs = samp_round0_theta, 
                         inputs_scaled = scale_input_data(samp_round0_theta, init_design_info$input_bounds), 
                         outputs = lpost_round0_outputs$lpost)

# lpost emulator predictions at sampled points. 
lpost_emulator_pred_round0 <- predict_lpost_emulator(lpost_emulator = lpost_emulator, 
                                                     inputs_new_scaled = samp_round0_info$inputs_scaled, 
                                                     inputs_new_unscaled = samp_round0_info$inputs, include_nugget = TRUE)
```


```{r}
# Compute "sample-based metrics"; that is, measures of error between the approximate and true posterior computed from the MCMC samples. 

# round0_sample_metrics <- compute_mcmc_comparison_metrics(samp_dt = mcmc_samp_dt, burn_in_start = burn_ins, 
#                                                          test_label_1 = "exact", test_label_2 = "round0", 
#                                                          param_types = c("theta", "sig_eps"), 
#                                                          metrics = c("mean", "cov"))
# print(round0_sample_metrics$metrics_individual)
# print(round0_sample_metrics$metrics_agg)
```


```{r}
# GP predictive mean and variance plots. 

plt_mean <- get_2d_heatmap_plot(X = samp_round0_info$inputs, y = lpost_emulator_pred_round0$mean, param_names = computer_model_data$pars_cal_names, 
                                samples_kde = samp_exact_theta, raster = FALSE, 
                                samples_points = init_design_info$inputs, 
                                bigger_is_better = TRUE, 
                                main_title = "lpost predictive mean")
plt_var <- get_2d_heatmap_plot(X = samp_round0_info$inputs, y = lpost_emulator_pred_round0$var, param_names = computer_model_data$pars_cal_names, 
                               samples_kde = samp_exact_theta, raster = FALSE, 
                               samples_points = init_design_info$inputs, 
                               bigger_is_better = TRUE, log_scale = TRUE, main_title = "lpost predictive var")

plot(plt_mean)
plot(plt_var)
```
# Investigating Single-Point Acquisitions 

## Integrated Variance Acquisitions
```{r}
# Prior-Weighted 
# NOTE: plotting negative of IVAR vals to avoid negatives to produce more intuitive plots. 
# TODO: should probably also keep consistent color scheme (i.e. yellow = bigger)

# Evaluate Acquisitions. 
IVAR_lpost_grid_prior_wt <- acquisition_EIVAR_lpost(theta_vals = prior_grid_info$inputs_scaled, 
                                           lpost_emulator = lpost_emulator, 
                                           theta_grid_integrate = prior_grid_info$inputs_scaled, 
                                           verbose = FALSE, include_nugget = TRUE)

IVAR_post_grid_prior_wt <- acquisition_IVAR_post(theta_vals = prior_grid_info$inputs_scaled, 
                                                 lpost_emulator = lpost_emulator, 
                                                 theta_grid_integrate = prior_grid_info$inputs_scaled, 
                                                 verbose = FALSE, include_nugget = TRUE)

# Optimizers of acquisitions. 
IVAR_lpost_grid_prior_wt_best_idx <- which.max(IVAR_lpost_grid_prior_wt)
IVAR_post_grid_prior_wt_best_idx <- which.max(IVAR_post_grid_prior_wt)
  
# Generate Plots. 
IVAR_lpost_grid_prior_wt_plot <- get_2d_heatmap_plot(X = prior_grid_info$inputs, 
                                                     y = -IVAR_lpost_grid_prior_wt, param_names = computer_model_data$pars_cal_names, 
                                                     samples_kde = samp_exact_theta, raster = TRUE, 
                                                     samples_points = init_design_info$inputs, 
                                                     bigger_is_better = FALSE, 
                                                     point_coords = prior_grid_info$inputs[IVAR_lpost_grid_prior_wt_best_idx,],
                                                     main_title = "IVAR-lpost", point_coords_col = "black")
IVAR_post_grid_prior_wt_plot <- get_2d_heatmap_plot(X = prior_grid_info$inputs, 
                                                    y = -IVAR_post_grid_prior_wt, param_names = computer_model_data$pars_cal_names, 
                                                    samples_kde = samp_exact_theta, raster = TRUE, 
                                                    samples_points = init_design_info$inputs, 
                                                    bigger_is_better = FALSE, 
                                                    point_coords = prior_grid_info$inputs[IVAR_post_grid_prior_wt_best_idx,],
                                                    main_title = "IVAR-post", point_coords_col = "black")

plot(IVAR_lpost_grid_prior_wt_plot)
plot(IVAR_post_grid_prior_wt_plot)

```

```{r}
# Sub-sample approximate posterior samples to use as weight points in acquisitions. 
N_support_points <- 1000

support_points_list <- support::sp(n = N_support_points, 
                                   p = length(computer_model_data$theta_true), 
                                   dist.samp = samp_round0_info$inputs)
support_points <- support_points_list$sp
colnames(support_points) <- colnames(lpost_emulator$inputs_lpost$inputs)
support_point_info <- list(inputs = support_points, 
                           inputs_scaled = scale_input_data(support_points, input_bounds = init_design_info$input_bounds))

support_point_plot <- get_2d_heatmap_plot(X = samp_round0_info$inputs, y = lpost_emulator_pred_round0$mean, 
                                          param_names = computer_model_data$pars_cal_names, 
                                          raster = FALSE, 
                                          samples_points = support_points, 
                                          bigger_is_better = TRUE, 
                                          main_title = "Support Points")

plot(support_point_plot)
```


```{r}
# Approx Posterior-Weighted 
# NOTE: plotting negative of IVAR vals to avoid negatives to produce more intuitive plots. 
# TODO: should probably also keep consistent color scheme (i.e. yellow = bigger)

# Evaluate Acquisitions. 
IVAR_lpost_grid_post_wt <- acquisition_EIVAR_lpost(theta_vals = prior_grid_info$inputs_scaled, 
                                                   lpost_emulator = lpost_emulator, 
                                                   theta_grid_integrate = support_point_info$inputs_scaled, 
                                                   verbose = FALSE, include_nugget = TRUE)

IVAR_post_grid_post_wt <- acquisition_IVAR_post(theta_vals = prior_grid_info$inputs_scaled, 
                                                lpost_emulator = lpost_emulator, 
                                                theta_grid_integrate = support_point_info$inputs_scaled, 
                                                verbose = FALSE, include_nugget = TRUE)

# Optimizers of acquisitions. 
IVAR_lpost_grid_post_wt_best_idx <- which.max(IVAR_lpost_grid_post_wt)
IVAR_post_grid_post_wt_best_idx <- which.max(IVAR_post_grid_post_wt)
  
# Generate Plots. 
IVAR_lpost_grid_post_wt_plot <- get_2d_heatmap_plot(X = prior_grid_info$inputs, 
                                                    y = -IVAR_lpost_grid_post_wt, param_names = computer_model_data$pars_cal_names, 
                                                    samples_kde = samp_exact_theta, raster = TRUE, 
                                                    samples_points = init_design_info$inputs, 
                                                    bigger_is_better = FALSE, 
                                                    point_coords = prior_grid_info$inputs[IVAR_lpost_grid_post_wt_best_idx,],
                                                    main_title = "IVAR-lpost, Approx Posterior Weights", point_coords_col = "black")
IVAR_post_grid_post_wt_plot <- get_2d_heatmap_plot(X = prior_grid_info$inputs, 
                                                   y = -IVAR_post_grid_post_wt, param_names = computer_model_data$pars_cal_names, 
                                                   samples_kde = samp_exact_theta, raster = TRUE, 
                                                   samples_points = init_design_info$inputs, 
                                                   bigger_is_better = FALSE, 
                                                   point_coords = prior_grid_info$inputs[IVAR_post_grid_post_wt_best_idx,],
                                                   main_title = "IVAR-post, Approx Posterior Weights", point_coords_col = "black")

plot(IVAR_lpost_grid_post_wt_plot)
plot(IVAR_post_grid_post_wt_plot)

```


















```{r}
#
# Test batch acquisition.
#

# Acquisition settings; acquisition type and batch method will be changed throughout the following tests.                                   
acquisition_settings <- list(acquisition_type = "",
                             opt_method = "grid",
                             batch_size = 10, 
                             batch_method = "",
                             theta_grid_candidate = samp_round0_info$inputs_scaled, 
                             theta_grid_integrate = samp_round0_info$inputs_scaled, 
                             N_subsample_candidate = 10000, 
                             N_subsample_integrate = 3000)

# Index selector for the new batch inputs. 
new_batch_sel <- c(rep(FALSE, nrow(init_design$inputs)), rep(TRUE, acquisition_settings$batch_size))

# Batch sequential design heuristic methods. 
batch_heuristics <- c("kriging_believer", "constant_liar_optimist", "constant_liar_pessimist")

```


# Visual Investigation of Single-Point Acquisitions 
```{r}
# Fix candidate and integrate points. 
theta_grid_candidate_sel <- sample(1:nrow(acquisition_settings$theta_grid_candidate), size = acquisition_settings$N_subsample_candidate, replace = FALSE)
theta_grid_integrate_sel <- sample(1:nrow(acquisition_settings$theta_grid_integrate), size = acquisition_settings$N_subsample_integrate, replace = FALSE)
```

```{r}
# IVAR-lpost 
IVAR_lpost_vals <- acquisition_EIVAR_lpost(theta_vals = samp_round0_info$inputs_scaled[theta_grid_candidate_sel,], lpost_emulator = lpost_emulator, 
                                           theta_grid_integrate = samp_round0_info$inputs_scaled[theta_grid_integrate_sel,], verbose = FALSE, include_nugget = TRUE)

IVAR_lpost_heatmap_plt <- get_2d_heatmap_plot(X = samp_round0_info$inputs[theta_grid_candidate_sel,], 
                                              y = IVAR_lpost_vals, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, raster = FALSE, 
                                              samples_points = init_design$inputs, 
                                              point_coords = computer_model_data$theta_true, bigger_is_better = TRUE, 
                                              main_title = "IVAR-lpost")

plot(IVAR_lpost_heatmap_plt)

```


```{r}
# IVAR-post 
IVAR_post_vals <- acquisition_IVAR_post(theta_vals = samp_round0_info$inputs_scaled[theta_grid_candidate_sel,], lpost_emulator = lpost_emulator, 
                                        theta_grid_integrate = samp_round0_info$inputs_scaled[theta_grid_integrate_sel,], verbose = FALSE, include_nugget = TRUE)

IVAR_post_heatmap_plt <- get_2d_heatmap_plot(X = samp_round0_info$inputs[theta_grid_candidate_sel,], 
                                             y = IVAR_post_vals, param_names = computer_model_data$pars_cal_names, 
                                             samples_kde = samp_exact_theta, raster = FALSE, 
                                             samples_points = init_design$inputs, 
                                             point_coords = computer_model_data$theta_true, bigger_is_better = TRUE, 
                                             main_title = "log IVAR-post")

plot(IVAR_post_heatmap_plt)

```



# Acquisition of Batch Points via Greedy Optimization

```{r}
#
# EI Acquisitions
#

acquisition_settings$acquisition_type <- "EI_lpost"

f_EI <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings)
}

EI_results <- mclapply(batch_heuristics, f_EI)
names(EI_results) <- c("KB", "CLO", "CLP")
```


```{r}
#
# Plot EI acquisitions results. 
#

for(j in seq_along(EI_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = EI_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = EI_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: EI-lpost, ", names(EI_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```

```{r}
#
# Max Variance Acquisitions
#

acquisition_settings$acquisition_type <- "VAR_lpost"

f_VAR <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings)
}

VAR_results <- mclapply(batch_heuristics, f_VAR)
names(VAR_results) <- c("KB", "CLO", "CLP")

```


```{r}
#
# Plot Max Variance acquisitions results. 
#

for(j in seq_along(VAR_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = VAR_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = VAR_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: VAR-lpost, ", names(VAR_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```

```{r}
#
# Integrated Variance Acquisitions - lpost
#

acquisition_settings$acquisition_type <- "EIVAR_lpost"

f_EIVAR <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings, verbose = FALSE)
}

EIVAR_results <- mclapply(batch_heuristics, f_EIVAR)
names(EIVAR_results) <- c("KB", "CLO", "CLP")

```


```{r}
#
# Plot Integrated Variance acquisitions results, lpost. 
#

for(j in seq_along(EIVAR_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = EIVAR_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = EIVAR_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: EIVAR-lpost, ", names(EIVAR_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```

```{r}
#
# Integrated Variance Acquisitions - post
#

acquisition_settings$acquisition_type <- "IVAR_post"

f_IVAR <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings, verbose = FALSE)
}

test <- batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings, verbose = FALSE)

IVAR_post_results <- mclapply(batch_heuristics, f_IVAR_post)
names(IVAR_post_results) <- c("KB", "CLO", "CLP")

```


```{r}
#
# Plot Integrated Variance acquisitions results, lpost. 
#

for(j in seq_along(IVAR_post_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = IVAR_post_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = IVAR_post_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: IVAR-post, ", names(IVAR_post_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```


# Compacting Approximate Posterior Samples
```{r}
support_points_list <- support::sp(n = acquisition_settings$batch_size, 
                                   p = length(computer_model_data$theta_true), 
                                   dist.samp = samp_round0_info$inputs)
support_points <- support_points_list$sp
colnames(support_points) <- colnames(lpost_emulator$inputs_lpost$inputs)

# TODO: order of support points is irrelevant so should add plotting option to allow plotting different marker than numbers. 
support_points_plt <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                                    lpost_vals = samp_round0_info$outputs,
                                                    computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                                    samples_kde = samp_exact_theta, 
                                                    init_design_points = lpost_emulator$inputs_lpost$inputs, 
                                                    sequential_design_points = support_points,
                                                    raster = FALSE, point_coords = computer_model_data$theta_true, 
                                                    main_title = "Support Points", 
                                                    bigger_is_better = TRUE, log_scale = FALSE)
plot(support_points_plt)

# TODO: add contour plots for approximate posterior. Seems that most of the probability mass is actually at the top part. 
# It seems that the best bet for this example would be a mixture of support points (which try to capture the approx 
# posterior) and a purely space-filling design. Or could adjust the approximate MCMC sampling itself to instead sample 
# a prior-approx posterior mixture. 

```
























# Current Thoughts 
1. In this specific test, some sort of space-filling sub-sample of the approximate posterior samples would likely have outperformed 
   any of the acquisition-based methods; this is likely due to the poor GP fit.  
2. Priorities for generalizing tests:  
    + Target the posterior, instead of log-posterior, approximation in the acquisition functions. 
    + Investigate the effect of varying batch size. 
    + After re-fitting hyperparameters, sample from updated posterior approximation and compute sample-based metrics. 
    + Simulation study: assess performance over many random initial designs. 
    + Method for sub-sampling approximate posterior samples, while also encouraging space-filling. 
    + Sample candidate points from approx posterior-prior mixture. 
3. When these priorities are completed, I think it will be a good time to focus on PEcAn implementation and tests on real data. 
4. Future work on sequential design: 
    + Consider sample-average approximation, gradient-based optimization approach. 
    + Assess different methods of handling likelihood parameters. 
    + Hybrid approaches, such as acquiring points in a greedy batch fashion, or online switching between acquisition functions. 













