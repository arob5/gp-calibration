---
title: "Batch Design 2d Illustration"
author: "Andrew Roberts"
date: '2023-08-08'
output: html_document
---

```{r, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lhs)
library(hetGP)
library(mlegp)
library(ggplot2)
library(viridis)
library(parallel)
library(gridExtra)
library(data.table)
library(BayesianTools)

source("numerical_experiment_functions.r")
source("mcmc_calibration_functions.r")
source("gp_emulator_functions.r")
source("sequential_design_optimization.r")
```

# TODOs
- Explore effect of conditioning on lpost emulator vs conditioning underlying GPs. 


# Computer Model and Data 

```{r}
# Synthetic data generation
computer_model_data <- generate_vsem_test_case(4)
```

```{r}
print(computer_model_data$ref_pars[computer_model_data$pars_cal_sel,])
```

```{r echo = FALSE}
for(output_var in computer_model_data$output_vars) {
 plotTimeSeries(observed = computer_model_data$data_obs[, output_var],
                predicted = computer_model_data$data_ref[, output_var], main = output_var) 
}
```

# Priors 

## Calibration Parameters 
```{r, echo = FALSE} 
# Priors 
theta_prior_params <- computer_model_data$ref_pars[computer_model_data$pars_cal_sel,]
theta_prior_params[, "dist"] <- c("Uniform", "Uniform")
theta_prior_params[,"param1"] <- c(1.3, 0.4) # theta_prior_params[,"lower"]
theta_prior_params[,"param2"] <- c(1.7, 0.6)  # theta_prior_params[,"upper"]
theta_prior_params <- theta_prior_params[, c("dist", "param1", "param2")]

print(theta_prior_params)
```


## Likelihood Parameters 
```{r}
sig2_prior_info <- get_IG_priors_numerical_test(sig2_true = diag(computer_model_data$Sig_eps), 
                                                bias_frac = c(0.1, -0.15), bins = 50,
                                                coef_var = c(0.3, 0.5), return_prior_plots = TRUE, 
                                                output_variables = computer_model_data$output_vars)
sig_eps_prior_params <- sig2_prior_info$prior
plts <- sig2_prior_info$plots

grid.arrange(arrangeGrob(grobs = plts, nrow = 1))
```

# Exact MCMC Samples.

## Exact MCMC. 
```{r}
N_mcmc_exact <- 50000

time_start <- proc.time()
mcmc_exact_list <- mcmc_calibrate_product_lik(computer_model_data = computer_model_data, 
                                              theta_prior_params = theta_prior_params, 
                                              learn_sig_eps = TRUE,
                                              sig_eps_prior_params = sig_eps_prior_params,
                                              N_mcmc = N_mcmc_exact)
mcmc_exact_runtime <- (proc.time() - time_start)[["elapsed"]]
print(paste0("Exact MCMC runtime: ", mcmc_exact_runtime, " seconds."))

# Format MCMC samples. 
mcmc_samp_dt <- format_mcmc_output(samp_list = mcmc_exact_list[c("theta", "sig_eps")], test_label = "exact")

```

```{r}
burn_ins <- c(exact = 10000)

mcmc_exact_trace_plts <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "exact", param_types = "theta")
grid.arrange(arrangeGrob(grobs = mcmc_exact_trace_plts, nrow = 1))
```

```{r}
mcmc_exact_trace_plts_sig_eps <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "exact", param_types = "sig_eps")
grid.arrange(arrangeGrob(grobs = mcmc_exact_trace_plts_sig_eps, nrow = 1))
```

```{r}
# Store matrix of calibration parameter samples from exact MCMC for plotting purposes. 
samp_exact_theta <- select_mcmc_samp(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "exact", param_types = "theta")[, .(param_name, sample)]
samp_exact_theta <- as.matrix(unstack(samp_exact_theta, sample ~ param_name))[, computer_model_data$pars_cal_names]
```


```{r}
# Store exact samples that will be used to compute error metrics. 


# Samples for sample-based metrics that require approximately independent samples. 
# TODO: should monitor estimated auto-correlation here. 
samp_exact_theta_thinned <- samp_exact_theta[seq(1, nrow(samp_exact_theta), 5),]

# Samples for computing emulator-based metrics. This requires computing GP predictions at every sample, so must reduce 
# the number of samples for computational feasibility. 
samp_exact_theta_emulator_metrics <- samp_exact_theta[seq(1, nrow(samp_exact_theta), 10),]

```


# Round 0: Fit GP on initial space-filling design. 

```{r, echo = FALSE}
# Emulator settings
emulator_settings <- data.frame(gp_lib = c("hetGP"), 
                                kernel = "Gaussian", 
                                transformation_method = c("truncated"),
                                emulator_target = "SSR",
                                scale_X = TRUE, 
                                normalize_y = TRUE)
print(emulator_settings)
```

```{r}
# Initial designs (round 0). I intentionally set a "bad design" here that completely misses the region of high posterior density. 
# This design was not engineered; it was the result of a random LHS initial design sample that I saved for future use in exploring 
# robustness to such bad designs. Actually, the first input in this design hits the true parameter value almost perfectly; however, 
# GPs still struggle with this design. 

bad_design_LAR <- c(1.50109273180366, 1.61540843766804, 1.4866612841934, 1.39175013386334, 1.69601865071803, 
                    1.41327501159161, 1.54226316135998, 1.57441896485165, 1.45254932799687, 1.66622050972655, 
                    1.37905605032419, 1.63773626082887, 1.53684211770073, 1.34601753323649, 1.32353227002546)
bad_design_KEXT <- c(0.500122809115176, 0.55026316565151, 0.430623519240568, 0.509714466591055, 
                     0.401992776303863, 0.544757780355091, 0.482141272605707, 0.447683127494529,
                     0.460279626613483, 0.529357980353137, 0.474070533936222, 0.56090595252191, 
                     0.598058511065319, 0.420622445465997, 0.582960123596713)
bad_design_inputs <- cbind(bad_design_LAR, bad_design_KEXT)
colnames(bad_design_inputs) <- c("LAR", "KEXT")
bad_design_outputs <- get_computer_model_SSR(computer_model_data, theta_vals = bad_design_inputs, na.rm = TRUE)

input_data_list <- prep_GP_training_data(X = bad_design_inputs, scale_X = TRUE)
output_data_list <- prep_GP_training_data(Y = bad_design_outputs, normalize_Y = TRUE)

init_design <- list(inputs = bad_design_inputs, 
                    inputs_scaled = input_data_list$X, 
                    input_bounds = input_data_list$input_bounds, 
                    outputs = bad_design_outputs, 
                    outputs_normalized = output_data_list$Y, 
                    output_stats = output_data_list$output_stats)

# Prior grid initial design for plotting purposes. 
prior_grid_info <- get_input_output_design(N_points = 51^2,
                                           design_method = "grid", 
                                           scale_inputs = TRUE,
                                           param_ranges = init_design$input_bounds,
                                           computer_model_data = computer_model_data, 
                                           theta_prior_params = theta_prior_params)
lpost_true_grid <- calc_lpost_theta_product_lik(computer_model_data = computer_model_data, 
                                                theta_vals = prior_grid_info$inputs, 
                                                vars_obs = diag(computer_model_data$Sig_eps), 
                                                na.rm = TRUE, theta_prior_params = theta_prior_params, 
                                                return_list = FALSE)

```

```{r}
# Plot initial design. 

plt_init_design <- get_2d_heatmap_plot(X = prior_grid_info$inputs, y = lpost_true_grid, param_names = computer_model_data$pars_cal_names, 
                                       samples_kde = samp_exact_theta, samples_points = init_design$inputs, raster = TRUE, 
                                       bigger_is_better = TRUE, main_title = "Initial Design over True Posterior", 
                                       point_coords = computer_model_data$theta_true)
plot(plt_init_design)


```

```{r}
# Fix pre-MCMC estimates of calibration and likelihood parameters based on design data. 
init_estimates <- get_init_param_estimates(init_design, computer_model_data, sig_eps_prior_params)
init_design$init_estimates <- init_estimates
print("Initial Estimates:")
print(init_estimates)
```


```{r}
# Fit emulators on initial design. 
gp_fits <- fit_independent_GPs(X_train = init_design$inputs_scaled, Y_train = init_design$outputs_normalized, 
                               gp_lib = emulator_settings$gp_lib, gp_kernel = emulator_settings$kernel)$fits
emulator_info_list <- list(gp_fits = gp_fits, input_bounds = init_design$input_bounds, 
                           output_stats = init_design$output_stats, settings = emulator_settings)

# Induced log joint density (i.e. log unnormalized posterior density) emulator. 
lpost_emulator <- get_lpost_emulator_obj(emulator_info_list = emulator_info_list, design_info_list = init_design, 
                                         computer_model_data = computer_model_data, sig2_eps = init_design$init_estimates$best_sig2_eps, 
                                         theta_prior_params = theta_prior_params)
```


```{r}
#
# Compute round 0 emulator-based metrics.  
#

# Validation data for evaluating emulator-based metrics. 
lpost_emulator_metrics <- calc_lpost_theta_product_lik(computer_model_data = computer_model_data, 
                                                       theta_vals = samp_exact_theta_emulator_metrics, 
                                                       vars_obs = diag(computer_model_data$Sig_eps), 
                                                       na.rm = TRUE, theta_prior_params = theta_prior_params, 
                                                       return_list = FALSE)

val_data_emulator_metrics <- list(inputs = samp_exact_theta_emulator_metrics, 
                                  inputs_scaled = scale_input_data(samp_exact_theta_emulator_metrics, init_design$input_bounds), 
                                  outputs = lpost_emulator_metrics)

# Compute metrics. 
metrics_results <- get_lpost_emulator_metrics(lpost_emulator = lpost_emulator, 
                                              lpost_validation_inputs = val_data_emulator_metrics$inputs, 
                                              lpost_validation_inputs_scaled = val_data_emulator_metrics$inputs_scaled,
                                              lpost_validation_outputs = val_data_emulator_metrics$outputs,
                                              metrics = c("crps", "rmse"),  
                                              include_nugget = TRUE)
emulator_metrics_results <- data.frame(as.list(metrics_results))
emulator_metrics_results$round <- 0
```


## Sample approximate posterior. 
```{r}
#
# Round 0 approximate posterior sampling. 
#

N_mcmc_approx <- 50000

mcmc_approx_round0 <- mcmc_calibrate_ind_GP(computer_model_data = computer_model_data, 
                                            theta_prior_params = theta_prior_params, 
                                            emulator_info = lpost_emulator$emulator_info_list,
                                            theta_init = init_design$init_estimates$best_input[1,], 
                                            sig_eps_init = init_design$init_estimates$best_sig2_eps, 
                                            learn_sig_eps = TRUE, 
                                            sig_eps_prior_params = sig_eps_prior_params, 
                                            N_mcmc = N_mcmc_approx)
```

```{r}
# Combine with existing data.table of MCMC output. 
mcmc_samp_dt <- rbindlist(list(mcmc_samp_dt, format_mcmc_output(samp_list = mcmc_approx_round0[c("theta", "sig_eps")], test_label = "round0")), 
                          use.names = TRUE)
                                                                       

```

### Round 0 MCMC sampling diagnostics. 
```{r}

burn_ins <- c(burn_ins, round0 = 10000)

mcmc_round0_trace_plts <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "round0", param_types = "theta")
grid.arrange(arrangeGrob(grobs = mcmc_round0_trace_plts, nrow = 1))
```

```{r}
mcmc_round0_trace_plts_sig_eps <- get_trace_plots(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "round0", param_types = "sig_eps")
grid.arrange(arrangeGrob(grobs = mcmc_round0_trace_plts_sig_eps, nrow = 1))
```

```{r}
#
# Store round 0 MCMC approximate posterior samples. These are used as candidate/integration points for sequential design, 
# as well as for plotting purposes. 
#

samp_round0_theta <- select_mcmc_samp(mcmc_samp_dt, burn_in_start = burn_ins, test_labels = "round0", param_types = "theta")[, .(param_name, sample)]
samp_round0_theta <- as.matrix(unstack(samp_round0_theta, sample ~ param_name))[, computer_model_data$pars_cal_names]

SSR_round0 <- get_computer_model_SSR(computer_model_data = computer_model_data, theta_vals = samp_round0_theta, na.rm = TRUE)
lpost_round0_outputs <- calc_lpost_theta_product_lik(computer_model_data = computer_model_data, 
                                                     theta_vals = samp_round0_theta, 
                                                     SSR = SSR_round0, 
                                                     vars_obs = lpost_emulator$sig2_eps, 
                                                     theta_prior_params = theta_prior_params)
samp_round0_info <- list(inputs = samp_round0_theta, 
                         inputs_scaled = scale_input_data(samp_round0_theta, init_design$input_bounds), 
                         outputs = lpost_round0_outputs$lpost)

# lpost emulator predictions at sampled points. 
lpost_emulator_pred_round0 <- predict_lpost_emulator(lpost_emulator = lpost_emulator, 
                                                     inputs_new_scaled = samp_round0_info$inputs_scaled, 
                                                     inputs_new_unscaled = samp_round0_info$inputs, include_nugget = TRUE)
```




```{r}
# Compute "sample-based metrics"; that is, measures of error between the approximate and true posterior computed from the MCMC samples. 

round0_sample_metrics <- compute_mcmc_comparison_metrics(samp_dt = mcmc_samp_dt, burn_in_start = burn_ins, 
                                                         test_label_1 = "exact", test_label_2 = "round0", 
                                                         param_types = c("theta", "sig_eps"), 
                                                         metrics = c("mean", "cov"))
print(round0_sample_metrics$metrics_individual)
print(round0_sample_metrics$metrics_agg)
```


```{r}
# GP predictive mean and variance plots. 

plt_mean <- get_2d_heatmap_plot(X = samp_round0_info$inputs, y = lpost_emulator_pred_round0$mean, param_names = computer_model_data$pars_cal_names, 
                                samples_kde = samp_exact_theta, raster = FALSE, 
                                samples_points = init_design$inputs, 
                                point_coords = computer_model_data$theta_true, bigger_is_better = TRUE, 
                                main_title = "lpost predictive mean")
plt_var <- get_2d_heatmap_plot(X = samp_round0_info$inputs, y = lpost_emulator_pred_round0$var, param_names = computer_model_data$pars_cal_names, 
                               samples_kde = samp_exact_theta, raster = FALSE, 
                               samples_points = init_design$inputs, 
                               point_coords = computer_model_data$theta_true, bigger_is_better = FALSE, log_scale = TRUE, main_title = "lpost predictive var")

plot(plt_mean)
plot(plt_var)
```

```{r}
# Underlying GP Predictions. 
pred_GPs <- predict_independent_GPs(X_pred = samp_round0_info$inputs_scaled, 
                                    gp_obj_list = lpost_emulator$emulator_info_list$gp_fits, 
                                    gp_lib = lpost_emulator$emulator_info_list$settings$gp_lib, 
                                    denormalize_predictions = TRUE, output_stats = init_design$output_stats)
```


```{r}
# Underlying GP plots. 

for(j in seq_along(pred_GPs)) {
  
  plt_GP_mean <- get_2d_heatmap_plot(X = samp_round0_info$inputs, y = pred_GPs[[j]]$mean, param_names = computer_model_data$pars_cal_names, 
                                     samples_kde = samp_exact_theta, raster = FALSE, 
                                     samples_points = init_design$inputs, 
                                     point_coords = computer_model_data$theta_true, bigger_is_better = FALSE, 
                                     main_title = paste0("SSR GP pred mean: ", computer_model_data$output_vars[j]))
  
  plt_GP_var <- get_2d_heatmap_plot(X = samp_round0_info$inputs, y = pred_GPs[[j]]$var_comb, param_names = computer_model_data$pars_cal_names, 
                                    samples_kde = samp_exact_theta, raster = FALSE, 
                                    samples_points = init_design$inputs, 
                                    point_coords = computer_model_data$theta_true, bigger_is_better = FALSE, 
                                    main_title = paste0("SSR GP pred var: ", computer_model_data$output_vars[j]), log_scale = TRUE)
  
  plot(plt_GP_mean)
  plot(plt_GP_var)
  
}


```



```{r}
#
# Test batch acquisition.
#

# Acquisition settings; acquisition type and batch method will be changed throughout the following tests.                                   
acquisition_settings <- list(acquisition_type = "",
                             opt_method = "grid",
                             batch_size = 10, 
                             batch_method = "",
                             theta_grid_candidate = samp_round0_info$inputs_scaled, 
                             theta_grid_integrate = samp_round0_info$inputs_scaled, 
                             N_subsample_candidate = 10000, 
                             N_subsample_integrate = 3000)

# Index selector for the new batch inputs. 
new_batch_sel <- c(rep(FALSE, nrow(init_design$inputs)), rep(TRUE, acquisition_settings$batch_size))

# Batch sequential design heuristic methods. 
batch_heuristics <- c("kriging_believer", "constant_liar_optimist", "constant_liar_pessimist")

```


```{r}
#
# EI Acquisitions
#

acquisition_settings$acquisition_type <- "EI_lpost"

f_EI <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings)
}

EI_results <- mclapply(batch_heuristics, f_EI)
names(EI_results) <- c("KB", "CLO", "CLP")
```


```{r}
#
# Plot EI acquisitions results. 
#

for(j in seq_along(EI_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = EI_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = EI_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: EI-lpost, ", names(EI_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```

```{r}
#
# Max Variance Acquisitions
#

acquisition_settings$acquisition_type <- "VAR_lpost"

f_VAR <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings)
}

VAR_results <- mclapply(batch_heuristics, f_VAR)
names(VAR_results) <- c("KB", "CLO", "CLP")

```


```{r}
#
# Plot Max Variance acquisitions results. 
#

for(j in seq_along(VAR_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = VAR_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = VAR_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: VAR-lpost, ", names(VAR_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```

```{r}
#
# Integrated Variance Acquisitions - lpost
#

acquisition_settings$acquisition_type <- "EIVAR_lpost"

f_EIVAR <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings, verbose = FALSE)
}

EIVAR_results <- mclapply(batch_heuristics, f_EIVAR)
names(EIVAR_results) <- c("KB", "CLO", "CLP")

```


```{r}
#
# Plot Integrated Variance acquisitions results, lpost. 
#

for(j in seq_along(EIVAR_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = EIVAR_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = EIVAR_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: EIVAR-lpost, ", names(EIVAR_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```

```{r}
#
# Integrated Variance Acquisitions - post
#

acquisition_settings$acquisition_type <- "IVAR_post"

f_IVAR <- function(heuristic) {
  acquisition_settings$batch_method <- heuristic
  batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings, verbose = FALSE)
}

test <- batch_acquisition_opt_one_step(lpost_emulator, acquisition_settings, verbose = FALSE)

IVAR_post_results <- mclapply(batch_heuristics, f_IVAR_post)
names(IVAR_post_results) <- c("KB", "CLO", "CLP")

```


```{r}
#
# Plot Integrated Variance acquisitions results, lpost. 
#

for(j in seq_along(IVAR_post_results)) {
  batch_plot <- get_2d_Bayes_opt_heatmap_plot(theta_vals = samp_round0_info$inputs, 
                                              lpost_vals = samp_round0_info$outputs,
                                              computer_model_data = computer_model_data, param_names = computer_model_data$pars_cal_names, 
                                              samples_kde = samp_exact_theta, 
                                              init_design_points = IVAR_post_results[[j]]$inputs_lpost$inputs[!new_batch_sel,,drop=FALSE], 
                                              sequential_design_points = IVAR_post_results[[j]]$inputs_lpost$inputs[new_batch_sel,,drop=FALSE],
                                              raster = FALSE, point_coords = computer_model_data$theta_true, 
                                              main_title = paste0("Batch acquisition: IVAR-post, ", names(IVAR_post_results)[j]), 
                                              bigger_is_better = TRUE, log_scale = FALSE)
                                              
  plot(batch_plot)
}

```


# TODO: should look at one-point acquisition heatmaps to better understand acquisition functions. 





























# Current Thoughts 
1. In this specific test, some sort of space-filling sub-sample of the approximate posterior samples would likely have outperformed 
   any of the acquisition-based methods; this is likely due to the poor GP fit.  
2. Priorities for generalizing tests:  
    + Target the posterior, instead of log-posterior, approximation in the acquisition functions. 
    + Investigate the effect of varying batch size. 
    + After re-fitting hyperparameters, sample from updated posterior approximation and compute sample-based metrics. 
    + Simulation study: assess performance over many random initial designs. 
    + Method for sub-sampling approximate posterior samples, while also encouraging space-filling. 
    + Sample candidate points from approx posterior-prior mixture. 
3. When these priorities are completed, I think it will be a good time to focus on PEcAn implementation and tests on real data. 
4. Future work on sequential design: 
    + Consider sample-average approximation, gradient-based optimization approach. 
    + Assess different methods of handling likelihood parameters. 
    + Hybrid approaches, such as acquiring points in a greedy batch fashion, or online switching between acquisition functions. 













