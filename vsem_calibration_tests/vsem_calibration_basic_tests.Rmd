---
title: 'VSEM Calibration: Basic Tests'
output: html_document
date: '2023-01-12'
---

# Introduction

## Ecosystem Model
The Very Simple Ecosystem Model (VSEM) is a simplified vegetation model that models carbon dynamics between three pools (above-ground vegetation, below-ground vegetation, 
and soil organic matter) with one forcing variable (PAR - photosynthetically active radiation). The model outputs time series for four output variables: the three carbon 
pools and Net Ecosystem Exchange (NEE). I represent the model mathematically as 
$$f: \mathcal{D} \subset \mathbb{R}^d \to \mathbb{R}^{n \times p}$$
where $\theta \in \mathcal{D}$ denotes the calibration parameters, $n$ the length of the output time series, and $p$ the number of output variables. We can consider $p = 4$ as 
described above or choose to focus on a subset of the outputs (e.g. just NEE). I utilize the notation $f(i, j, \theta) := [f(\theta)]_{ij}$ to refer to the scalar output at the $i^{th}$ time step of the $j^{th}$ output variable. 

## Statistical Model
I simulate data by first simulating a PAR time series, running the forward model $f$ using the simulated PAR forcing data and some true fixed values $\theta^*$ of the calibration 
parameters. I add Gaussian noise to the resulting outputs, resulting in the data-generating process
$$y_{ij} = f(i, j, \theta) + \epsilon_{ij}$$
where $y_{ij}$ denotes the simualted field data observation of the $j^{th}$ output variable at the $i^{th}$ time step. This document considers a basic independent Gaussian error structure, such that $\epsilon_{ij} \overset{ind}{\sim} N(0, \sigma^2_{\epsilon_j})$, allowing for the magnitude of the noise to be different across the different output variables. In other words, independence is assumed across time and outputs. Letting $Y \in \mathbb{R}^{n \times p}$ collect all of the field data observations and 
$\Sigma_\epsilon := \text{diag}\{\sigma^2_{\epsilon_1}, \dots, \sigma^2_{\epsilon_p}\}$, these assumptions imply the likelihood
$$p(Y|\theta, \Sigma_\epsilon) = \prod_{i = 1}^{n} \prod_{j = 1}^{p} N(y_{ij}|f(i, j, \theta), \sigma^2_{\epsilon_j})$$
I assume a well-specified model throughout this document, so the above likelihood corresponds to the true data-generating process as statistical model used to perform calibration.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(BayesianTools)

source("mcmc_calibration_functions.r")
```

```{r}
random_seed <- 5
set.seed(random_seed)
```


```{r run_params, include = FALSE}
# Number days in time series 
N_days <- 1000

# The covariance matrix between the outputs. Note that the NEE output of the
# model VSEM() is scalesd by 1000, so the observation error magnitude should correspond 
# to this scale. In this basic example, we assume equal noise variance for each output.
noise_var <- 4.0
Sig_eps <- noise_var * diag(1, nrow = 4)
rownames(Sig_eps) <- c("NEE", "Cv", "Cs", "CR")
colnames(Sig_eps) <- c("NEE", "Cv", "Cs", "CR")

# Assuming iid Inverse Gamma priors on each sig_eps_j
sig_eps_prior_mean <- noise_var
sig_eps_prior_sd <- 0.4

# Names of parameters to calibrate.
pars_cal <- c("KEXT")

# Whether or not to fix Sig_eps at known value, or to treat as random and infer from data.  
learn_lik_par <- FALSE

# Identify which outputs to constrain in the model. Each constrained output factors 
# into the likelihood. Choices are "NEE" and the three carbon pools "Cv", "Cs", and "CR".
output_vars <- c("NEE", "Cv", "Cs", "CR")
N_outputs <- length(output_vars)
```


# Model Parameters and Synthetic Data Generation

```{r data_gen, include = FALSE}
# Create time series of Phosynthetically Active Radiation (PAR) which is the forcing variable
# for the VSEM model. 
PAR <- VSEMcreatePAR(seq_len(N_days))

# The "best" column of the reference parameters are used to generate the "true" 
# output data. We will add noise to this data to simulate the field observations.
ref_pars <- VSEMgetDefaults()
data_ref <- as.data.table(VSEM(ref_pars$best, PAR))[, ..output_vars]

# Add observational noise; NEE is scaled by 1000. Fow now considering independent 
# outputs, but can consider models that fill in the off-diagonal Sig_eps values
# in the future. 
if("NEE" %in% output_vars) {
  data_ref[, NEE := NEE*1000]
}
Lt <- chol(Sig_eps[output_vars, output_vars]) # Upper triangular Cholesky factor of output covariance
Z <- matrix(rnorm(N_days*N_outputs), N_days, N_outputs) 
data_obs <- data_ref + Z %*% Lt

# Index selector for calibration parameters
pars_cal_sel <- which(rownames(ref_pars) %in% pars_cal)
ref_pars[["calibrate"]] <- rownames(ref_pars) %in% pars_cal
```


## True Parameters

### Calibration Parameters ($\theta$)
```{r true_params, echo = FALSE}
print(ref_pars)
```

### Likelihood Parameters ($\Sigma_\epsilon$)
```{r true_lik_params, echo = FALSE}
print(Sig_eps)
```

## Synthetic data plots
```{r PAR_plot, echo = FALSE}
# Plot PAR, the forcing term in the model
plot(PAR, main = "PAR (driving the model)", xlab = "Day", ylab = "PAR")
```


```{r NEE_plot, echo = FALSE}
output_var_idx <- 1
plotTimeSeries(observed = data_obs[[output_vars[output_var_idx]]], 
               predicted = data_ref[[output_vars[output_var_idx]]], main = output_vars[output_var_idx])
```

```{r Cv_plot, echo = FALSE}
output_var_idx <- 2
plotTimeSeries(observed = data_obs[[output_vars[output_var_idx]]], 
               predicted = data_ref[[output_vars[output_var_idx]]], main = output_vars[output_var_idx])
```

```{r Cs_plot, echo = FALSE}
output_var_idx <- 3
plotTimeSeries(observed = data_obs[[output_vars[output_var_idx]]], 
               predicted = data_ref[[output_vars[output_var_idx]]], main = output_vars[output_var_idx])
```

```{r CR_plot, echo = FALSE}
output_var_idx <- 4
plotTimeSeries(observed = data_obs[[output_vars[output_var_idx]]], 
               predicted = data_ref[[output_vars[output_var_idx]]], main = output_vars[output_var_idx])
```

```{r NEE_vs_PAR, echo = FALSE}
# Normalize NEE and PAR and plot them together
# Note: NEE > 0 implies positive flux to atmosphere
NEE_ref_norm <- data_ref[, (NEE - mean(NEE))/sd(NEE)]
PAR_norm <- (PAR - mean(PAR)) / sd(PAR)
plot(NEE_ref_norm, main = "Ground Truth NEE vs. PAR (Normalized)", 
     xlab = "Day", ylab = "Z-scaore NEE/PAR", col = "red")
points(PAR_norm, col = "blue")

legend(x = "bottomright",     
       legend = c("NEE", "PAR"), 
       pch = c(1, 1),
       col = c("red", "blue")) 
```

### Likelihood Plot
```{r, echo = FALSE}
k_ext_vals <- seq(ref_pars["KEXT", "lower"], ref_pars["KEXT", "upper"], length.out = 100)
llik_vals <- vector(mode = "numeric", length = length(k_ext_vals))
for(i in seq_along(llik_vals)) {
  llik_vals[i] <- llik_Gaussian(k_ext_vals[i], Sig_eps, ref_pars, pars_cal_sel, output_vars, PAR, data_obs)
}

plot(k_ext_vals, llik_vals, type = "l", xlab = "KEXT", ylab = "Unnormalized Log-Likelihood", main = "Log-Likelihood 1D Projection")
abline(v = ref_pars["KEXT", "best"], col = "red")
```

# Priors

## Calibration Parameters
```{r, echo = FALSE}
ref_pars["KEXT", "dist"] <- "Uniform"
ref_pars["KEXT", "param1"] <- 0.2
ref_pars["KEXT", "param2"] <- 0.7
theta_prior_params <- ref_pars[pars_cal_sel, c("dist", "param1", "param2")]
print(theta_prior_params)
```
## Observation Covariance Matrix

```{r, echo = FALSE}
# Define inverse Gamma hyperparameters, in order to achieve mean and sd specified above
inv_gamma_a <- 2 + (sig_eps_prior_mean / sig_eps_prior_sd)^2
inv_gamma_b <- sig_eps_prior_mean + sig_eps_prior_mean^3 / sig_eps_prior_sd^2

Sig_eps_prior_params <- list(dist = "IG", 
                             IG_shape = rep(inv_gamma_a, N_outputs), 
                             IG_scale = rep(inv_gamma_b, N_outputs))
```

Recall that the true noise variances $\sigma^2_{\epsilon_j}$ $j = 1, \dots, 4$ were all set to the value `r noise_var`. In this example, I define iid priors
$$\sigma^2_{\epsilon_j} \overset{iid}{\sim} IG(a, b)$$
where a = `r inv_gamma_a` and b = `r inv_gamma_b` which center the priors on the true values, with standard deviations `r sig_eps_prior_sd`. Note that this defines iid priors, but the 
variances are not constrained to be equal across outputs. 


# MCMC

## Adaptive Metropolis-within-Gibbs
I first consider an adaptive MWG sampler without any sort of model emulation. 

```{r}
# Parameters for MWG sampler
learn_Sig_eps <- TRUE
diag_cov <- TRUE
N_mcmc <- 50000
adapt_frequency <- 1000
adapt_min_scale <- 0.1
accept_rate_target <- 0.3
```

```{r}
mwg_results <- mcmc_calibrate(par_ref = par_ref, 
                              par_cal_sel = par_cal_sel, 
                              data_obs = data_obs, 
                              output_vars = output_vars, 
                              PAR = PAR,
                              theta_init = NA, 
                              theta_prior_params = theta_prior_params, 
                              learn_Sig_eps = TRUE, 
                              Sig_eps_init = NA, 
                              Sig_eps_prior_params = Sig_eps_prior_params, 
                              diag_cov = TRUE, 
                              N_mcmc = N_mcmc, 
                              adapt_frequency = adapt_frequency, 
                              adapt_min_scale = adapt_min_scale, 
                              accept_rate_target = accept_rate_target)
```



